
==================== FILE: demo_benchmark copy.py ====================
#!/usr/bin/env python3
"""Run a small, reproducible refactoring benchmark on a Java project.

This script is designed to support a "research-flavored" demo:
  - 1-2 small refactoring tasks
  - measurable outcomes (correctness, maintainability, change-risk)
  - ablation / comparison (Graph-RAG vs vector-only retrieval)

Usage (example):
  python demo_benchmark.py \
    --project data/marketing-demo \
    --tasks data/bench_tasks.json \
    --out bench_out \
    --modes graph_rag,vector_only

Notes:
  - By default, the agent uses an OpenAI-compatible endpoint.
    Set OPENAI_API_KEY (and optionally OPENAI_MODEL, OPENAI_BASE_URL).
  - If you pass --dry-llm, the benchmark will still run but refactoring will
    likely fail verification (useful to validate the plumbing).
"""

from __future__ import annotations

import argparse
from pathlib import Path

from src.dotenv import auto_load_dotenv
from src.eval.benchmark import load_tasks, run_benchmark
from src.eval.report import write_benchmark_report


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--dotenv",
        default=None,
        help=(
            "Optional path to a .env file. If omitted, the runner will still try to "
            "auto-load .env from the current directory or parent directories."
        ),
    )
    ap.add_argument("--project", required=True, help="Java project root directory")
    ap.add_argument("--tasks", required=True, help="Path to tasks JSON (see data/bench_tasks.json)")
    ap.add_argument("--out", default="bench_out", help="Output directory")
    ap.add_argument("--modes", default="graph_rag,vector_only", help="Comma-separated: graph_rag,vector_only")
    ap.add_argument("--seed-top-k", type=int, default=5)
    ap.add_argument("--hops", type=int, default=2)
    ap.add_argument("--max-nodes", type=int, default=30)
    ap.add_argument("--max-iters", type=int, default=3)
    ap.add_argument("--dry-llm", action="store_true")
    ap.add_argument(
        "--force-regex-parser",
        action="store_true",
        help="Force the regex fallback parser (useful if you don't want tree-sitter).",
    )
    args = ap.parse_args()

    # Load .env (optional explicit path, otherwise auto-search).
    auto_load_dotenv(args.dotenv)

    project_root = Path(args.project)
    tasks_path = Path(args.tasks)
    out_dir = Path(args.out)

    tasks = load_tasks(tasks_path)
    modes = [m.strip() for m in str(args.modes).split(",") if m.strip()]

    _ = run_benchmark(
        project_root=project_root,
        tasks=tasks,
        out_dir=out_dir,
        modes=modes,
        prefer_tree_sitter=not bool(args.force_regex_parser),
        seed_top_k=args.seed_top_k,
        hops=args.hops,
        max_nodes=args.max_nodes,
        max_iters=args.max_iters,
        dry_llm=args.dry_llm,
    )

    results_path = out_dir / "benchmark_results.json"
    html_path = out_dir / "benchmark_report.html"
    write_benchmark_report(results_path, out_html=html_path)

    print(f"âœ… Results JSON: {results_path.resolve()}")
    print(f"âœ… Report HTML:  {html_path.resolve()}")
    print(f"Modes: {', '.join(modes)}")
    print(f"Tasks: {', '.join(t.name for t in tasks)}")


if __name__ == "__main__":
    main()

==================== END FILE ====================


==================== FILE: merge.py ====================
import os

def merge_project_code(root_dir, output_file):
    # 1. ã€é»‘åå•ç›®å½•åã€‘é‡åˆ°è¿™äº›æ–‡ä»¶å¤¹åï¼Œç›´æŽ¥è·³è¿‡ï¼Œè¿žè¿›éƒ½ä¸è¿›åŽ»
    # è¿™äº›é€šå¸¸æ˜¯è™šæ‹ŸçŽ¯å¢ƒã€ç¼“å­˜ã€Gité…ç½®ç­‰
    IGNORE_DIRS = {
        '.venv', 'venv', 'env', '.env',  # å„ç§è™šæ‹ŸçŽ¯å¢ƒå†™æ³•
        '__pycache__', 
        '.git', '.idea', '.vscode',      # ç¼–è¾‘å™¨é…ç½®
        'build', 'dist', 'egg-info',     # æ‰“åŒ…æ®‹ç•™
        'node_modules',                  # å‰ç«¯ä¾èµ–ï¼ˆå¦‚æžœæœ‰ï¼‰
        'site-packages'                  # ä¸¥é˜²æ­»å®ˆç¬¬ä¸‰æ–¹åº“
    }

    # 2. ã€è·¯å¾„å…³é”®è¯è¿‡æ»¤ã€‘å¦‚æžœæ–‡ä»¶è·¯å¾„é‡ŒåŒ…å«è¿™äº›è¯ï¼Œä¹Ÿå¼ºåˆ¶è·³è¿‡
    # è¿™æ˜¯ä¸ºäº†é˜²æ­¢æ¼ç½‘ä¹‹é±¼ï¼Œæ¯”å¦‚æŸäº›æ·±å±‚ç›®å½•é‡Œçš„åº“æ–‡ä»¶
    IGNORE_KEYWORDS = [
        'site-packages',  # å†æ¬¡ç¡®ä¿åº“æ–‡ä»¶ä¸è¢«è¯»å–
        '/lib/python',    # å…¸åž‹çš„åº“è·¯å¾„ç‰¹å¾
        '\\lib\\python'   # å…¼å®¹ Windows è·¯å¾„
    ]

    this_script_name = os.path.basename(__file__)
    file_count = 0
    
    print(f"æ­£åœ¨æ‰«æ: {root_dir}")
    print("å·²å¼€å¯ã€å¼ºåŠ›è¿‡æ»¤æ¨¡å¼ã€‘ï¼Œè‡ªåŠ¨å±è”½è™šæ‹ŸçŽ¯å¢ƒå’Œç¬¬ä¸‰æ–¹åº“...")

    with open(output_file, 'w', encoding='utf-8') as outfile:
        for root, dirs, files in os.walk(root_dir):
            # --- æ ¸å¿ƒè¿‡æ»¤æ­¥éª¤ 1: ä¿®æ”¹ dirs åˆ—è¡¨ï¼Œé˜»æ­¢è¿›å…¥é»‘åå•ç›®å½• ---
            # è¿™ä¸€æ­¥éžå¸¸å…³é”®ï¼Œå®ƒèƒ½è®©ç¨‹åºç›´æŽ¥ä¸æ‰«æ .venv æ–‡ä»¶å¤¹ï¼ŒèŠ‚çœå¤§é‡æ—¶é—´
            # æˆ‘ä»¬å€’åºéåŽ†ï¼Œè¿™æ ·ç§»é™¤å…ƒç´ ä¸ä¼šå½±å“ç´¢å¼•
            for i in range(len(dirs) - 1, -1, -1):
                d = dirs[i]
                # è§„åˆ™ï¼šå¦‚æžœç›®å½•ååœ¨é»‘åå•é‡Œï¼Œæˆ–è€…ä»¥ '.' å¼€å¤´ï¼ˆéšè—ç›®å½•ï¼‰ï¼Œç›´æŽ¥å‰”é™¤
                if d in IGNORE_DIRS or d.startswith('.'):
                    dirs.pop(i)
            
            # --- æ ¸å¿ƒè¿‡æ»¤æ­¥éª¤ 2: æ£€æŸ¥å½“å‰è·¯å¾„æ˜¯å¦åŒ…å«æ•æ„Ÿè¯ ---
            # å¦‚æžœè·¯å¾„é‡Œå±…ç„¶è¿˜æœ‰ site-packages (åŒé‡ä¿é™©)ï¼Œç›´æŽ¥è·³è¿‡è¿™ä¸€å±‚çš„æ‰€æœ‰æ–‡ä»¶
            if any(keyword in root for keyword in IGNORE_KEYWORDS):
                continue

            for file in files:
                if file.endswith('.py') and file != this_script_name:
                    full_path = os.path.join(root, file)
                    relative_path = os.path.relpath(full_path, root_dir)
                    
                    # æ‰“å°ä¸€ä¸‹ï¼Œè®©ä½ çŸ¥é“å®ƒåœ¨å¹²æ´»ï¼Œä½†æ²¡åœ¨çžŽå¹²æ´»
                    print(f"æ­£åœ¨åˆå¹¶: {relative_path}")
                    
                    outfile.write(f"\n{'='*20} FILE: {relative_path} {'='*20}\n")
                    
                    try:
                        with open(full_path, 'r', encoding='utf-8') as infile:
                            outfile.write(infile.read())
                    except Exception as e:
                        outfile.write(f"# è¯»å–é”™è¯¯: {e}\n")
                        
                    outfile.write(f"\n{'='*20} END FILE {'='*20}\n\n")
                    file_count += 1

    print(f"\nåˆå¹¶å®Œæˆï¼å…±å¤„ç† {file_count} ä¸ªæ–‡ä»¶ã€‚")
    print(f"ç»“æžœå·²ä¿å­˜è‡³: {output_file}")

if __name__ == "__main__":
    merge_project_code(os.getcwd(), "final_code.txt")
==================== END FILE ====================


==================== FILE: demo_benchmark.py ====================
#!/usr/bin/env python3
"""Run a small, reproducible refactoring benchmark on a Java project.

This script is designed to support a "research-flavored" demo:
  - 1-2 small refactoring tasks
  - measurable outcomes (correctness, maintainability, change-risk)
  - ablation / comparison (Graph-RAG vs vector-only retrieval)

Usage (example):
  python demo_benchmark.py \
    --project data/marketing-demo \
    --tasks data/bench_tasks.json \
    --out bench_out \
    --modes graph_rag,vector_only

Notes:
  - By default, the agent uses an OpenAI-compatible endpoint.
    Set OPENAI_API_KEY (and optionally OPENAI_MODEL, OPENAI_BASE_URL).
  - If you pass --dry-llm, the benchmark will still run but refactoring will
    likely fail verification (useful to validate the plumbing).
"""

from __future__ import annotations

import argparse
from pathlib import Path

from src.dotenv import auto_load_dotenv
from src.eval.benchmark import load_tasks, run_benchmark
from src.eval.report import write_benchmark_report


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument(
        "--dotenv",
        default=".env",
        help=(
            "Optional path to a .env file. If omitted, the runner will still try to "
            "auto-load .env from the current directory or parent directories."
        ),
    )
    ap.add_argument("--project", required=True, help="Java project root directory")
    ap.add_argument("--tasks", required=True, help="Path to tasks JSON (see data/bench_tasks.json)")
    ap.add_argument("--out", default="bench_out", help="Output directory")
    ap.add_argument("--modes", default="graph_rag,vector_only", help="Comma-separated: graph_rag,vector_only")
    ap.add_argument(
        "--vector-only-no-search-tools",
        action="store_true",
        help="For vector_only runs, remove search commands (rg/grep/find) from the sandbox whitelist to better isolate retrieval differences.",
    )
    ap.add_argument("--seed-top-k", type=int, default=5)
    ap.add_argument("--hops", type=int, default=2)
    ap.add_argument("--max-nodes", type=int, default=30)
    ap.add_argument("--max-iters", type=int, default=3)
    ap.add_argument("--dry-llm", action="store_true")
    ap.add_argument(
        "--force-regex-parser",
        action="store_true",
        help="Force the regex fallback parser (useful if you don't want tree-sitter).",
    )
    args = ap.parse_args()

    # Load .env (optional explicit path, otherwise auto-search).
    auto_load_dotenv(args.dotenv)

    project_root = Path(args.project)
    tasks_path = Path(args.tasks)
    out_dir = Path(args.out)

    tasks = load_tasks(tasks_path)
    modes = [m.strip() for m in str(args.modes).split(",") if m.strip()]

    _ = run_benchmark(
        project_root=project_root,
        tasks=tasks,
        out_dir=out_dir,
        modes=modes,
        prefer_tree_sitter=not bool(args.force_regex_parser),
        seed_top_k=args.seed_top_k,
        hops=args.hops,
        max_nodes=args.max_nodes,
        max_iters=args.max_iters,
        dry_llm=args.dry_llm,
        restrict_vector_only_tools=args.vector_only_no_search_tools,
    )

    results_path = out_dir / "benchmark_results.json"
    html_path = out_dir / "benchmark_report.html"
    write_benchmark_report(results_path, out_html=html_path)

    print(f"âœ… Results JSON: {results_path.resolve()}")
    print(f"âœ… Report HTML:  {html_path.resolve()}")
    print(f"Modes: {', '.join(modes)}")
    print(f"Tasks: {', '.join(t.name for t in tasks)}")


if __name__ == "__main__":
    main()

==================== END FILE ====================


==================== FILE: render_context_pack.py ====================
#!/usr/bin/env python3
"""Render context_pack.json into a simple IDE-like HTML preview.

Usage:
  python render_context_pack.py /path/to/context_pack.json -o context_preview.html
"""
from __future__ import annotations

import argparse
import html
import json
from pathlib import Path
from typing import Any, Dict, List, Optional


def _escape(s: str) -> str:
    return html.escape(s, quote=False)


def _as_list(x):
    if x is None:
        return []
    if isinstance(x, list):
        return x
    return [x]


def _node_map(pack: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    m: Dict[str, Dict[str, Any]] = {}
    for n in pack.get("nodes", []):
        nid = n.get("node_id") or n.get("id")
        if nid:
            m[nid] = n
    return m


def _format_why(why: Any) -> str:
    items = _as_list(why)
    if not items:
        return ""
    lis = "\n".join(f"<li>{_escape(str(it))}</li>" for it in items)
    return f"<ul class='why'>{lis}</ul>"


def _code_with_line_numbers(snippet: str, start_line: int, highlight: Optional[Dict[str, int]]) -> str:
    lines = snippet.splitlines()
    hl_start = hl_end = None
    if isinstance(highlight, dict):
        hl_start = highlight.get("start_line")
        hl_end = highlight.get("end_line")
    out = []
    for i, line in enumerate(lines):
        lineno = start_line + i
        cls = "code-line"
        if hl_start is not None and hl_end is not None and hl_start <= lineno <= hl_end:
            cls += " hl"
        out.append(
            f"<div class='{cls}'><span class='ln'>{lineno:>4}</span><span class='src'>{_escape(line)}</span></div>"
        )
    return "<div class='code'>" + "\n".join(out) + "</div>"


def _node_card(n: Dict[str, Any]) -> str:
    nid = n.get("node_id") or ""
    kind = n.get("type") or n.get("kind") or ""
    role = n.get("role") or ""
    roles = n.get("roles") or []
    fp = n.get("file_path") or ""
    sig = n.get("signature") or ""
    doc = n.get("docstring") or ""
    snippet = n.get("snippet") or ""
    start_line = int(n.get("start_line") or 0)
    highlight = n.get("highlight_span")

    meta_bits = []
    if fp:
        meta_bits.append(f"<span class='meta'><b>File:</b> {_escape(fp)}:{start_line}-{n.get('end_line')}</span>")
    if sig:
        meta_bits.append(f"<span class='meta'><b>Sig:</b> {_escape(sig)}</span>")
    if role:
        meta_bits.append(f"<span class='meta'><b>Role:</b> {_escape(role)}</span>")
    if roles:
        meta_bits.append(f"<span class='meta'><b>Roles:</b> {_escape(', '.join(map(str, roles)))}</span>")

    meta_html = "<div class='meta-row'>" + " | ".join(meta_bits) + "</div>" if meta_bits else ""
    doc_html = f"<pre class='doc'>{_escape(doc)}</pre>" if doc else ""
    code_html = _code_with_line_numbers(snippet, start_line if start_line else 1, highlight) if snippet else ""
    why_html = _format_why(n.get("why"))

    return f"""
    <div class=\"card\" id=\"{_escape(nid)}\">
      <div class=\"card-head\">
        <div class=\"title\"><span class=\"badge kind\">{_escape(kind)}</span> <b>{_escape(nid)}</b></div>
        {meta_html}
      </div>
      {doc_html}
      {code_html}
      {why_html}
    </div>
    """


def _mini_node_link(nid: str, nmap: Dict[str, Dict[str, Any]]) -> str:
    n = nmap.get(nid, {})
    kind = n.get("type") or n.get("kind") or "Node"
    role = n.get("role") or ""
    return f'<a class="node-link" href="#{_escape(nid)}"><span class="badge kind">{_escape(kind)}</span> {_escape(nid)} <span class="badge role">{_escape(role)}</span></a>'


def _section_list(title: str, items: List[Any], nmap: Dict[str, Dict[str, Any]], key: str = "node_id") -> str:
    if not items:
        body = "<div class='empty'>None</div>"
    else:
        rows = []
        for it in items:
            if isinstance(it, dict):
                nid = it.get(key) or it.get("node_id")
                extra = []
                if "depth" in it:
                    extra.append(f"depth={it['depth']}")
                if extra:
                    rows.append(f"<li>{_mini_node_link(nid, nmap)} <span class='small'>({', '.join(extra)})</span></li>")
                else:
                    rows.append(f"<li>{_mini_node_link(nid, nmap)}</li>")
            else:
                rows.append(f"<li>{_mini_node_link(str(it), nmap)}</li>")
        body = "<ul class='list'>" + "\n".join(rows) + "</ul>"
    return f"<details open class='section'><summary>{_escape(title)}</summary>{body}</details>"


def render(pack: Dict[str, Any]) -> str:
    nmap = _node_map(pack)

    query = pack.get("query", "")
    focus = (pack.get("focus") or {}).get("node_id") or pack.get("focus_node") or ""
    seeds = pack.get("seed_nodes", [])
    seed_lines = []
    for s in seeds:
        nid = s.get("node_id")
        score = s.get("score")
        seed_lines.append(f"<li>{_mini_node_link(nid, nmap)} <span class='small'>(score={float(score):.3f})</span></li>")
    seed_html = "<ul class='list'>" + "\n".join(seed_lines) + "</ul>" if seed_lines else "<div class='empty'>None</div>"

    cg = pack.get("call_graph", {}) or {}
    df = pack.get("data_flow", {}) or {}

    left = []
    left.append(f"<div class='kv'><b>Query:</b> {_escape(str(query))}</div>")
    left.append(f"<div class='kv'><b>Focus:</b> {(_mini_node_link(focus, nmap) if focus else '<span class=empty>None</span>')}</div>")
    left.append("<details open class='section'><summary>Seeds</summary>" + seed_html + "</details>")
    left.append(_section_list("Call Graph Â· Callers", cg.get("callers", []), nmap))
    left.append(_section_list("Call Graph Â· Callees", cg.get("callees", []), nmap))
    left.append(_section_list("Data Flow Â· Read fields", df.get("read_fields", []), nmap, key="node_id"))
    left.append(_section_list("Data Flow Â· Written fields", df.get("written_fields", []), nmap, key="node_id"))
    left.append(_section_list("Same Class", pack.get("same_class", []), nmap, key="node_id"))
    left.append(_section_list("Same File", pack.get("same_file", []), nmap, key="node_id"))

    role_order = {
        "focus": 0, "seed": 1, "caller": 2, "callee": 3,
        "shared_field": 4, "shared_field_reader": 5, "shared_field_writer": 6,
        "same_class_member": 7, "same_file_helper": 8
    }
    nodes = pack.get("nodes", [])
    def sort_key(n):
        r = n.get("role") or ""
        return (role_order.get(r, 99), n.get("type",""), n.get("node_id",""))

    nodes_sorted = sorted(nodes, key=sort_key)
    main_cards = "\n".join(_node_card(n) for n in nodes_sorted)

    css = (Path(__file__).with_name("style.css")).read_text(encoding="utf-8")

    return f"""<!doctype html>
<html lang=\"en\">
<head>
<meta charset=\"utf-8\"/>
<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/>
<title>Graph-RAG Context Pack Preview</title>
<style>
{css}
</style>
</head>
<body>
<header>
  <div class=\"brand\">Graph-RAG Â· Context Pack Preview</div>
  <div class=\"hint\">Click items in the left panel to jump to code cards. Highlighted lines indicate focus spans.</div>
</header>
<div class=\"layout\">
  <aside class=\"sidebar\">
    {''.join(left)}
  </aside>
  <main class=\"main\">
    {main_cards}
  </main>
</div>
</body>
</html>
"""


def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("context_pack", type=str, help="path to context_pack.json")
    ap.add_argument("-o", "--out", type=str, default="context_preview.html")
    args = ap.parse_args()

    pack = json.loads(Path(args.context_pack).read_text(encoding="utf-8"))
    html_out = render(pack)
    Path(args.out).write_text(html_out, encoding="utf-8")
    print(f"âœ… Wrote: {args.out}")


if __name__ == "__main__":
    main()

==================== END FILE ====================


==================== FILE: demo_context_pack.py ====================
#!/usr/bin/env python3
"""
Demo: build Graph-RAG context pack for a Java repository.

Usage:
  python demo_context_pack.py --project /path/to/java/repo --query "refactor duplication in offer decision"

Outputs:
  - Prints a short summary
  - Saves context_pack.json in current directory
"""
from __future__ import annotations

import argparse
import json
import os
from pathlib import Path

from src.parser import JavaCodeParser
from src.graph_builder import CodeGraphBuilder
from src.vector_index import NodeVectorIndex
from src.context_engine import GraphRAGContextEngine


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("--project", required=True, help="Java project root directory")
    ap.add_argument("--query", required=True, help="Natural language query OR exact node id")
    ap.add_argument("--seed_top_k", type=int, default=5)
    ap.add_argument("--hops", type=int, default=2)
    ap.add_argument("--max_nodes", type=int, default=30)
    ap.add_argument("--out", default="context_pack.json")
    args = ap.parse_args()

    project_root = args.project
    if not os.path.isdir(project_root):
        raise SystemExit(f"Project path not found: {project_root}")

    print(f"ðŸ”Ž Parsing project: {project_root}")
    parser = JavaCodeParser()
    data = parser.parse_project(project_root)

    builder = CodeGraphBuilder()
    builder.build_from_parsed_data(data)
    graph = builder.get_graph()

    print("ðŸ§  Building vector index (TF-IDF)...")
    vindex = NodeVectorIndex()
    vindex.build_from_graph(graph)

    engine = GraphRAGContextEngine(graph, vindex)

    print(f"ðŸ§© Query: {args.query}")
    pack = engine.query(
        args.query,
        seed_top_k=args.seed_top_k,
        hops=args.hops,
        max_nodes=args.max_nodes,
    )

    # Print a small human-friendly summary
    print("\n================= CONTEXT PACK SUMMARY =================")
    print(f"Focus: {pack.get('focus_node')}")
    print("Seeds:")
    for s in pack.get("seed_nodes", []):
        print(f"  - {s['node_id']} (score={s['score']:.3f})")
    print(f"Selected nodes: {pack['stats']['selected_nodes']}, edges: {pack['stats']['selected_edges']}")

    # Show top 5 nodes with why
    nodes = pack.get("nodes", [])
    print("\nTop nodes (first 5):")
    for n in nodes[:5]:
        why = "; ".join(n.get("why", [])[:2])
        loc = f"{n.get('file_path')}:{n.get('start_line')}-{n.get('end_line')}" if n.get("file_path") else ""
        print(f"- [{n.get('type')}] {n.get('node_id')}  {loc}")
        if n.get("signature"):
            print(f"    sig: {n.get('signature')[:120]}")
        if why:
            print(f"    why: {why}")

    out_path = Path(args.out)
    out_path.write_text(json.dumps(pack, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"\nâœ… Saved: {out_path.resolve()}")


if __name__ == "__main__":
    main()

==================== END FILE ====================


==================== FILE: demo_refactor_agent.py ====================
#!/usr/bin/env python3
from __future__ import annotations

import argparse
import json
import os
import re
from pathlib import Path

from src.agent.agent import AgentConfig, RefactoringAgent
from src.agent.llm import OpenAICompatibleChatClient, OpenAICompatibleConfig, DummyEchoLLM

def load_dotenv(dotenv_path: Path, *, override: bool = False) -> None:
    """
    Minimal .env loader (no extra dependency).
    - Supports KEY=VALUE
    - Ignores blank lines / comments (# ...)
    - Strips surrounding quotes
    - Expands ${VAR} using current env
    - By default does NOT override existing env vars (override=False)
    """
    if not dotenv_path.exists():
        return

    text = dotenv_path.read_text(encoding="utf-8", errors="replace")
    for raw in text.splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if line.lower().startswith("export "):
            line = line[7:].strip()
        if "=" not in line:
            continue

        key, val = line.split("=", 1)
        key = key.strip()
        val = val.strip()

        if not key:
            continue

        # strip quotes
        if len(val) >= 2 and ((val[0] == val[-1] == '"') or (val[0] == val[-1] == "'")):
            val = val[1:-1]

        # allow \n in env values
        val = val.replace("\\n", "\n")

        # expand ${VAR}
        val = re.sub(r"\$\{([^}]+)\}", lambda m: os.environ.get(m.group(1), ""), val)

        if override or key not in os.environ:
            os.environ[key] = val


def env_bool(key: str, default: bool = False) -> bool:
    v = os.environ.get(key)
    if v is None:
        return default
    return v.strip().lower() in ("1", "true", "yes", "y", "on")


def env_list(key: str) -> list[str]:
    """
    Reads a list from env. Split by ';' or newline.
    """
    v = (os.environ.get(key) or "").strip()
    if not v:
        return []
    parts = re.split(r"[;\n]+", v)
    return [p.strip() for p in parts if p.strip()]


def require(value: str | None, name: str, ap: argparse.ArgumentParser, hint: str) -> str:
    if value is None or str(value).strip() == "":
        ap.error(f"Missing {name}. {hint}")
    return str(value)


def load_context_pack(path: Path) -> dict:
    return json.loads(path.read_text(encoding="utf-8"))


def main():
    ap = argparse.ArgumentParser()

    # å…ˆè®©ä½ å¯ä»¥æŒ‡å®š .env æ–‡ä»¶ä½ç½®ï¼ˆé»˜è®¤å½“å‰ç›®å½• .envï¼‰
    ap.add_argument("--env", default=".env", help="Path to .env file. Default: .env in current directory.")

    # CLI ä¸å† requiredï¼Œå…¨éƒ¨å¯ä»Ž .env è¯»å–ï¼›CLI ä»å¯è¦†ç›–
    ap.add_argument("--project", default=None, help="Project repo root. Fallback: REFAC_PROJECT in .env")
    ap.add_argument("--context-pack", default=None, help="Path to context_pack.json. Fallback: REFAC_CONTEXT_PACK")
    ap.add_argument("--request", default=None, help="Refactoring request. Fallback: REFAC_REQUEST")

    ap.add_argument("--max-iters", type=int, default=None, help="Fallback: REFAC_MAX_ITERS (default 3)")

    ap.add_argument("--model", default=None, help="Fallback: OPENAI_MODEL (default gpt-4.1-mini)")
    ap.add_argument("--base-url", default=None, help="Fallback: OPENAI_BASE_URL (default https://api.openai.com)")
    ap.add_argument("--api-key", default=None, help="Fallback: OPENAI_API_KEY")

    ap.add_argument("--use-docker", action="store_true",
                    help="Run verification in docker. Fallback: REFAC_USE_DOCKER=true/false")
    ap.add_argument("--docker-image", default=None, help="Fallback: REFAC_DOCKER_IMAGE")

    ap.add_argument("--verify-cmd", action="append", default=None,
                    help="Repeatable verification cmd. Fallback: REFAC_VERIFY_CMDS separated by ';' or newlines")
    ap.add_argument("--allow-cmd", action="append", default=None,
                    help="Extend whitelist. Fallback: REFAC_ALLOW_CMDS separated by ';' or newlines")

    ap.add_argument("--dry-llm", action="store_true",
                    help="Do not call real LLM. Fallback: REFAC_DRY_LLM=true/false")

    ap.add_argument("--print-effective-config", action="store_true",
                    help="Print resolved config (after .env) and exit.")

    args = ap.parse_args()

    # åŠ è½½ .envï¼ˆä¸è¦†ç›–å·²å­˜åœ¨çš„ç³»ç»ŸçŽ¯å¢ƒå˜é‡ï¼‰
    dotenv_path = Path(args.env).expanduser().resolve()
    load_dotenv(dotenv_path, override=False)

    # ä¼˜å…ˆçº§ï¼šCLI > .envï¼ˆos.environï¼‰> é»˜è®¤å€¼
    project = args.project or os.environ.get("REFAC_PROJECT")
    context_pack = args.context_pack or os.environ.get("REFAC_CONTEXT_PACK")
    request = args.request or os.environ.get("REFAC_REQUEST")

    max_iters = args.max_iters if args.max_iters is not None else int(os.environ.get("REFAC_MAX_ITERS", "3"))

    model = args.model or os.environ.get("OPENAI_MODEL", "gpt-4.1-mini")
    base_url = args.base_url or os.environ.get("OPENAI_BASE_URL", "https://api.openai.com")
    api_key = args.api_key or os.environ.get("OPENAI_API_KEY", "")

    # boolï¼šCLI åªè´Ÿè´£æŠŠ true æ‰“å¼€ï¼›å¦åˆ™èµ° env
    use_docker = args.use_docker or env_bool("REFAC_USE_DOCKER", default=False)
    docker_image = args.docker_image or os.environ.get("REFAC_DOCKER_IMAGE", "python:3.10-slim")

    verify_cmds = (args.verify_cmd or []) if args.verify_cmd else env_list("REFAC_VERIFY_CMDS")
    allow_cmds = (args.allow_cmd or []) if args.allow_cmd else env_list("REFAC_ALLOW_CMDS")

    dry_llm = args.dry_llm or env_bool("REFAC_DRY_LLM", default=False)

    # å¿…å¡«é¡¹ï¼šCLI æˆ– env è‡³å°‘è¦æœ‰ä¸€ä¸ª
    project = require(project, "--project / REFAC_PROJECT", ap, "Set it in .env or pass --project.")
    context_pack = require(context_pack, "--context-pack / REFAC_CONTEXT_PACK", ap, "Set it in .env or pass --context-pack.")
    request = require(request, "--request / REFAC_REQUEST", ap, "Set it in .env or pass --request.")

    if args.print_effective_config:
        print(json.dumps({
            "env_file": str(dotenv_path),
            "project": project,
            "context_pack": context_pack,
            "request": request,
            "max_iters": max_iters,
            "model": model,
            "base_url": base_url,
            "api_key_set": bool(api_key),
            "use_docker": use_docker,
            "docker_image": docker_image,
            "verify_cmds": verify_cmds,
            "allow_cmds": allow_cmds,
            "dry_llm": dry_llm,
        }, ensure_ascii=False, indent=2))
        return

    project_dir = Path(project).resolve()
    context_pack_path = Path(context_pack).resolve()
    pack = load_context_pack(context_pack_path)

    if dry_llm:
        llm = DummyEchoLLM()
    else:
        llm = OpenAICompatibleChatClient(OpenAICompatibleConfig(
            base_url=base_url,
            api_key=api_key or None,
            model=model,
        ))

    cfg = AgentConfig(
        project_dir=project_dir,
        max_iters=max_iters,
        use_docker=use_docker,
        docker_image=docker_image,
        default_verify_cmds=verify_cmds if verify_cmds else None,
        allowed_commands=None,
    )

    if allow_cmds:
        # æ³¨æ„ï¼šåªæœ‰ verify/tool ç”¨åˆ°çš„ base command æ‰éœ€è¦åŠ ç™½åå•
        cfg.allowed_commands = list(set(allow_cmds + [
            "rg", "grep", "find", "ls", "cat", "sed",
            "python", "python3",
            "mvn", "./mvnw",
            "gradle", "./gradlew",
            "npm", "pnpm", "yarn",
            "pytest",
            "git",
            "javac", "java",
            "black", "ruff", "prettier", "eslint", "google-java-format",
        ]))

    agent = RefactoringAgent(llm=llm, cfg=cfg)
    summary = agent.run(request=request, context_pack=pack)
    print(json.dumps(summary, ensure_ascii=False, indent=2))


if __name__ == "__main__":
    main()

==================== END FILE ====================


==================== FILE: merge_refactor_logs.py ====================
import os
import json
from pathlib import Path

# ================= é…ç½®åŒºåŸŸ =================
# ä½ çš„ bench_out è¾“å‡ºç›®å½•åç§°
BENCH_OUT_DIR = "bench_out"
# æœ€ç»ˆç”Ÿæˆçš„åˆå¹¶æ–‡ä»¶åç§°
OUTPUT_FILE = "merged_refactor_debug_log.txt"
# ===========================================

def read_file_content(file_path):
    """è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå¤„ç†ç¼–ç é—®é¢˜"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                return f.read()
        except Exception:
            return "[Binary or Unreadable File]"
    except FileNotFoundError:
        return "[File Not Found]"

def write_separator(f, title, char="="):
    """å†™å…¥æ¸…æ™°çš„åˆ†éš”ç¬¦"""
    f.write(f"\n{char*50}\n")
    f.write(f" {title}\n")
    f.write(f"{char*50}\n\n")

def main():
    root_path = Path(os.getcwd())
    bench_path = root_path / BENCH_OUT_DIR
    
    if not bench_path.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {bench_path}")
        return

    print(f"ðŸ“‚ å¼€å§‹æ‰«æ {bench_path}...")
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:
        outfile.write(f"Refactoring Agent Debug Log\nGenerated Time: {os.times()}\n\n")

        # éåŽ† bench_out ä¸‹çš„æ‰€æœ‰æ¨¡å¼ (ä¾‹å¦‚ graph_rag, vector_only)
        for mode_dir in bench_path.iterdir():
            if not mode_dir.is_dir() or mode_dir.name.startswith("."):
                continue
            
            # éåŽ†æ¨¡å¼ä¸‹çš„å…·ä½“ä»»åŠ¡ (ä¾‹å¦‚ consolidate_base_score_computation)
            for task_dir in mode_dir.iterdir():
                if not task_dir.is_dir() or task_dir.name.startswith("."):
                    continue

                task_name = task_dir.name
                mode_name = mode_dir.name
                
                print(f"  Processing Task: [{mode_name}] {task_name}")
                
                write_separator(outfile, f"TASK: {task_name} (Mode: {mode_name})", char="#")

                # 1. è¯»å– Bench Out ç›®å½•ä¸‹çš„æ¦‚è§ˆæ–‡ä»¶
                bench_files = ["agent_summary.json", "run_record.json", "context_coverage.json"]
                artifacts_path = None
                
                for filename in bench_files:
                    file_path = task_dir / filename
                    if file_path.exists():
                        content = read_file_content(file_path)
                        outfile.write(f"--- [Bench File] {filename} ---\n")
                        outfile.write(content + "\n\n")
                        
                        # å¦‚æžœæ˜¯ summaryï¼Œå°è¯•æå– artifacts è·¯å¾„
                        if filename == "agent_summary.json":
                            try:
                                data = json.loads(content)
                                if "artifacts_dir" in data:
                                    raw_path = data["artifacts_dir"]
                                    # å¤„ç†ç»å¯¹è·¯å¾„ï¼Œå¦‚æžœåœ¨è¿™å°æœºå™¨ä¸Šè·‘ï¼Œç»å¯¹è·¯å¾„é€šå¸¸æ˜¯æœ‰æ•ˆçš„
                                    # å¦‚æžœç»å¯¹è·¯å¾„æ— æ•ˆï¼Œå°è¯•å°†å…¶è§†ä¸ºç›¸å¯¹è·¯å¾„æˆ–å¯»æ‰¾é¡¹ç›®å†…çš„å¯¹åº”è·¯å¾„
                                    artifacts_path = Path(raw_path)
                                    if not artifacts_path.exists():
                                        # å°è¯•ä¸€ç§å›žé€€æœºåˆ¶ï¼šå‡è®¾ artifacts åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ .refactor_agent_runs ä¸‹
                                        # æå–è·¯å¾„ä¸­ .refactor_agent_runs ä¹‹åŽçš„éƒ¨åˆ†
                                        parts = raw_path.split(".refactor_agent_runs")
                                        if len(parts) > 1:
                                            artifacts_path = root_path / ".refactor_agent_runs" / parts[1].strip(os.sep)
                            except Exception as e:
                                print(f"    âš ï¸ è§£æž artifacts_dir å¤±è´¥: {e}")

                # 2. è¯»å– Artifacts ç›®å½•ä¸‹çš„è¯¦ç»†è¿‡ç¨‹æ–‡ä»¶
                if artifacts_path and artifacts_path.exists():
                    outfile.write(f"--- [Artifacts Dir] {artifacts_path} ---\n\n")
                    
                    # èŽ·å–è¯¥ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶å¹¶æŽ’åº
                    # æŽ’åºå¾ˆé‡è¦ï¼Œä¸ºäº†è®© step1, step2 æŒ‰é¡ºåºæ˜¾ç¤º
                    artifact_files = sorted([f for f in artifacts_path.iterdir() if f.is_file()])
                    
                    # å®šä¹‰æˆ‘ä»¬å…³å¿ƒçš„æ–‡ä»¶ä¼˜å…ˆçº§ï¼Œç¡®ä¿é‡è¦çš„å…ˆå±•ç¤º
                    # æ¯”å¦‚ plan.json æœ€å…ˆï¼Œsummary.json æœ€åŽï¼Œä¸­é—´æ˜¯æ­¥éª¤
                    def sort_key(f):
                        name = f.name
                        if "plan.json" in name: return 0
                        if "tool_outputs" in name: return 1
                        if "step" in name: return 2
                        if "summary.json" in name: return 99
                        return 10
                    
                    artifact_files.sort(key=sort_key)

                    for art_file in artifact_files:
                        # è·³è¿‡ä¸€äº›ä¸éœ€è¦çš„äºŒè¿›åˆ¶æ–‡ä»¶æˆ–è¿‡å¤§çš„æ–‡ä»¶
                        if art_file.suffix not in ['.json', '.txt', '.diff', '.log', '.md', '.py', '.java']:
                            continue
                        
                        # è¯»å–å†…å®¹
                        content = read_file_content(art_file)
                        
                        outfile.write(f"ðŸ“„ FILE: {art_file.name}\n")
                        outfile.write("-" * 20 + "\n")
                        outfile.write(content)
                        outfile.write("\n" + "-" * 20 + "\n\n")
                else:
                    outfile.write(f"âš ï¸ Warning: Artifacts directory not found or inaccessible: {artifacts_path}\n")

    print(f"\nâœ… åˆå¹¶å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³: {Path(OUTPUT_FILE).absolute()}")

if __name__ == "__main__":
    main()
==================== END FILE ====================


==================== FILE: bench_out/merge_refactor_logs.py ====================
import os
import json
from pathlib import Path

# ================= é…ç½®åŒºåŸŸ =================
# ä½ çš„ bench_out è¾“å‡ºç›®å½•åç§°
BENCH_OUT_DIR = "bench_out"
# æœ€ç»ˆç”Ÿæˆçš„åˆå¹¶æ–‡ä»¶åç§°
OUTPUT_FILE = "merged_refactor_debug_log.txt"
# ===========================================

def read_file_content(file_path):
    """è¯»å–æ–‡ä»¶å†…å®¹ï¼Œå¤„ç†ç¼–ç é—®é¢˜"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        try:
            with open(file_path, 'r', encoding='latin-1') as f:
                return f.read()
        except Exception:
            return "[Binary or Unreadable File]"
    except FileNotFoundError:
        return "[File Not Found]"

def write_separator(f, title, char="="):
    """å†™å…¥æ¸…æ™°çš„åˆ†éš”ç¬¦"""
    f.write(f"\n{char*50}\n")
    f.write(f" {title}\n")
    f.write(f"{char*50}\n\n")

def main():
    root_path = Path(os.getcwd())
    bench_path = root_path / BENCH_OUT_DIR
    
    if not bench_path.exists():
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {bench_path}")
        return

    print(f"ðŸ“‚ å¼€å§‹æ‰«æ {bench_path}...")
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:
        outfile.write(f"Refactoring Agent Debug Log\nGenerated Time: {os.times()}\n\n")

        # éåŽ† bench_out ä¸‹çš„æ‰€æœ‰æ¨¡å¼ (ä¾‹å¦‚ graph_rag, vector_only)
        for mode_dir in bench_path.iterdir():
            if not mode_dir.is_dir() or mode_dir.name.startswith("."):
                continue
            
            # éåŽ†æ¨¡å¼ä¸‹çš„å…·ä½“ä»»åŠ¡ (ä¾‹å¦‚ consolidate_base_score_computation)
            for task_dir in mode_dir.iterdir():
                if not task_dir.is_dir() or task_dir.name.startswith("."):
                    continue

                task_name = task_dir.name
                mode_name = mode_dir.name
                
                print(f"  Processing Task: [{mode_name}] {task_name}")
                
                write_separator(outfile, f"TASK: {task_name} (Mode: {mode_name})", char="#")

                # 1. è¯»å– Bench Out ç›®å½•ä¸‹çš„æ¦‚è§ˆæ–‡ä»¶
                bench_files = ["agent_summary.json", "run_record.json", "context_coverage.json"]
                artifacts_path = None
                
                for filename in bench_files:
                    file_path = task_dir / filename
                    if file_path.exists():
                        content = read_file_content(file_path)
                        outfile.write(f"--- [Bench File] {filename} ---\n")
                        outfile.write(content + "\n\n")
                        
                        # å¦‚æžœæ˜¯ summaryï¼Œå°è¯•æå– artifacts è·¯å¾„
                        if filename == "agent_summary.json":
                            try:
                                data = json.loads(content)
                                if "artifacts_dir" in data:
                                    raw_path = data["artifacts_dir"]
                                    # å¤„ç†ç»å¯¹è·¯å¾„ï¼Œå¦‚æžœåœ¨è¿™å°æœºå™¨ä¸Šè·‘ï¼Œç»å¯¹è·¯å¾„é€šå¸¸æ˜¯æœ‰æ•ˆçš„
                                    # å¦‚æžœç»å¯¹è·¯å¾„æ— æ•ˆï¼Œå°è¯•å°†å…¶è§†ä¸ºç›¸å¯¹è·¯å¾„æˆ–å¯»æ‰¾é¡¹ç›®å†…çš„å¯¹åº”è·¯å¾„
                                    artifacts_path = Path(raw_path)
                                    if not artifacts_path.exists():
                                        # å°è¯•ä¸€ç§å›žé€€æœºåˆ¶ï¼šå‡è®¾ artifacts åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ .refactor_agent_runs ä¸‹
                                        # æå–è·¯å¾„ä¸­ .refactor_agent_runs ä¹‹åŽçš„éƒ¨åˆ†
                                        parts = raw_path.split(".refactor_agent_runs")
                                        if len(parts) > 1:
                                            artifacts_path = root_path / ".refactor_agent_runs" / parts[1].strip(os.sep)
                            except Exception as e:
                                print(f"    âš ï¸ è§£æž artifacts_dir å¤±è´¥: {e}")

                # 2. è¯»å– Artifacts ç›®å½•ä¸‹çš„è¯¦ç»†è¿‡ç¨‹æ–‡ä»¶
                if artifacts_path and artifacts_path.exists():
                    outfile.write(f"--- [Artifacts Dir] {artifacts_path} ---\n\n")
                    
                    # èŽ·å–è¯¥ç›®å½•ä¸‹æ‰€æœ‰æ–‡ä»¶å¹¶æŽ’åº
                    # æŽ’åºå¾ˆé‡è¦ï¼Œä¸ºäº†è®© step1, step2 æŒ‰é¡ºåºæ˜¾ç¤º
                    artifact_files = sorted([f for f in artifacts_path.iterdir() if f.is_file()])
                    
                    # å®šä¹‰æˆ‘ä»¬å…³å¿ƒçš„æ–‡ä»¶ä¼˜å…ˆçº§ï¼Œç¡®ä¿é‡è¦çš„å…ˆå±•ç¤º
                    # æ¯”å¦‚ plan.json æœ€å…ˆï¼Œsummary.json æœ€åŽï¼Œä¸­é—´æ˜¯æ­¥éª¤
                    def sort_key(f):
                        name = f.name
                        if "plan.json" in name: return 0
                        if "tool_outputs" in name: return 1
                        if "step" in name: return 2
                        if "summary.json" in name: return 99
                        return 10
                    
                    artifact_files.sort(key=sort_key)

                    for art_file in artifact_files:
                        # è·³è¿‡ä¸€äº›ä¸éœ€è¦çš„äºŒè¿›åˆ¶æ–‡ä»¶æˆ–è¿‡å¤§çš„æ–‡ä»¶
                        if art_file.suffix not in ['.json', '.txt', '.diff', '.log', '.md', '.py', '.java']:
                            continue
                        
                        # è¯»å–å†…å®¹
                        content = read_file_content(art_file)
                        
                        outfile.write(f"ðŸ“„ FILE: {art_file.name}\n")
                        outfile.write("-" * 20 + "\n")
                        outfile.write(content)
                        outfile.write("\n" + "-" * 20 + "\n\n")
                else:
                    outfile.write(f"âš ï¸ Warning: Artifacts directory not found or inaccessible: {artifacts_path}\n")

    print(f"\nâœ… åˆå¹¶å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜è‡³: {Path(OUTPUT_FILE).absolute()}")

if __name__ == "__main__":
    main()
==================== END FILE ====================


==================== FILE: cua/cua_chrome/cua_chrome/core/policy_merge.py ====================
"""
merge chrome enterprise policies copied under $CHROMIUM_POLICY_DIR
creates a single merged json file with original backups under .policy_merge
http://go/docs-link/cua-chrome-policy-merge
"""

import glob
import json
import re
import sys
import typing
from pathlib import Path

AnyDict = dict[str, typing.Any]

OUTPUT_FILENAME = "000_policy_merge.json"
"""
The name of the output file that will contain the merged policies.
We specifically allow overwriting this file so you can merge policies
in a second pass, e.g. in response to a policy change.
"""


def main(*, path: Path, merge_keys: list[str]) -> None:
    print(f"{path=}")
    print(f"{merge_keys=}")

    path = path.expanduser()
    merged_path = Path(path) / OUTPUT_FILENAME

    if not path.exists():
        raise ValueError(f"{path=} does not exist")

    # ensure the .policy_merge directory exists
    backup_dir = path / ".policy_merge"
    backup_dir.mkdir(parents=True, exist_ok=True)

    # ensure glob of filename is sorted as one would expect
    file_list = list(glob.glob(f"{str(path)}/*"))
    file_list.sort(key=natural_sort_key)

    policy_list: list[AnyDict] = []
    for filename in file_list:
        print(f"  {filename}")
        file_path = Path(filename)

        with open(file_path, "r") as f:
            policy_list.append(json.load(f))

        # move file_path to nested .policy_merge dir
        new_file_path = backup_dir / file_path.name
        file_path.rename(new_file_path)

    merged: AnyDict = dict()
    merge_keys_set = set(merge_keys)
    for policy in policy_list:
        # move policies to nested .policy_merge dir
        merged = deep_merge(merged, policy, merge_keys_set=merge_keys_set)

    # write merged policy to path
    with open(merged_path, "w") as f:
        json.dump(merged, f, indent=2)

    if not merged_path.exists():
        raise ValueError(f"{merged_path} must exist")


def deep_merge(a: AnyDict, b: AnyDict, *, merge_keys_set: set[str]) -> AnyDict:
    result = a.copy()
    for key, value in b.items():
        # recurse if both values are dictionaries
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            if key in merge_keys_set:
                result[key] = deep_merge(result[key], value, merge_keys_set=merge_keys_set)
            else:
                result[key] = value
        elif key in result and isinstance(result[key], list) and isinstance(value, list):
            if key in merge_keys_set:
                for item in value:
                    if item not in result[key]:
                        result[key].append(item)
            else:
                result[key] = value
        else:
            result[key] = value
    return result


# splits the string into numeric and non-numeric parts for sorting
def natural_sort_key(item: typing.Any) -> list[int | str | float]:
    # ensure None keys always sort last
    if item is None:
        return [float("inf")]

    item_str = str(item)

    return [
        # convert to int if digit
        int(text) if text.isdigit() else text
        for text in re.split(RE_DIGIT, item_str)
    ]


RE_DIGIT = re.compile(r"(\d+)")


if __name__ == "__main__":
    [command, *arg_list] = sys.argv

    arg_separator = "="
    path = None
    merge_keys = None
    for arg in arg_list:
        if arg_separator in arg:
            [key, value] = arg.split(arg_separator)
            if not value:
                raise ValueError(f"{key} missing value")
            if key == "path":
                path = Path(value)
            elif key == "merge_keys":
                merge_keys = value.split(",")

    if path is None:
        raise ValueError("path is required")

    if merge_keys is None:
        raise ValueError("merge_keys is required")

    main(path=path, merge_keys=merge_keys)

==================== END FILE ====================


==================== FILE: src/vector_index.py ====================
"""
Vector index for code graph nodes.

For the demo we implement TF-IDF (offline-friendly).
Later you can swap to embedding-based retrieval (OpenAI / local embedding models)
without changing the Graph-RAG interface.
"""
from __future__ import annotations

from dataclasses import dataclass
from typing import Dict, Iterable, List, Optional, Sequence, Tuple

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer

from .utils import normalize_code_text


@dataclass
class ScoredNode:
    node_id: str
    score: float


class NodeVectorIndex:
    def __init__(self) -> None:
        self.vectorizer: Optional[TfidfVectorizer] = None
        self.node_ids: List[str] = []
        self.matrix = None  # scipy sparse matrix

    @staticmethod
    def _node_to_text(node_id: str, attrs: Dict) -> str:
        parts: List[str] = []
        ntype = attrs.get("type", "Unknown")
        parts.append(f"{ntype} {node_id}")
        if attrs.get("name"):
            parts.append(str(attrs["name"]))
        if attrs.get("signature"):
            parts.append(str(attrs["signature"]))
        if attrs.get("docstring"):
            parts.append(str(attrs["docstring"]))
        # Light metadata can help retrieval
        if attrs.get("class"):
            parts.append(f"class {attrs['class']}")
        if attrs.get("file_path"):
            parts.append(f"file {attrs['file_path']}")
        return normalize_code_text(" ".join(parts))

    def build_from_graph(self, graph) -> None:
        texts: List[str] = []
        node_ids: List[str] = []
        for node_id, attrs in graph.nodes(data=True):
            node_ids.append(node_id)
            texts.append(self._node_to_text(node_id, attrs))

        self.node_ids = node_ids
        self.vectorizer = TfidfVectorizer(
            ngram_range=(1, 2),
            max_features=50000,
            token_pattern=r"(?u)\b\w+\b",
        )
        self.matrix = self.vectorizer.fit_transform(texts)

    def search(self, query: str, top_k: int = 5, min_score: float = 0.0) -> List[ScoredNode]:
        if not self.vectorizer or self.matrix is None:
            raise RuntimeError("Vector index is not built. Call build_from_graph() first.")

        q = normalize_code_text(query)
        q_vec = self.vectorizer.transform([q])

        # cosine similarity for TF-IDF vectors: dot product is enough because vectors are L2-normalized by default.
        scores = (self.matrix @ q_vec.T).toarray().ravel()
        if scores.size == 0:
            return []

        top_idx = np.argsort(scores)[::-1][: top_k * 2]  # take a bit more then filter
        out: List[ScoredNode] = []
        for idx in top_idx:
            s = float(scores[idx])
            if s <= min_score:
                continue
            out.append(ScoredNode(node_id=self.node_ids[idx], score=s))
            if len(out) >= top_k:
                break
        return out

==================== END FILE ====================


==================== FILE: src/retriever.py ====================
"""
Backward-compatible retriever.

- `retrieve_context(node_id)` keeps your old behavior (in/out edges)
- `retrieve_context_pack(query)` returns the new structured Graph-RAG Context Pack
"""
from __future__ import annotations

from typing import Any, Dict, Optional

import networkx as nx

from .vector_index import NodeVectorIndex
from .context_engine import GraphRAGContextEngine


class GraphRetriever:
    def __init__(self, graph: nx.DiGraph, vector_index: Optional[NodeVectorIndex] = None):
        self.graph = graph
        self.vector_index = vector_index
        self._engine: Optional[GraphRAGContextEngine] = None

        if vector_index is not None:
            self._engine = GraphRAGContextEngine(graph, vector_index)

    def retrieve_context(self, query_node_id: str, hops: int = 1) -> Dict[str, Any]:
        """
        Old-style graph retrieval: dependencies (out edges) + usages (in edges).
        """
        if query_node_id not in self.graph:
            return {"error": f"Node not found: {query_node_id}"}

        dependencies = []
        for neighbor in self.graph.successors(query_node_id):
            edge_data = self.graph.get_edge_data(query_node_id, neighbor) or {}
            dependencies.append(f"  -> {edge_data.get('relation')} -> {neighbor}")

        usages = []
        for neighbor in self.graph.predecessors(query_node_id):
            edge_data = self.graph.get_edge_data(neighbor, query_node_id) or {}
            usages.append(f"  <- {edge_data.get('relation')} <- {neighbor}")

        return {
            "focus_node": query_node_id,
            "dependencies": dependencies,
            "usages": usages,
        }

    def retrieve_context_pack(self, query: str, **kwargs) -> Dict:
        """
        New Graph-RAG retrieval: vector seeds + graph expansion + structured Context Pack.

        kwargs are forwarded to GraphRAGContextEngine.query().
        """
        if not self._engine:
            if not self.vector_index:
                raise RuntimeError("Vector index not provided. Build NodeVectorIndex and pass it into GraphRetriever.")
            self._engine = GraphRAGContextEngine(self.graph, self.vector_index)
        return self._engine.query(query, **kwargs)

==================== END FILE ====================


==================== FILE: src/__init__.py ====================
# Graph-RAG Context Engine demo package

==================== END FILE ====================


==================== FILE: src/prompts.py ====================
from __future__ import annotations

import json
from typing import Any, Dict, List


def _trim(s: str, max_chars: int) -> str:
    if s is None:
        return ""
    s = str(s)
    return s if len(s) <= max_chars else (s[: max_chars - 3] + "...")


def context_pack_to_prompt(pack: Dict[str, Any], *, max_nodes: int = 18, max_snippet_chars: int = 2200) -> str:
    """
    Convert context_pack.json into a compact, LLM-friendly text block.
    """
    query = pack.get("query", "")
    focus = (pack.get("focus") or {}).get("node_id") or pack.get("focus_node") or ""
    seed_nodes = pack.get("seed_nodes", [])

    nodes = pack.get("nodes", [])
    def node_key(n):
        role = n.get("role", "")
        order = {"focus": 0, "seed": 1, "caller": 2, "callee": 3}.get(role, 9)
        return (order, n.get("type",""), n.get("node_id",""))

    nodes_sorted = sorted(nodes, key=node_key)[:max_nodes]

    out: List[str] = []
    out.append(f"Retrieval query: {query}")
    out.append(f"Focus node: {focus}")
    if seed_nodes:
        out.append("Seed nodes (vector search):")
        for s in seed_nodes[:8]:
            out.append(f"  - {s.get('node_id')} (score={s.get('score')})")
    out.append("")
    out.append("=== Context Nodes (with code excerpts) ===")
    for n in nodes_sorted:
        nid = n.get("node_id")
        typ = n.get("type")
        fp = n.get("file_path")
        sl = n.get("start_line")
        el = n.get("end_line")
        sig = _trim(n.get("signature",""), 240)
        roles = n.get("roles", [])
        why = n.get("why", [])
        snippet = _trim(n.get("snippet",""), max_snippet_chars)
        out.append(f"\n[{typ}] {nid}")
        if fp:
            out.append(f"Location: {fp}:{sl}-{el}")
        if sig:
            out.append(f"Signature: {sig}")
        if roles:
            out.append(f"Roles: {', '.join(map(str, roles))}")
        if why:
            why_short = [str(x) for x in why][:5]
            out.append("Why selected:")
            for w in why_short:
                out.append(f"  - {w}")
        if snippet:
            out.append("Code:")
            out.append(snippet)
    out.append("\n=== End Context ===")
    return "\n".join(out)


PLAN_SYSTEM = """You are a senior software engineer designing a safe automated refactoring plan.
You must be concise, risk-aware, and verification-driven.
Return STRICT JSON only (no markdown, no commentary outside JSON)."""

PLAN_USER_TEMPLATE = """Given the user request and the provided context pack, propose a refactoring plan.

Requirements:
- The goal is behavior-preserving refactoring.
- Only modify files that are necessary.
- Include a verification plan (commands) that can run in a sandbox (no shell operators like &&, |, >).
- Include risk notes.
- Optional: request additional information using tool_requests.
- IMPORTANT: All paths must be repo-root-relative, like "src/main/java/...". Do NOT prefix with "data/marketing-demo/".

Return JSON with this schema:
{{
  "objective": "...",
  "assumptions": ["..."],
  "steps": ["..."],
  "files_to_change": [{{"file_path":"...", "why":"...", "risk":"low|medium|high"}}],
  "verification": [{{"name":"...", "cmd":"..."}}],
  "tool_requests": [{{"tool":"ripgrep", "pattern":"...", "path":"..."}}]
}}

User request:
{request}

Context pack:
{context}
"""


EDIT_SYSTEM = """You are a senior software engineer.
You MUST output ONLY edit instructions using either Search/Replace blocks (preferred) or Full Rewrite blocks.
No markdown. No explanation. No code fences.

FORMAT (Search/Replace blocks - preferred):
FILE: <repo-relative-path>
<<<<<<< SEARCH
<exact text copied from the current file>
=======
<replacement text>
>>>>>>> REPLACE

You may include multiple SEARCH/REPLACE blocks under the same FILE.

FORMAT (Full Rewrite - allowed for small files):
FILE: <repo-relative-path>
<<<<<<< REWRITE
<entire new file content>
>>>>>>> REWRITE

RULES:
- Do NOT use "..." anywhere. Do NOT omit code.
- Do NOT abbreviate file paths.
- For Search/Replace: the SEARCH text MUST match EXACTLY ONE occurrence in the current file.
- Keep changes minimal and behavior-preserving.
"""


EDIT_USER_TEMPLATE = """Task: {objective}

Refactoring plan (JSON):
{plan_json}

Context pack with code excerpts:
{context}

IMPORTANT:
- Use file paths relative to the repo root (e.g., "src/main/java/..."). Do NOT prefix with "data/marketing-demo/".
- Output MUST be ONLY edit instructions (no commentary).
- Prefer Search/Replace blocks (stable). Use Full Rewrite only when necessary.
- Do NOT use "..." anywhere; do NOT shorten paths or code.

If the prompt includes a section named "EXACT REPO FILE CONTENTS (authoritative)", you MUST use that as the source of truth.

Return an UPDATED FULL set of edit instructions that should pass verification.
Return ONLY the edit instructions.
"""


REPAIR_SYSTEM = """You are a senior software engineer.
You MUST output ONLY edit instructions using either Search/Replace blocks (preferred) or Full Rewrite blocks.
No markdown. No explanation. No code fences.

You are given previous edit instructions and failure logs. Produce an UPDATED FULL set of instructions
(relative to the ORIGINAL codebase) that fixes the failures while keeping changes minimal and behavior-preserving.

FORMAT (Search/Replace blocks - preferred):
FILE: <repo-relative-path>
<<<<<<< SEARCH
<exact text copied from the current file>
=======
<replacement text>
>>>>>>> REPLACE

FORMAT (Full Rewrite - allowed for small files):
FILE: <repo-relative-path>
<<<<<<< REWRITE
<entire new file content>
>>>>>>> REWRITE

RULES:
- Do NOT use "..." anywhere. Do NOT omit code.
- Do NOT abbreviate file paths.
- For Search/Replace: the SEARCH text MUST match EXACTLY ONE occurrence in the current file.
- Keep changes minimal and behavior-preserving.
"""


REPAIR_USER_TEMPLATE = """Task: {objective}

Refactoring plan (JSON):
{plan_json}

Previous edit instructions (that failed to apply or failed verification):
{prev_patch}

Failure / verification outputs:
{verify_logs}

Context pack with code excerpts:
{context}

IMPORTANT:
- Use file paths relative to the repo root (e.g., "src/main/java/..."). Do NOT prefix with "data/marketing-demo/".
- Output MUST be ONLY edit instructions (no commentary).
- Prefer Search/Replace blocks (stable). Use Full Rewrite only when necessary.
- Do NOT use "..." anywhere; do NOT shorten paths or code.
- If apply failed because SEARCH did not match, adjust the SEARCH blocks to match the exact current file text (include more surrounding context).

If the prompt includes a section named "EXACT REPO FILE CONTENTS (authoritative)", you MUST use that as the source of truth.

Return an UPDATED FULL set of edit instructions that should pass verification.
Return ONLY the edit instructions.
"""

==================== END FILE ====================


==================== FILE: src/parser.py ====================
"""
Java repository parser for building a *traceable* code knowledge graph.

Output schema (dict):
{
  "classes": [ {...} ],
  "methods": [ {...} ],
  "fields": [ {...} ],
  "relationships": [ {"source": str, "target": str, "type": str, "file_path": str, "line": int} ]
}

Each method/field/class record includes traceability fields:
- file_path
- start_line, end_line
- signature
- docstring
"""
from __future__ import annotations

import os
from dataclasses import dataclass
import re
from typing import Dict, Iterable, List, Optional, Set, Tuple

from .utils import extract_comment_spans, find_attached_doc, safe_read_text

# Optional dependency: tree-sitter Java.
#
# In many environments tree-sitter may not be installed. For a demo / benchmark runner,
# we provide a regex-based fallback parser so the repo still runs out-of-the-box.
#
# When tree-sitter is available, we use it (more accurate relationships and spans).
try:
    import tree_sitter_java as tsjava
    from tree_sitter import Language, Parser
    _TREE_SITTER_OK = True
except Exception:  # pragma: no cover
    tsjava = None
    Language = None
    Parser = None
    _TREE_SITTER_OK = False


def _iter_java_files(project_root: str) -> Iterable[str]:
    ignore = {
        ".git",
        ".refactor_agent_runs",
        "target",
        "build",
        ".gradle",
        "node_modules",
        "__MACOSX",
        "__pycache__",
    }
    for root, dirs, files in os.walk(project_root):
        # Prune ignored dirs in-place
        dirs[:] = [d for d in dirs if d not in ignore]
        for fn in files:
            if fn.endswith(".java"):
                yield os.path.join(root, fn)


def _node_text(code_bytes: bytes, node) -> str:
    return code_bytes[node.start_byte:node.end_byte].decode("utf-8", errors="ignore")


def _node_lines(node) -> Tuple[int, int]:
    # tree-sitter rows are 0-indexed
    return int(node.start_point[0]) + 1, int(node.end_point[0]) + 1


def _compress_ws(s: str) -> str:
    return " ".join(s.replace("\n", " ").replace("\t", " ").split())


def _find_nodes_by_type(node, type_name: str) -> List:
    out = []
    stack = [node]
    while stack:
        n = stack.pop()
        if getattr(n, "type", None) == type_name:
            out.append(n)
        # children is a property in tree-sitter python
        stack.extend(getattr(n, "children", []) or [])
    return out


class JavaCodeParser:
    """
    Parse a Java project into a symbol table + relationships suitable for:
    - building a code knowledge graph (NetworkX)
    - building a vector index (TF-IDF/Embeddings)
    - later: powering an editing/refactoring agent

    Notes:
    - For a demo, we focus on class/method/field extraction and basic CALLS/READS.
    - Cross-class method resolution is intentionally conservative (best-effort).
    """

    def __init__(self, *, prefer_tree_sitter: bool = True) -> None:
        """Create a Java parser.

        prefer_tree_sitter:
          - True (default): use tree-sitter when available; otherwise fallback to regex.
          - False: always use regex fallback (useful for ultra-lightweight demos).
        """
        self.use_tree_sitter = bool(prefer_tree_sitter and _TREE_SITTER_OK)

        # Tree-sitter path (more accurate spans / relationships)
        if self.use_tree_sitter:
            # Build Language object (API differs across versions)
            try:
                self.JAVA_LANGUAGE = Language(tsjava.language())
            except Exception:
                # Some versions may already return a Language-like object
                self.JAVA_LANGUAGE = tsjava.language()

            # Build parser (API differs across versions)
            try:
                self.parser = Parser(self.JAVA_LANGUAGE)
            except Exception:
                self.parser = Parser()
                if hasattr(self.parser, "set_language"):
                    self.parser.set_language(self.JAVA_LANGUAGE)
        else:
            self.JAVA_LANGUAGE = None
            self.parser = None

    def parse_project(self, project_root: str) -> Dict:
        """Parse a Java project directory into symbols and relationships.

        The output format is stable across both implementations:
          - tree-sitter mode (preferred when available)
          - regex fallback mode (best-effort)
        """
        if not self.use_tree_sitter:
            return self._parse_project_regex(project_root)

        classes: List[Dict] = []
        methods: List[Dict] = []
        fields: List[Dict] = []
        relationships: List[Dict] = []

        # Project-wide indexes to support lightweight intra-repo resolution.
        # - global_method_name_map: methodName -> [Type.methodName]
        # - global_type_to_methods: Type -> {methodName -> Type.methodName}
        # - global_method_return_type: Type.methodName -> "ReturnType" (best-effort)
        # - global_types: set of type names (classes + interfaces)
        global_method_name_map: Dict[str, List[str]] = {}
        global_type_to_methods: Dict[str, Dict[str, str]] = {}
        global_method_return_type: Dict[str, str] = {}
        global_types: Set[str] = set()

        # First pass: parse each file, build symbols; also build global indexes.
        per_file_symbols: List[Tuple[str, Dict]] = []
        for file_path in _iter_java_files(project_root):
            symbols = self._parse_file_symbols(file_path)
            per_file_symbols.append((file_path, symbols))

            for t in symbols["classes"]:
                global_types.add(str(t["name"]))

            for m in symbols["methods"]:
                global_method_name_map.setdefault(m["name"], []).append(m["id"])
                global_type_to_methods.setdefault(str(m["class"]), {})[str(m["name"])] = str(m["id"])
                global_method_return_type[str(m["id"])] = str(m.get("return_type", "") or "")

        # Second pass: parse relationships with access to method map.
        for file_path, symbols in per_file_symbols:
            # Add classes/methods/fields
            classes.extend(symbols["classes"])
            methods.extend(symbols["methods"])
            fields.extend(symbols["fields"])

            # Relationship extraction depends on method ids in the same file/class.
            rels = self._parse_file_relationships(
                file_path=file_path,
                class_records=symbols["classes"],
                method_records=symbols["methods"],
                field_records=symbols["fields"],
                global_method_name_map=global_method_name_map,
                global_type_to_methods=global_type_to_methods,
                global_method_return_type=global_method_return_type,
                global_types=global_types,
            )
            relationships.extend(rels)

        return {
            "classes": classes,
            "methods": methods,
            "fields": fields,
            "relationships": relationships,
        }

    # -------------------------
    # File-level parsing
    # -------------------------
    def _parse_file_symbols(self, file_path: str) -> Dict:
        source_text = safe_read_text(file_path)
        comments = extract_comment_spans(source_text)
        code_bytes = source_text.encode("utf-8", errors="ignore")

        tree = self.parser.parse(code_bytes)
        root = tree.root_node

        classes: List[Dict] = []
        methods: List[Dict] = []
        fields: List[Dict] = []

        # Parse both classes and interfaces (important for resolving interface-method calls
        # such as IPromotionStrategy.execute()).
        type_nodes: List[Tuple[str, object]] = []
        for n in _find_nodes_by_type(root, "class_declaration"):
            type_nodes.append(("Class", n))
        for n in _find_nodes_by_type(root, "interface_declaration"):
            type_nodes.append(("Interface", n))

        for type_kind, class_node in type_nodes:
            name_node = class_node.child_by_field_name("name")
            if not name_node:
                continue
            class_name = _node_text(code_bytes, name_node)

            cls_start, cls_end = _node_lines(class_node)
            cls_doc = find_attached_doc(comments, cls_start) or ""

            # Signature: take the first line of class declaration (best-effort)
            # We take bytes from start_byte to the first "{" in the class node text.
            class_text = _node_text(code_bytes, class_node)
            sig = class_text.split("{", 1)[0].strip()
            sig = _compress_ws(sig)

            class_id = class_name  # keep simple for demo

            classes.append({
                "id": class_id,
                "name": class_name,
                "type": type_kind,
                "file_path": file_path,
                "start_line": cls_start,
                "end_line": cls_end,
                "signature": sig,
                "docstring": cls_doc,
            })

            # Extract members *inside this class*
            body_node = class_node.child_by_field_name("body")
            if not body_node:
                continue

            # Field declarations
            for field_decl in _find_nodes_by_type(body_node, "field_declaration"):
                fld_start, fld_end = _node_lines(field_decl)
                fld_doc = find_attached_doc(comments, fld_start) or ""

                # Type node (best-effort)
                type_node = field_decl.child_by_field_name("type")
                fld_type = _compress_ws(_node_text(code_bytes, type_node)) if type_node else ""

                # One declaration can declare multiple variables: int a, b;
                for var_decl in _find_nodes_by_type(field_decl, "variable_declarator"):
                    var_name_node = var_decl.child_by_field_name("name")
                    if not var_name_node:
                        continue
                    fld_name = _node_text(code_bytes, var_name_node)
                    field_id = f"{class_name}.{fld_name}"

                    # Signature: "Type name" + optional initializer excerpt
                    var_text = _node_text(code_bytes, var_decl)
                    signature = f"{fld_type} {var_text}".strip()
                    signature = _compress_ws(signature)

                    fields.append({
                        "id": field_id,
                        "name": fld_name,
                        "class": class_id,
                        "type": "Field",
                        "file_path": file_path,
                        "start_line": fld_start,
                        "end_line": fld_end,
                        "signature": signature,
                        "declared_type": fld_type,
                        "docstring": fld_doc,
                    })

            # Method declarations
            for method_node in _find_nodes_by_type(body_node, "method_declaration"):
                name_node = method_node.child_by_field_name("name")
                if not name_node:
                    continue
                method_name = _node_text(code_bytes, name_node)
                m_start, m_end = _node_lines(method_node)
                m_doc = find_attached_doc(comments, m_start) or ""

                # Return type (best-effort) for later lightweight call-chain inference.
                rt_node = method_node.child_by_field_name("type")
                return_type = _compress_ws(_node_text(code_bytes, rt_node)) if rt_node else ""

                # Signature: from method start to body start (or to end if no body)
                body = method_node.child_by_field_name("body")
                end_byte = body.start_byte if body else method_node.end_byte
                sig_bytes = code_bytes[method_node.start_byte:end_byte]
                signature = _compress_ws(sig_bytes.decode("utf-8", errors="ignore"))

                # ID: keep stable and human-friendly.
                # For demo: Class.methodName
                method_id = f"{class_name}.{method_name}"

                methods.append({
                    "id": method_id,
                    "name": method_name,
                    "class": class_id,
                    "type": "Method",
                    "file_path": file_path,
                    "start_line": m_start,
                    "end_line": m_end,
                    "signature": signature,
                    "return_type": return_type,
                    "docstring": m_doc,
                })

        return {"classes": classes, "methods": methods, "fields": fields}

    def _parse_file_relationships(
        self,
        file_path: str,
        class_records: List[Dict],
        method_records: List[Dict],
        field_records: List[Dict],
        global_method_name_map: Dict[str, List[str]],
        global_type_to_methods: Dict[str, Dict[str, str]],
        global_method_return_type: Dict[str, str],
        global_types: Set[str],
    ) -> List[Dict]:
        """
        Extract intra-file relationships. For the demo we extract:
          - CALLS: method -> method
          - READS: method -> field (best-effort; only field_access nodes)
          - WRITES: method -> field (best-effort; only assignment_expression to field_access)

        Relationship dict includes file_path and an approximate line.
        """
        source_text = safe_read_text(file_path)
        code_bytes = source_text.encode("utf-8", errors="ignore")

        tree = self.parser.parse(code_bytes)
        root = tree.root_node

        # Build quick lookup for same-class members + field types
        class_to_methods: Dict[str, Dict[str, str]] = {}
        for m in method_records:
            class_to_methods.setdefault(str(m["class"]), {})[str(m["name"])] = str(m["id"])

        class_to_fields: Dict[str, Dict[str, str]] = {}
        class_to_field_types: Dict[str, Dict[str, str]] = {}
        for f in field_records:
            cls = str(f.get("class") or "")
            nm = str(f.get("name") or "")
            if not cls or not nm:
                continue
            class_to_fields.setdefault(cls, {})[nm] = str(f["id"])
            class_to_field_types.setdefault(cls, {})[nm] = str(f.get("declared_type") or "")

        def _split_generic_args(s: str) -> List[str]:
            # Split generics by commas at depth=0: "A<B,C<D>>" -> ["B", "C<D>"]
            out: List[str] = []
            buf: List[str] = []
            depth = 0
            for ch in s:
                if ch == "<":
                    depth += 1
                    buf.append(ch)
                elif ch == ">":
                    depth = max(0, depth - 1)
                    buf.append(ch)
                elif ch == "," and depth == 0:
                    part = "".join(buf).strip()
                    if part:
                        out.append(part)
                    buf = []
                else:
                    buf.append(ch)
            tail = "".join(buf).strip()
            if tail:
                out.append(tail)
            return out

        def _parse_type(type_str: str) -> Tuple[str, List[str]]:
            t = (type_str or "").strip()
            if not t:
                return "", []
            # strip array
            t = t.replace("[]", "").strip()
            # remove annotations like @Nullable
            t = re.sub(r"@\w+", "", t).strip()
            # base + generics
            base = t
            gens: List[str] = []
            if "<" in t and ">" in t:
                base = t.split("<", 1)[0].strip()
                inner = t[t.find("<") + 1 : t.rfind(">")].strip()
                gens = [g.strip() for g in _split_generic_args(inner) if g.strip()]
            # simple names (strip package)
            base_simple = base.split(".")[-1].strip()
            gen_simple: List[str] = []
            for g in gens:
                g = g.replace("[]", "").strip()
                gen_simple.append(g.split(".")[-1].strip())
            return base_simple, gen_simple

        COLLECTION_BASES = {"List", "ArrayList", "LinkedList", "Set", "HashSet", "Collection", "Iterable"}

        def _looks_like_external_type(simple_name: str) -> bool:
            if not simple_name:
                return False
            if simple_name in global_types:
                return False
            # java.lang / standard library shorthands
            if simple_name in {"System", "Math", "Objects", "String", "Integer", "Long", "Double", "Float", "Boolean"}:
                return True
            # heuristic: PascalCase but not defined in this repo
            return simple_name[:1].isupper()

        def _resolve_on_type(type_str: str, method_name: str) -> Optional[str]:
            base, gens = _parse_type(type_str)
            if not base:
                return None
            # direct dispatch on known type
            if base in global_type_to_methods and method_name in global_type_to_methods[base]:
                return global_type_to_methods[base][method_name]
            # collection element dispatch (List<T>.get(i).execute())
            if base in COLLECTION_BASES and gens:
                return _resolve_on_type(gens[0], method_name)
            return None

        def _build_local_symbols(method_node) -> Dict[str, str]:
            """Lightweight local symbol table: varName -> declaredType."""
            syms: Dict[str, str] = {}
            # Parameters
            for p in _find_nodes_by_type(method_node, "formal_parameter"):
                tnode = p.child_by_field_name("type")
                nnode = p.child_by_field_name("name")
                if not tnode or not nnode:
                    continue
                ptype = _compress_ws(_node_text(code_bytes, tnode))
                pname = _node_text(code_bytes, nnode)
                if pname:
                    syms[pname] = ptype

            # Local variables
            for lv in _find_nodes_by_type(method_node, "local_variable_declaration"):
                tnode = lv.child_by_field_name("type")
                ltype = _compress_ws(_node_text(code_bytes, tnode)) if tnode else ""
                for vd in _find_nodes_by_type(lv, "variable_declarator"):
                    nnode = vd.child_by_field_name("name")
                    if not nnode:
                        continue
                    vname = _node_text(code_bytes, nnode)
                    if vname and ltype:
                        syms[vname] = ltype
            return syms

        def _is_external_qualifier(obj_text: str, local_syms: Dict[str, str], field_types: Dict[str, str]) -> bool:
            t = (obj_text or "").strip()
            if not t:
                return False
            if t.startswith("java.") or t.startswith("javax."):
                return True
            root = t.split(".")[0]
            root_simple = root.split(".")[-1]
            if root_simple in local_syms or root_simple in field_types:
                return False
            return _looks_like_external_type(root_simple)

        def _infer_return_type_of_invocation(
            current_class_id: str,
            inv_node,
            local_syms: Dict[str, str],
            field_types: Dict[str, str],
            depth: int = 2,
        ) -> str:
            """Infer return type of an invocation (best-effort) to help resolve chained calls."""
            if depth <= 0 or not inv_node or getattr(inv_node, "type", None) != "method_invocation":
                return ""
            name_node = inv_node.child_by_field_name("name")
            if not name_node:
                return ""
            inner_name = _node_text(code_bytes, name_node)
            obj_node = inv_node.child_by_field_name("object")

            # Heuristic: collection.get(i) returns element type
            if inner_name == "get" and obj_node is not None:
                if obj_node.type in ("identifier", "scoped_identifier"):
                    base_var = _node_text(code_bytes, obj_node).split(".")[-1]
                    vtype = local_syms.get(base_var) or field_types.get(base_var) or ""
                    base, gens = _parse_type(vtype)
                    if base in COLLECTION_BASES and gens:
                        return gens[0]

            # Try resolve the inner invocation to an internal method id, then use known return type
            target = _resolve_invocation_target(current_class_id, inner_name, obj_node, local_syms, field_types, depth - 1)
            if target and not target.startswith("UNRESOLVED::") and not target.startswith("EXTERNAL::"):
                return str(global_method_return_type.get(target, "") or "")
            return ""

        def _resolve_invocation_target(
            current_class_id: str,
            callee_name: str,
            object_node,
            local_syms: Dict[str, str],
            field_types: Dict[str, str],
            depth: int = 2,
        ) -> str:
            """Resolve a method invocation target into either an internal id or EXTERNAL/UNRESOLVED."""
            # Unqualified: execute() or this.execute()
            if object_node is None or object_node.type in ("this", "super"):
                # same-class first
                tgt = class_to_methods.get(current_class_id, {}).get(callee_name)
                if tgt:
                    return tgt
                # unique global resolution
                candidates = global_method_name_map.get(callee_name, [])
                if len(candidates) == 1:
                    return candidates[0]
                return f"UNRESOLVED::{callee_name}"

            # Qualified call: obj.execute()
            obj_type: Optional[str] = None
            obj_text = _compress_ws(_node_text(code_bytes, object_node))

            if object_node.type in ("identifier", "scoped_identifier"):
                ident = obj_text.split(".")[-1]
                # variable dispatch
                if ident in local_syms:
                    obj_type = local_syms[ident]
                elif ident in field_types:
                    obj_type = field_types[ident]
                else:
                    # static call: SomeClass.execute()
                    if ident in global_types:
                        tgt = global_type_to_methods.get(ident, {}).get(callee_name)
                        if tgt:
                            return tgt
                    # external type
                    if _looks_like_external_type(ident):
                        return f"EXTERNAL::{ident}.{callee_name}"
                    return f"UNRESOLVED::{callee_name}"

            elif object_node.type == "field_access":
                # e.g., System.out.println() where object is "System.out"
                full_obj = _compress_ws(_node_text(code_bytes, object_node))
                if _is_external_qualifier(full_obj, local_syms, field_types):
                    return f"EXTERNAL::{full_obj}.{callee_name}"
                return f"UNRESOLVED::{callee_name}"

            elif object_node.type == "method_invocation":
                # chained call: strategies.get(i).execute()
                inferred = _infer_return_type_of_invocation(current_class_id, object_node, local_syms, field_types, depth=depth)
                if inferred:
                    obj_type = inferred

            # If we have an object type, try dispatch.
            if obj_type:
                tgt = _resolve_on_type(obj_type, callee_name)
                if tgt:
                    return tgt
                base, _ = _parse_type(obj_type)
                if _looks_like_external_type(base):
                    return f"EXTERNAL::{base}.{callee_name}"

            # fallback
            # if the method name exists in-repo, it's an unresolved internal call; otherwise likely external
            if callee_name in global_method_name_map:
                return f"UNRESOLVED::{callee_name}"
            if _is_external_qualifier(obj_text, local_syms, field_types):
                return f"EXTERNAL::{obj_text}.{callee_name}"
            return f"UNRESOLVED::{callee_name}"

        relationships: List[Dict] = []

        # Find type declarations (class + interface) and scan inside methods
        type_nodes: List[Tuple[str, object]] = []
        for n in _find_nodes_by_type(root, "class_declaration"):
            type_nodes.append(("Class", n))
        for n in _find_nodes_by_type(root, "interface_declaration"):
            type_nodes.append(("Interface", n))

        for _, type_node in type_nodes:
            name_node = type_node.child_by_field_name("name")
            if not name_node:
                continue
            class_name = _node_text(code_bytes, name_node)
            class_id = class_name

            body_node = type_node.child_by_field_name("body")
            if not body_node:
                continue

            for method_node in _find_nodes_by_type(body_node, "method_declaration"):
                mn_node = method_node.child_by_field_name("name")
                if not mn_node:
                    continue
                method_name = _node_text(code_bytes, mn_node)
                method_id = f"{class_name}.{method_name}"

                local_syms = _build_local_symbols(method_node)
                field_types = class_to_field_types.get(class_id, {})

                # 1) CALLS edges: method_invocation
                for inv in _find_nodes_by_type(method_node, "method_invocation"):
                    callee_node = inv.child_by_field_name("name")
                    if not callee_node:
                        continue
                    callee_name = _node_text(code_bytes, callee_node)
                    obj_node = inv.child_by_field_name("object")
                    line, _ = _node_lines(inv)

                    target_id = _resolve_invocation_target(class_id, callee_name, obj_node, local_syms, field_types)

                    relationships.append({
                        "source": method_id,
                        "target": target_id,
                        "type": "CALLS",
                        "file_path": file_path,
                        "line": line,
                    })

                # 2) READS edges: field_access nodes
                for fa in _find_nodes_by_type(method_node, "field_access"):
                    field_node = fa.child_by_field_name("field")
                    obj_node = fa.child_by_field_name("object")
                    if not field_node or not obj_node:
                        continue
                    field_name = _node_text(code_bytes, field_node)
                    obj_text = _compress_ws(_node_text(code_bytes, obj_node))
                    line, _ = _node_lines(fa)

                    if obj_node.type in ("this", "super"):
                        field_id = class_to_fields.get(class_id, {}).get(field_name, f"{class_name}.{field_name}")
                    else:
                        full_field = f"{obj_text}.{field_name}" if obj_text else field_name
                        if _is_external_qualifier(obj_text, local_syms, field_types):
                            field_id = f"EXTERNAL::{full_field}"
                        else:
                            field_id = f"UNRESOLVED_FIELD::{full_field}"

                    relationships.append({
                        "source": method_id,
                        "target": field_id,
                        "type": "READS",
                        "file_path": file_path,
                        "line": line,
                    })

                # 3) WRITES edges: assignment_expression where left is field_access
                for assign in _find_nodes_by_type(method_node, "assignment_expression"):
                    left = assign.child_by_field_name("left")
                    if not left or left.type != "field_access":
                        continue
                    field_node = left.child_by_field_name("field")
                    obj_node = left.child_by_field_name("object")
                    if not field_node or not obj_node:
                        continue
                    field_name = _node_text(code_bytes, field_node)
                    obj_text = _compress_ws(_node_text(code_bytes, obj_node))
                    line, _ = _node_lines(assign)

                    if obj_node.type in ("this", "super"):
                        field_id = class_to_fields.get(class_id, {}).get(field_name, f"{class_name}.{field_name}")
                    else:
                        full_field = f"{obj_text}.{field_name}" if obj_text else field_name
                        if _is_external_qualifier(obj_text, local_syms, field_types):
                            field_id = f"EXTERNAL::{full_field}"
                        else:
                            field_id = f"UNRESOLVED_FIELD::{full_field}"

                    relationships.append({
                        "source": method_id,
                        "target": field_id,
                        "type": "WRITES",
                        "file_path": file_path,
                        "line": line,
                    })

        return relationships


    # ---------------------------------------------------------------------
    # Regex fallback implementation (no tree-sitter)
    # ---------------------------------------------------------------------
    _RE_CLASS_DECL = re.compile(
        r"\b(class|interface)\s+(?P<name>[A-Za-z_][A-Za-z0-9_]*)\b(?P<rest>[^\n{]*)\{"
    )
    _RE_EXTENDS = re.compile(r"\bextends\s+([A-Za-z_][A-Za-z0-9_]*)\b")

    # Method declaration (with body). Best-effort; ignores edge cases.
    _RE_METHOD_DECL = re.compile(
        r"^\s*(?:public|protected|private)?\s*(?:static\s+)?(?:final\s+)?(?P<rtype>[A-Za-z_][A-Za-z0-9_<>\[\]]*)\s+(?P<name>[A-Za-z_][A-Za-z0-9_]*)\s*\([^;]*\)\s*\{\s*$"
    )

    # Constructor declaration (no return type). We keep it as a Method node
    # with id=Class.<init> for completeness.
    _RE_CTOR_DECL = re.compile(
        r"^\s*(?:public|protected|private)?\s*(?P<name>[A-Za-z_][A-Za-z0-9_]*)\s*\([^;]*\)\s*\{\s*$"
    )

    # Interface method (no body)
    _RE_INTERFACE_METHOD = re.compile(
        r"^\s*(?:public|protected|private)?\s*(?:static\s+)?(?:default\s+)?(?P<rtype>[A-Za-z_][A-Za-z0-9_<>\[\]]*)\s+(?P<name>[A-Za-z_][A-Za-z0-9_]*)\s*\([^;]*\)\s*;\s*$"
    )

    _RE_FIELD_DECL = re.compile(
        r"^\s*(?:public|protected|private)?\s*(?:static\s+)?(?:final\s+)?(?P<type>[A-Za-z_][A-Za-z0-9_<>\[\]]*)\s+(?P<name>[A-Za-z_][A-Za-z0-9_]*)\s*(?:=[^;]*)?;\s*$"
    )

    # Call patterns (line-level)
    _RE_CALL_QUAL = re.compile(r"\b(?P<recv>[A-Za-z_][A-Za-z0-9_]*)\s*\.\s*(?P<name>[A-Za-z_][A-Za-z0-9_]*)\s*\(")
    _RE_CALL_UNQUAL = re.compile(r"\b(?P<name>[A-Za-z_][A-Za-z0-9_]*)\s*\(")

    _JAVA_KEYWORDS_CALLLIKE = {
        "if", "for", "while", "switch", "catch", "new", "return", "throw", "synchronized",
        "try", "super", "this", "do", "else", "case", "assert",
    }

    @staticmethod
    def _brace_balance(line: str) -> int:
        # NOTE: best-effort; strings/comments can break this but acceptable for demo.
        return line.count("{") - line.count("}")

    @classmethod
    def _find_block_end(cls, lines: List[str], start_idx: int) -> int:
        """Return the inclusive line index where the '{' block opened at/after start_idx ends."""
        depth = 0
        started = False
        for i in range(start_idx, len(lines)):
            ln = lines[i]
            delta = cls._brace_balance(ln)
            if "{" in ln:
                started = True
            depth += delta
            if started and depth <= 0:
                return i
        return len(lines) - 1

    def _parse_project_regex(self, project_root: str) -> Dict:
        classes: List[Dict] = []
        methods: List[Dict] = []
        fields: List[Dict] = []
        relationships: List[Dict] = []

        global_method_name_map: Dict[str, List[str]] = {}
        global_type_to_methods: Dict[str, Dict[str, str]] = {}
        global_method_return_type: Dict[str, str] = {}
        global_types: Set[str] = set()
        extends_map: Dict[str, str] = {}

        per_file_symbols: List[Tuple[str, Dict]] = []

        # Pass 1: symbols
        for file_path in _iter_java_files(project_root):
            symbols = self._parse_file_symbols_regex(file_path)
            per_file_symbols.append((file_path, symbols))
            for t in symbols["classes"]:
                global_types.add(str(t["name"]))
                if t.get("extends"):
                    extends_map[str(t["name"])] = str(t["extends"])
            for m in symbols["methods"]:
                global_method_name_map.setdefault(str(m["name"]), []).append(str(m["id"]))
                global_type_to_methods.setdefault(str(m["class"]), {})[str(m["name"])] = str(m["id"])
                global_method_return_type[str(m["id"])] = str(m.get("return_type", "") or "")

        # Pass 2: relationships
        for file_path, symbols in per_file_symbols:
            classes.extend(symbols["classes"])
            methods.extend(symbols["methods"])
            fields.extend(symbols["fields"])
            relationships.extend(
                self._parse_file_relationships_regex(
                    file_path=file_path,
                    class_records=symbols["classes"],
                    method_records=symbols["methods"],
                    field_records=symbols["fields"],
                    global_method_name_map=global_method_name_map,
                    global_type_to_methods=global_type_to_methods,
                    global_types=global_types,
                    extends_map=extends_map,
                )
            )

        return {
            "classes": classes,
            "methods": methods,
            "fields": fields,
            "relationships": relationships,
        }

    def _parse_file_symbols_regex(self, file_path: str) -> Dict:
        source_text = safe_read_text(file_path)
        lines = source_text.splitlines()
        comments = extract_comment_spans(source_text)

        classes: List[Dict] = []
        methods: List[Dict] = []
        fields: List[Dict] = []

        # Find top-level class/interface declaration (best-effort)
        m = self._RE_CLASS_DECL.search(source_text)
        if not m:
            return {"classes": classes, "methods": methods, "fields": fields}

        type_kind = "Class" if m.group(1) == "class" else "Interface"
        class_name = m.group("name")
        rest = m.group("rest") or ""
        extends_match = self._RE_EXTENDS.search(rest)
        extends_name = extends_match.group(1) if extends_match else ""

        # Approximate class span by brace matching from the line containing the first '{'
        cls_start_line = source_text.count("\n", 0, m.start()) + 1
        cls_start_idx = max(0, cls_start_line - 1)
        cls_end_idx = self._find_block_end(lines, cls_start_idx)
        cls_end_line = cls_end_idx + 1
        cls_doc = find_attached_doc(comments, cls_start_line) or ""

        # Signature = declaration line (trimmed)
        sig = (lines[cls_start_idx] if cls_start_idx < len(lines) else "").strip()
        sig = _compress_ws(sig)

        classes.append({
            "id": class_name,
            "name": class_name,
            "type": type_kind,
            "file_path": file_path,
            "start_line": cls_start_line,
            "end_line": cls_end_line,
            "signature": sig,
            "docstring": cls_doc,
            "extends": extends_name,
        })

        # Scan members inside class block.
        in_class = False
        class_depth = 0
        in_method = False
        method_depth = 0
        for i in range(cls_start_idx, min(cls_end_idx + 1, len(lines))):
            ln = lines[i]
            if not in_class:
                if "{" in ln:
                    in_class = True
                    class_depth = 1
                continue

            # Track class brace depth to know when we are inside methods.
            class_depth += self._brace_balance(ln)
            if class_depth <= 0:
                break

            # Track method depth to avoid parsing fields inside methods.
            if in_method:
                method_depth += self._brace_balance(ln)
                if method_depth <= 0:
                    in_method = False
                    method_depth = 0
                continue

            # Interface methods (no body)
            mi = self._RE_INTERFACE_METHOD.match(ln)
            if mi and type_kind == "Interface":
                method_name = mi.group("name")
                start_line = i + 1
                m_doc = find_attached_doc(comments, start_line) or ""
                signature = _compress_ws(ln.strip())
                method_id = f"{class_name}.{method_name}"
                methods.append({
                    "id": method_id,
                    "name": method_name,
                    "class": class_name,
                    "type": "Method",
                    "file_path": file_path,
                    "start_line": start_line,
                    "end_line": start_line,
                    "signature": signature,
                    "return_type": mi.group("rtype") or "",
                    "docstring": m_doc,
                })
                continue

            # Method declarations (with body)
            mm = self._RE_METHOD_DECL.match(ln)
            if mm:
                method_name = mm.group("name")
                start_line = i + 1
                m_doc = find_attached_doc(comments, start_line) or ""
                end_idx = self._find_block_end(lines, i)
                end_line = end_idx + 1
                signature = _compress_ws(ln.strip())
                method_id = f"{class_name}.{method_name}"
                methods.append({
                    "id": method_id,
                    "name": method_name,
                    "class": class_name,
                    "type": "Method",
                    "file_path": file_path,
                    "start_line": start_line,
                    "end_line": end_line,
                    "signature": signature,
                    "return_type": mm.group("rtype") or "",
                    "docstring": m_doc,
                })
                # Enter method body tracking
                in_method = True
                method_depth = 1
                continue

            # Constructor declarations (treated as Class.<init>)
            mc = self._RE_CTOR_DECL.match(ln)
            if mc and mc.group("name") == class_name:
                start_line = i + 1
                m_doc = find_attached_doc(comments, start_line) or ""
                end_idx = self._find_block_end(lines, i)
                end_line = end_idx + 1
                signature = _compress_ws(ln.strip())
                method_id = f"{class_name}.<init>"
                methods.append({
                    "id": method_id,
                    "name": "<init>",
                    "class": class_name,
                    "type": "Method",
                    "file_path": file_path,
                    "start_line": start_line,
                    "end_line": end_line,
                    "signature": signature,
                    "return_type": "",
                    "docstring": m_doc,
                })
                in_method = True
                method_depth = 1
                continue

            # Field declarations (only when not inside a method)
            mf = self._RE_FIELD_DECL.match(ln)
            if mf and "(" not in ln:
                fld_name = mf.group("name")
                fld_type = mf.group("type")
                start_line = i + 1
                fld_doc = find_attached_doc(comments, start_line) or ""
                field_id = f"{class_name}.{fld_name}"
                signature = _compress_ws(ln.strip())
                fields.append({
                    "id": field_id,
                    "name": fld_name,
                    "class": class_name,
                    "type": "Field",
                    "file_path": file_path,
                    "start_line": start_line,
                    "end_line": start_line,
                    "signature": signature,
                    "declared_type": fld_type,
                    "docstring": fld_doc,
                })
                continue

        return {"classes": classes, "methods": methods, "fields": fields}

    def _parse_file_relationships_regex(
        self,
        *,
        file_path: str,
        class_records: List[Dict],
        method_records: List[Dict],
        field_records: List[Dict],
        global_method_name_map: Dict[str, List[str]],
        global_type_to_methods: Dict[str, Dict[str, str]],
        global_types: Set[str],
        extends_map: Dict[str, str],
    ) -> List[Dict]:
        source_text = safe_read_text(file_path)
        lines = source_text.splitlines()

        # Determine current class (best-effort: first class record)
        class_name = str(class_records[0]["name"]) if class_records else ""
        if not class_name:
            return []

        # Build same-class method lookup
        class_to_methods: Dict[str, Dict[str, str]] = {}
        for m in method_records:
            class_to_methods.setdefault(str(m["class"]), {})[str(m["name"])] = str(m["id"])

        relationships: List[Dict] = []

        # For each method with a span, scan its body lines for call patterns.
        for m in method_records:
            method_id = str(m["id"])
            start_line = int(m.get("start_line") or 0)
            end_line = int(m.get("end_line") or 0)
            if start_line <= 0 or end_line <= 0 or end_line < start_line:
                continue

            # Slice lines; include signature line to keep it simple.
            body_lines = lines[start_line - 1 : end_line]
            for offset, ln in enumerate(body_lines):
                lineno = start_line + offset

                # Qualified calls first
                for qm in self._RE_CALL_QUAL.finditer(ln):
                    recv = qm.group("recv")
                    name = qm.group("name")
                    if not name or name in self._JAVA_KEYWORDS_CALLLIKE:
                        continue

                    target_raw = ""
                    if recv == "this":
                        target_raw = f"{class_name}.{name}"
                    elif recv == "super":
                        parent = extends_map.get(class_name, "")
                        target_raw = f"{parent}.{name}" if parent else name
                    elif recv in global_types:
                        target_raw = f"{recv}.{name}"
                    else:
                        # unknown receiver type (variable instance) -> unresolved
                        target_raw = f"{recv}.{name}"

                    relationships.append({
                        "source": method_id,
                        "target": target_raw,
                        "type": "CALLS",
                        "file_path": file_path,
                        "line": lineno,
                    })

                # Unqualified calls
                for um in self._RE_CALL_UNQUAL.finditer(ln):
                    name = um.group("name")
                    if not name or name in self._JAVA_KEYWORDS_CALLLIKE:
                        continue
                    # Skip if this was part of a qualified call (already handled)
                    # e.g. 'LegacyScoringUtil.calculateBaseScore(' -> would match calculateBaseScore too
                    if "." in ln[max(0, um.start() - 2) : um.start()]:
                        continue

                    target_raw = ""
                    # Same class
                    same = class_to_methods.get(class_name, {}).get(name)
                    if same:
                        target_raw = same
                    else:
                        # Global unique name
                        cands = global_method_name_map.get(name, [])
                        if len(cands) == 1:
                            target_raw = cands[0]
                        else:
                            target_raw = name

                    relationships.append({
                        "source": method_id,
                        "target": target_raw,
                        "type": "CALLS",
                        "file_path": file_path,
                        "line": lineno,
                    })

        return relationships

==================== END FILE ====================


==================== FILE: src/dotenv.py ====================

from __future__ import annotations

import os
from pathlib import Path
from typing import Optional


def _strip_quotes(v: str) -> str:
    v = v.strip()
    if len(v) >= 2 and ((v[0] == v[-1] == '"') or (v[0] == v[-1] == "'")):
        return v[1:-1]
    return v


def load_dotenv(path: str | Path = ".env", *, override: bool = False) -> bool:
    """A tiny .env loader (no external dependency).

    - Parses KEY=VALUE lines
    - Ignores blank lines and comments (# ...)
    - Supports quoted values ("..."/'...') and inline comments after a space + #
    - Writes into os.environ (unless already set and override=False)

    Returns True if file existed and was loaded.
    """
    p = Path(path).expanduser()
    if not p.is_file():
        return False

    for raw in p.read_text(encoding="utf-8", errors="ignore").splitlines():
        line = raw.strip()
        if not line or line.startswith("#"):
            continue
        if "=" not in line:
            continue
        k, v = line.split("=", 1)
        key = k.strip()
        val = v.strip()

        # remove inline comment: only if there's an unquoted ' #' sequence
        if val and val[0] not in "'":
            # split on first ' #' (space hash) to avoid chopping URLs like https://...
            idx = val.find(" #")
            if idx != -1:
                val = val[:idx].rstrip()

        val = _strip_quotes(val)
        if not key:
            continue
        if (not override) and (key in os.environ) and (os.environ[key] != ""):
            continue
        os.environ[key] = val
    return True


def auto_load_dotenv(explicit_path: Optional[str] = None) -> Optional[str]:
    """Try to load dotenv from common locations; returns loaded path if any."""
    candidates = []
    if explicit_path:
        candidates.append(Path(explicit_path))
    # current working directory
    candidates.append(Path.cwd() / ".env")
    # repo root heuristic: walk up a few levels looking for .env
    cur = Path.cwd()
    for _ in range(5):
        candidates.append(cur / ".env")
        cur = cur.parent

    for c in candidates:
        try:
            if load_dotenv(c):
                return str(c)
        except Exception:
            # Never hard-fail on dotenv parsing
            continue
    return None

==================== END FILE ====================


==================== FILE: src/utils.py ====================
"""
Utility helpers for Graph-RAG on code repositories.

This module is deliberately dependency-light so the demo can run offline.
"""
from __future__ import annotations

import os
import re
from dataclasses import dataclass
from typing import Iterable, List, Optional, Tuple


_CAMEL_1 = re.compile(r"([a-z0-9])([A-Z])")
_CAMEL_2 = re.compile(r"([A-Z]+)([A-Z][a-z])")


def normalize_code_text(text: str) -> str:
    """
    Normalize code-ish text for lexical vector search (TF-IDF/BM25 style).

    - split CamelCase: myMethodName -> my Method Name
    - split snake_case / dotted.names / :: names
    - lowercase
    """
    if not text:
        return ""
    t = text
    t = t.replace("::", " ")
    t = t.replace(".", " ").replace("_", " ").replace("/", " ")
    t = _CAMEL_2.sub(r"\1 \2", t)
    t = _CAMEL_1.sub(r"\1 \2", t)
    t = re.sub(r"\s+", " ", t)
    return t.strip().lower()


@dataclass(frozen=True)
class CommentSpan:
    start_line: int
    end_line: int
    text: str
    kind: str  # "javadoc" | "block" | "line"


_BLOCK_COMMENT_RE = re.compile(r"/\*.*?\*/", re.DOTALL)
_LINE_COMMENT_RE = re.compile(r"//.*?$", re.MULTILINE)


def extract_comment_spans(source_text: str) -> List[CommentSpan]:
    """
    Extract comment spans by line numbers using regex.

    This is not a perfect Java lexer (comments inside strings are tricky),
    but it's good enough for a demo and for capturing Javadoc blocks.
    """
    spans: List[CommentSpan] = []

    # Block comments (including Javadoc)
    for m in _BLOCK_COMMENT_RE.finditer(source_text):
        block = m.group(0)
        kind = "javadoc" if block.startswith("/**") else "block"
        start = source_text.count("\n", 0, m.start()) + 1
        end = source_text.count("\n", 0, m.end()) + 1
        spans.append(CommentSpan(start_line=start, end_line=end, text=block, kind=kind))

    # Line comments
    for m in _LINE_COMMENT_RE.finditer(source_text):
        line_text = m.group(0)
        start = source_text.count("\n", 0, m.start()) + 1
        spans.append(CommentSpan(start_line=start, end_line=start, text=line_text, kind="line"))

    spans.sort(key=lambda s: (s.start_line, s.end_line))
    return spans


def find_attached_doc(comments: List[CommentSpan], decl_start_line: int, max_gap_lines: int = 1) -> Optional[str]:
    """
    Attach the nearest preceding comment block to a declaration start line.

    Common Java style:
      /** ... */
      public void foo() { ... }

    We accept a small gap (blank line) between comment and declaration.
    """
    best = None
    best_end = -1
    for c in comments:
        if c.end_line <= decl_start_line - 1:
            gap = (decl_start_line - 1) - c.end_line
            if gap <= max_gap_lines and c.end_line > best_end:
                best = c
                best_end = c.end_line
    if not best:
        return None

    # Prefer Javadoc when possible
    if best.kind == "javadoc":
        return best.text
    # If nearest isn't Javadoc, still return (could be // comment)
    return best.text


def safe_read_text(path: str) -> str:
    # Try UTF-8, fall back to latin-1 to avoid crashing on weird encodings.
    try:
        with open(path, "r", encoding="utf-8") as f:
            return f.read()
    except UnicodeDecodeError:
        with open(path, "r", encoding="latin-1") as f:
            return f.read()


def load_snippet(path: str, start_line: int, end_line: int, max_lines: int = 120) -> str:
    """
    Load a snippet from file by 1-indexed line numbers.
    """
    if not path or not os.path.exists(path):
        return ""
    if start_line <= 0:
        start_line = 1
    if end_line < start_line:
        end_line = start_line

    with open(path, "r", encoding="utf-8", errors="ignore") as f:
        lines = f.readlines()

    start_idx = max(0, start_line - 1)
    end_idx = min(len(lines), end_line)

    snippet_lines = lines[start_idx:end_idx]
    if len(snippet_lines) > max_lines:
        # Keep head+tail for readability
        head = snippet_lines[: max_lines // 2]
        tail = snippet_lines[-max_lines // 2 :]
        snippet_lines = head + ["\n... (snippet truncated) ...\n"] + tail

    return "".join(snippet_lines)

==================== END FILE ====================


==================== FILE: src/agent.py ====================
from __future__ import annotations

import json
import os
import re
import shutil
import time
import difflib
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from .llm import LLMClient
from .patcher import PatchApplyError  # reuse exception type
from .prompts import (
    PLAN_SYSTEM, PLAN_USER_TEMPLATE,
    EDIT_SYSTEM, EDIT_USER_TEMPLATE,
    REPAIR_SYSTEM, REPAIR_USER_TEMPLATE,
    context_pack_to_prompt,
)
from .sandbox import Sandbox, SandboxConfig, CommandResult


@dataclass
class AgentConfig:
    project_dir: Path
    work_dir: Optional[Path] = None  # if None, create .refactor_agent_runs/<ts> under project_dir
    max_iters: int = 3

    # Prompt control
    max_nodes_in_prompt: int = 18
    max_snippet_chars: int = 2200

    # Verification
    # If None/empty, RefactoringAgent will auto-detect sensible verification commands
    # based on repo contents (e.g. Maven/Gradle/Java demo runner).
    default_verify_cmds: Optional[List[str]] = None

    # Whether to trust/execute verification commands proposed by the LLM in plan.json.
    # Default False to avoid brittle verification steps.
    use_plan_verification: bool = False

    # Sandbox
    sandbox_timeout_s: int = 240
    use_docker: bool = False
    docker_image: str = "python:3.10-slim"
    allowed_commands: Optional[List[str]] = None


@dataclass
class SearchReplaceBlock:
    search: str
    replace: str


@dataclass
class FileEditInstruction:
    path: str
    blocks: List[SearchReplaceBlock] = None
    rewrite: Optional[str] = None



class RefactoringAgent:
    """
    Minimal refactoring agent (Plan â†’ Edit â†’ Verify/Repair) using git apply as the patch application engine.

    Key robustness features vs earlier versions:
    - Normalize plan paths (strip prefixes like data/marketing-demo/ if work_dir is already marketing-demo root)
    - Feed EXACT file contents into prompts so LLM doesn't guess context lines
    - Use git reset --hard + git clean -fd between iterations to keep index/worktree consistent
    - Support both git-style patches (diff --git a/ b/) and traditional patches (---/+++ without a/ b/) via -p level
    """
    def __init__(self, *, llm: LLMClient, cfg: AgentConfig):
        self.llm = llm
        self.cfg = cfg
        self.project_dir = Path(cfg.project_dir).resolve()
        if not self.project_dir.exists():
            raise FileNotFoundError(f"project_dir not found: {self.project_dir}")

        ts = time.strftime("%Y%m%d_%H%M%S")
        self.work_dir = Path(cfg.work_dir or (self.project_dir / ".refactor_agent_runs" / ts)).resolve()

        if self.work_dir.exists():
            raise FileExistsError(f"work_dir already exists: {self.work_dir}")
        self.work_dir.parent.mkdir(parents=True, exist_ok=True)

        # Copy project into sandbox workspace (ignore heavy folders)
        shutil.copytree(
            self.project_dir,
            self.work_dir,
            dirs_exist_ok=False,
            ignore=shutil.ignore_patterns(".refactor_agent_runs", ".git", "target", "build", ".gradle", "node_modules", "__pycache__")
        )

        sandbox_cfg = SandboxConfig(
            root_dir=self.work_dir,
            timeout_s=cfg.sandbox_timeout_s,
            allowed_commands=(cfg.allowed_commands or SandboxConfig(root_dir=self.work_dir).allowed_commands),
            use_docker=cfg.use_docker,
            docker_image=cfg.docker_image,
        )
        self.sandbox = Sandbox(sandbox_cfg)

        # Auto-detect verification commands if not provided.
        if not (self.cfg.default_verify_cmds or []):
            self.cfg.default_verify_cmds = self._auto_detect_verify_cmds()

        self._git_initialized = False

    # ---------------------------
    # Utilities
    # ---------------------------


    def _auto_detect_verify_cmds(self) -> List[str]:
        """Choose deterministic verification commands based on repo contents.

        We intentionally avoid trusting LLM-generated verification commands by default
        because they are often brittle (wrong classpath, missing files, shell globs, etc.).
        """
        repo = self.work_dir

        # Java: if there is a DemoRunner, compile all sources and run it.
        src_root = repo / "src" / "main" / "java"
        if src_root.exists():
            demo = next(src_root.rglob("DemoRunner.java"), None)
            if demo:
                main_class = self._java_main_class_from_source(demo)
                # Compile into target/classes to avoid polluting source tree
                compile_cmd = "javac -encoding UTF-8 -d target/classes -cp src/main/java src/main/java/**/*.java"

                # Include resources if present
                cp = f"target/classes{os.pathsep}src/main/resources" if (repo / "src" / "main" / "resources").exists() else "target/classes"
                run_cmd = f"java -cp {cp} {main_class}"
                return [compile_cmd, run_cmd]

            # Fallback: just compile everything
            return ["javac -encoding UTF-8 -d target/classes -cp src/main/java src/main/java/**/*.java"]

        # Maven / Gradle (fallbacks)
        if (repo / "pom.xml").exists():
            if (repo / "mvnw").exists():
                return ["./mvnw -q test"]
            return ["mvn -q test"]

        if (repo / "build.gradle").exists() or (repo / "build.gradle.kts").exists():
            if (repo / "gradlew").exists():
                return ["./gradlew test"]
            return ["gradle test"]

        # Python (very generic fallback)
        if (repo / "pyproject.toml").exists() or (repo / "requirements.txt").exists():
            return ["pytest -q"]

        return []

    @staticmethod
    def _java_main_class_from_source(source_path: Path) -> str:
        """Derive a Java main class (FQN) from a .java file by reading its package statement."""
        try:
            lines = source_path.read_text(encoding="utf-8", errors="replace").splitlines()
        except Exception:
            return source_path.stem

        pkg = ""
        for ln in lines[:80]:
            s = ln.strip()
            if s.startswith("package ") and s.endswith(";"):
                pkg = s[len("package "):].rstrip(";").strip()
                break
        return f"{pkg}.{source_path.stem}" if pkg else source_path.stem

    def _ensure_output_dirs_for_cmds(self, cmds: List[str]) -> None:
        """Create output dirs used by javac -d to avoid spurious failures."""
        for cmd_str in cmds or []:
            m = re.search(r"\s-d\s+([^\s]+)", cmd_str)
            if not m:
                continue
            out_dir = m.group(1)
            # Only handle relative paths inside the workdir
            if out_dir.startswith(('/', '~')) or ':' in out_dir:
                continue
            try:
                (self.work_dir / out_dir).mkdir(parents=True, exist_ok=True)
            except Exception:
                pass

    def _extract_json(self, text: str) -> Dict[str, Any]:
        text = (text or "").strip()
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            start = text.find("{")
            end = text.rfind("}")
            if start >= 0 and end > start:
                return json.loads(text[start:end + 1])
            raise

    @staticmethod
    def _sanitize_patch_text(patch: str) -> str:
        """
        Make LLM output more 'git apply' friendly:
        - remove ``` fences
        - trim everything before first diff header
        - normalize newlines and ensure trailing newline
        - fix corrupt diffs caused by blank lines inside hunks
        - fix common LLM mistakes where hunk lines miss the leading ' ' / '+' / '-' marker
        - reconstruct truncated 'diff --git' lines from subsequent ---/+++ headers
        """
        if patch is None:
            return ""

        patch = patch.replace("\r\n", "\n").replace("\r", "\n")
        raw_lines = patch.splitlines()

        # Drop code fences if any
        raw_lines = [ln for ln in raw_lines if not ln.strip().startswith("```")]

        # Trim everything before the first diff header
        start_idx = 0
        for i, ln in enumerate(raw_lines):
            if ln.startswith("diff --git ") or ln.startswith("--- "):
                start_idx = i
                break
        raw_lines = raw_lines[start_idx:]

        out: list[str] = []
        in_hunk = False

        for ln in raw_lines:
            if ln.startswith("@@ "):
                in_hunk = True
                out.append(ln)
                continue

            # leaving a hunk when a new file header starts
            if in_hunk and (ln.startswith("diff --git ") or ln.startswith("--- ") or ln.startswith("+++ ")):
                in_hunk = False

            if in_hunk:
                # In unified diff, every hunk line must start with ' ', '+', '-', or '\'
                if ln == "":
                    out.append(" ")
                    continue
                if ln.startswith("\\ No newline at end of file"):
                    out.append(ln)
                    continue
                if ln[:1] not in (" ", "+", "-", "\\"):
                    # Model forgot the prefix; assume it's a context line.
                    out.append(" " + ln)
                    continue

            out.append(ln)

        # Fix 'diff --git' lines that may be truncated by the LLM by reconstructing
        # them from the subsequent ---/+++ headers.
        fixed: list[str] = []
        i = 0
        while i < len(out):
            ln = out[i]
            if ln.startswith("diff --git "):
                a_path = None
                b_path = None
                j = i + 1
                while j < len(out) and (not out[j].startswith("diff --git ")):
                    if out[j].startswith("--- "):
                        a_path = out[j].split(maxsplit=1)[1].strip()
                    elif out[j].startswith("+++ "):
                        b_path = out[j].split(maxsplit=1)[1].strip()
                        break
                    j += 1
                if a_path and b_path:
                    fixed.append(f"diff --git {a_path} {b_path}")
                    i += 1
                    continue
            fixed.append(ln)
            i += 1

        return "\n".join(fixed).strip() + "\n"



    def _patch_has_git_header(self, patch: str) -> bool:
        return "diff --git " in (patch or "")

    def _guess_p_level(self, patch: str) -> int:
        """
        git apply by default behaves like -p1 (strip one path component).
        For patches without a/ b/ prefixes, we usually want -p0.
        """
        if re.search(r"^---\s+a\/", patch, re.M) or re.search(r"^\+\+\+\s+b\/", patch, re.M) or "diff --git a/" in patch:
            return 1
        return 0

    def _resolve_in_workdir(self, path: str, *, want_dir: bool = False) -> Optional[str]:
        """
        Resolve a possibly-prefixed path (e.g. data/marketing-demo/src/...) to a repo-root-relative path
        that exists under work_dir. Returns normalized relative path, or None if not resolvable.
        """
        if not path:
            return None
        p = str(path).replace("\\", "/").lstrip("/")

        # strip common diff prefixes
        if p.startswith("a/") or p.startswith("b/"):
            p = p[2:]

        # try as-is
        cand = (self.work_dir / p)
        if want_dir and cand.is_dir():
            return p
        if (not want_dir) and cand.is_file():
            return p

        parts = [x for x in p.split("/") if x]
        if not parts:
            return None

        # try suffixes
        for i in range(1, len(parts)):
            suf = "/".join(parts[i:])
            cand2 = (self.work_dir / suf)
            if want_dir and cand2.is_dir():
                return suf
            if (not want_dir) and cand2.is_file():
                return suf

        # directory fallback: if want_dir, also allow existing parent
        if want_dir:
            for i in range(1, len(parts)):
                suf = "/".join(parts[i:])
                cand2 = (self.work_dir / suf)
                if cand2.exists() and cand2.is_dir():
                    return suf
        return None

    def _normalize_plan_paths(self, plan: Dict[str, Any], context_pack: Dict[str, Any]) -> Dict[str, Any]:
        """
        Normalize plan["files_to_change"][].file_path and plan["tool_requests"][].path so they work under work_dir.
        """
        plan = dict(plan)

        # files_to_change
        ftc = plan.get("files_to_change") or []
        new_ftc = []
        for item in ftc:
            item = dict(item)
            fp = (item.get("file_path") or "").strip()
            resolved = self._resolve_in_workdir(fp, want_dir=False)
            if resolved:
                item["file_path"] = resolved
            new_ftc.append(item)
        plan["files_to_change"] = new_ftc

        # tool_requests paths (dirs)
        tr = plan.get("tool_requests") or []
        new_tr = []
        for req in tr:
            req = dict(req)
            p = (req.get("path") or ".").strip() or "."
            resolved_dir = self._resolve_in_workdir(p, want_dir=True)
            req["path"] = resolved_dir or "."
            new_tr.append(req)
        plan["tool_requests"] = new_tr

        # verification commands: keep as-is
        return plan

    def _focus_file_from_context_pack(self, context_pack: Dict[str, Any]) -> Optional[str]:
        focus = (context_pack.get("focus") or {}).get("node_id") or context_pack.get("focus_node")
        if not focus:
            return None
        for n in (context_pack.get("nodes") or []):
            if n.get("node_id") == focus and n.get("file_path"):
                fp = n.get("file_path")
                resolved = self._resolve_in_workdir(fp, want_dir=False)
                return resolved or None
        return None

    def _dump_files_for_prompt(self, plan: Dict[str, Any], context_pack: Dict[str, Any], *, max_chars_per_file: int = 22000) -> str:
        """
        Append exact file contents from the sandbox workdir so the LLM can produce an apply-able patch.
        Uses normalized plan file paths; if missing, falls back to focus file.
        """
        rel_files: List[str] = []
        for f in (plan.get("files_to_change") or []):
            fp = (f.get("file_path") or "").strip()
            if fp:
                rel_files.append(fp)

        if not rel_files:
            focus_fp = self._focus_file_from_context_pack(context_pack)
            if focus_fp:
                rel_files.append(focus_fp)

        # de-dup
        seen = set()
        rel_files = [x for x in rel_files if not (x in seen or seen.add(x))]

        blocks = []
        for rel in rel_files[:6]:
            p = (self.work_dir / rel).resolve()
            if not str(p).startswith(str(self.work_dir)):
                continue
            if not p.exists() or not p.is_file():
                continue
            txt = p.read_text(encoding="utf-8", errors="replace")
            if len(txt) > max_chars_per_file:
                txt = txt[:max_chars_per_file] + "\n/* ... TRUNCATED ... */\n"
            blocks.append(f"\n--- FILE: {rel} ---\n{txt}\n--- END FILE: {rel} ---\n")
        return "\n".join(blocks)

    # ---------------------------
    # Plan / Edit / Repair
    # ---------------------------

    def _plan(self, *, request: str, context_pack: Dict[str, Any]) -> Dict[str, Any]:
        context_txt = context_pack_to_prompt(
            context_pack,
            max_nodes=self.cfg.max_nodes_in_prompt,
            max_snippet_chars=self.cfg.max_snippet_chars,
        )
        messages = [
            {"role": "system", "content": PLAN_SYSTEM},
            {"role": "user", "content": PLAN_USER_TEMPLATE.format(request=request, context=context_txt)},
        ]
        out = self.llm.chat(messages, temperature=0.1, max_tokens=1400)
        plan = self._extract_json(out)
        return plan

    def _run_tool_requests(self, tool_requests: List[Dict[str, Any]]) -> str:
        if not tool_requests:
            return ""
        chunks: List[str] = []
        for req in tool_requests[:6]:
            tool = (req.get("tool") or "").lower()
            if tool in ("ripgrep", "rg"):
                pattern = str(req.get("pattern") or "").strip()
                path = str(req.get("path") or ".").strip() or "."
                if not pattern:
                    continue
                cmd = ["rg", "-n", pattern, path]
                try:
                    res = self.sandbox.run(cmd, cwd=self.work_dir)
                    chunks.append(f"[TOOL rg] cmd={' '.join(cmd)}\n{res.stdout}\n{res.stderr}".strip())
                except Exception as e:
                    chunks.append(f"[TOOL rg ERROR] {e}")
        return "\n\n".join(chunks)

    def _edit(self, *, objective: str, plan: Dict[str, Any], context_pack: Dict[str, Any], extra_tool_info: str = "") -> str:
        context_txt = context_pack_to_prompt(
            context_pack,
            max_nodes=self.cfg.max_nodes_in_prompt,
            max_snippet_chars=self.cfg.max_snippet_chars,
        )
        file_dump = self._dump_files_for_prompt(plan, context_pack)
        if file_dump:
            context_txt += "\n\n=== EXACT REPO FILE CONTENTS (authoritative) ===\n" + file_dump + "\n=== END EXACT FILE CONTENTS ===\n"
        if extra_tool_info:
            context_txt += "\n\n=== Tool outputs ===\n" + extra_tool_info + "\n=== End tool outputs ===\n"

        plan_json = json.dumps(plan, ensure_ascii=False, indent=2)
        messages = [
            {"role": "system", "content": EDIT_SYSTEM},
            {"role": "user", "content": EDIT_USER_TEMPLATE.format(objective=objective, plan_json=plan_json, context=context_txt)},
        ]
        patch = self.llm.chat(messages, temperature=0.2, max_tokens=2600)
        return (patch or "").strip()

    def _repair(self, *, objective: str, plan: Dict[str, Any], context_pack: Dict[str, Any], prev_patch: str, verify_logs: str, extra_tool_info: str = "") -> str:
        context_txt = context_pack_to_prompt(
            context_pack,
            max_nodes=self.cfg.max_nodes_in_prompt,
            max_snippet_chars=self.cfg.max_snippet_chars,
        )
        file_dump = self._dump_files_for_prompt(plan, context_pack)
        if file_dump:
            context_txt += "\n\n=== EXACT REPO FILE CONTENTS (authoritative) ===\n" + file_dump + "\n=== END EXACT FILE CONTENTS ===\n"
        if extra_tool_info:
            context_txt += "\n\n=== Tool outputs ===\n" + extra_tool_info + "\n=== End tool outputs ===\n"

        plan_json = json.dumps(plan, ensure_ascii=False, indent=2)
        messages = [
            {"role": "system", "content": REPAIR_SYSTEM},
            {"role": "user", "content": REPAIR_USER_TEMPLATE.format(
                objective=objective,
                plan_json=plan_json,
                prev_patch=prev_patch,
                verify_logs=verify_logs,
                context=context_txt
            )},
        ]
        patch = self.llm.chat(messages, temperature=0.2, max_tokens=3000)
        return (patch or "").strip()

    # ---------------------------
    # Git patch application
    # ---------------------------

    def _ensure_git_baseline(self, artifacts_dir: Path) -> None:
        if self._git_initialized:
            return
        if not (self.work_dir / ".git").exists():
            self.sandbox.run(["git", "init"], cwd=self.work_dir)
        # set identity to avoid "Please tell me who you are"
        self.sandbox.run(["git", "config", "user.email", "refactor-agent@example.com"], cwd=self.work_dir)
        self.sandbox.run(["git", "config", "user.name", "RefactorAgent"], cwd=self.work_dir)

        self.sandbox.run(["git", "add", "-A"], cwd=self.work_dir)
        # baseline commit (ignore non-zero if nothing to commit)
        _ = self.sandbox.run(["git", "commit", "-m", "baseline"], cwd=self.work_dir)
        self._git_initialized = True

    def _git_reset_clean(self) -> None:
        # restore to baseline commit
        self.sandbox.run(["git", "reset", "--hard", "HEAD"], cwd=self.work_dir)
        self.sandbox.run(["git", "clean", "-fd"], cwd=self.work_dir)

    def _extract_apply_failure_context(self, stderr: str) -> str:
        """
        If stderr contains 'patch failed: <file>:<line>', append an excerpt of that file around the line.
        """
        if not stderr:
            return ""
        m = re.search(r"patch failed:\s+([^\s:]+):(\d+)", stderr)
        if not m:
            return ""
        rel = m.group(1).strip()
        line_no = int(m.group(2))
        resolved = self._resolve_in_workdir(rel, want_dir=False) or rel
        p = (self.work_dir / resolved)
        if not p.exists():
            return ""
        lines = p.read_text(encoding="utf-8", errors="replace").splitlines()
        lo = max(0, line_no - 1 - 20)
        hi = min(len(lines), line_no - 1 + 20)
        excerpt = "\n".join(f"{i+1:04d}: {lines[i]}" for i in range(lo, hi))
        return f"\n[FILE EXCERPT] {resolved} around line {line_no}\n{excerpt}\n"


    # ---------------------------
    # Apply LLM edits (Search/Replace Blocks or Full Rewrite)
    # ---------------------------

    def _apply_llm_output(self, llm_text: str, diff_file: Path) -> Tuple[bool, str]:
        """
        Apply LLM output to the repo working tree.
        Preferred format:
          - FILE: <path>
            <<<<<<< SEARCH
            ...
            =======
            ...
            >>>>>>> REPLACE
          - or:
            FILE: <path>
            <<<<<<< REWRITE
            <full new file content>
            >>>>>>> REWRITE

        Fallback: if the output looks like a unified diff (diff --git), apply via git apply.
        On success, writes `git diff` (against baseline) to diff_file.
        Returns (ok, logs). Logs are suitable to feed to repair.
        """
        (diff_file.parent / (diff_file.stem + "_raw.txt")).write_text(llm_text, encoding="utf-8")

        looks_like_diff = bool(re.search(r"^diff --git ", llm_text.strip(), re.M)) or bool(re.search(r"^---\s+", llm_text.strip(), re.M))
        looks_like_blocks = ("FILE:" in llm_text) or ("<<<<<<< SEARCH" in llm_text) or ("<<<<<<< REWRITE" in llm_text)

        if looks_like_diff and not looks_like_blocks:
            # unified diff path
            tmp_patch = diff_file.parent / (diff_file.stem + "_unified.diff")
            ok, logs = self._git_apply_unified_diff(llm_text, tmp_patch)
            if not ok:
                return False, logs
        else:
            edits, perr = self._parse_edit_instructions(llm_text)
            if perr:
                return False, "[EDIT PARSE ERROR]\n" + perr
            ok, logs = self._apply_edit_instructions(edits)
            if not ok:
                return False, logs

        # On success, persist the actual diff vs baseline
        diff = self.sandbox.run(["git", "diff"], cwd=self.work_dir)
        diff_file.write_text(diff.stdout or "", encoding="utf-8")
        return True, ""

    def _parse_edit_instructions(self, llm_text: str) -> Tuple[List[FileEditInstruction], str]:
        """
        Parse Search/Replace blocks and Full Rewrite blocks from LLM output.
        Expected:
          FILE: path
          <<<<<<< SEARCH
          ...
          =======
          ...
          >>>>>>> REPLACE

        Or:
          FILE: path
          <<<<<<< REWRITE
          ...
          >>>>>>> REWRITE

        Returns (edits, error_message). error_message == "" when ok.
        """
        if llm_text is None:
            return [], "Empty output."

        t = llm_text.replace("\r\n", "\n").replace("\r", "\n")
        lines = t.split("\n")

        edits: List[FileEditInstruction] = []
        cur: Optional[FileEditInstruction] = None

        def finish_current():
            nonlocal cur
            if cur is not None:
                if cur.blocks is None:
                    cur.blocks = []
                edits.append(cur)
                cur = None

        i = 0
        while i < len(lines):
            ln = lines[i]
            m = re.match(r"^\s*FILE:\s*(.+?)\s*$", ln)
            if m:
                finish_current()
                cur = FileEditInstruction(path=m.group(1).strip(), blocks=[], rewrite=None)
                i += 1
                continue

            if cur is None:
                i += 1
                continue

            if ln.strip() == "<<<<<<< SEARCH":
                i += 1
                search_lines = []
                while i < len(lines) and lines[i].strip() != "=======":
                    search_lines.append(lines[i])
                    i += 1
                if i >= len(lines) or lines[i].strip() != "=======":
                    return [], f"Missing '=======' after SEARCH block in file {cur.path}."
                i += 1
                replace_lines = []
                while i < len(lines) and lines[i].strip() != ">>>>>>> REPLACE":
                    replace_lines.append(lines[i])
                    i += 1
                if i >= len(lines) or lines[i].strip() != ">>>>>>> REPLACE":
                    return [], f"Missing '>>>>>>> REPLACE' after REPLACE block in file {cur.path}."
                i += 1
                cur.blocks.append(SearchReplaceBlock(search="\n".join(search_lines), replace="\n".join(replace_lines)))
                continue

            if ln.strip() == "<<<<<<< REWRITE":
                i += 1
                rewrite_lines = []
                while i < len(lines) and lines[i].strip() != ">>>>>>> REWRITE":
                    rewrite_lines.append(lines[i])
                    i += 1
                if i >= len(lines) or lines[i].strip() != ">>>>>>> REWRITE":
                    return [], f"Missing '>>>>>>> REWRITE' for file {cur.path}."
                i += 1
                cur.rewrite = "\n".join(rewrite_lines)
                continue

            i += 1

        finish_current()

        if not edits:
            return [], "No FILE: sections found. Output must start with one or more 'FILE: <path>' headers."
        # Validate
        bad = [e.path for e in edits if not e.path]
        if bad:
            return [], f"Empty FILE path in sections: {bad}"
        return edits, ""

    def _apply_edit_instructions(self, edits: List[FileEditInstruction]) -> Tuple[bool, str]:
        """
        Apply parsed edits to the working tree. Strict by default:
          - SEARCH text must match EXACTLY once
          - REWRITE replaces entire file contents
        """
        logs: List[str] = []
        for e in edits:
            rel = e.path.strip()
            resolved = self._resolve_in_workdir(rel, want_dir=False) or rel.lstrip("/")
            p = self.work_dir / resolved
            if not p.exists() and e.rewrite is None:
                logs.append(f"[EDIT APPLY ERROR] File not found: {resolved}")
                continue

            if e.rewrite is not None:
                p.parent.mkdir(parents=True, exist_ok=True)
                new_text = e.rewrite.replace("\r\n", "\n").replace("\r", "\n")
                if not new_text.endswith("\n"):
                    new_text += "\n"
                p.write_text(new_text, encoding="utf-8")
                continue

            # Search/Replace blocks
            file_text = p.read_text(encoding="utf-8").replace("\r\n", "\n").replace("\r", "\n")
            for bi, blk in enumerate(e.blocks or [], start=1):
                search = blk.search.replace("\r\n", "\n").replace("\r", "\n")
                replace = blk.replace.replace("\r\n", "\n").replace("\r", "\n")
                if search == "":
                    logs.append(f"[EDIT APPLY ERROR] Empty SEARCH block in {resolved} (block #{bi}).")
                    continue

                occ = file_text.count(search)
                if occ == 0:
                    # Provide fuzzy hint
                    hint = self._best_fuzzy_match_hint(file_text, search)
                    logs.append(
                        f"[EDIT APPLY ERROR] SEARCH block not found in {resolved} (block #{bi}).\n"
                        f"[SEARCH]\n{search[:800]}\n"
                        f"{hint}"
                    )
                    continue
                if occ > 1:
                    logs.append(
                        f"[EDIT APPLY ERROR] SEARCH block matched {occ} times in {resolved} (block #{bi}). "
                        "Make SEARCH more specific.\n"
                        f"[SEARCH]\n{search[:800]}\n"
                    )
                    continue

                file_text = file_text.replace(search, replace, 1)

            # Only write back if no errors for this file
            if not any(msg.startswith("[EDIT APPLY ERROR]") and f" {resolved}" in msg for msg in logs):
                if not file_text.endswith("\n"):
                    file_text += "\n"
                p.write_text(file_text, encoding="utf-8")

        if logs:
            return False, "\n".join(logs)
        return True, ""

    def _best_fuzzy_match_hint(self, file_text: str, search: str) -> str:
        """
        Best-effort hint for repair: find the most similar window in the file for the given search block.
        """
        try:
            file_lines = file_text.split("\n")
            search_lines = search.split("\n")
            n = len(search_lines)
            if n == 0:
                return ""

            # Limit scanning for performance on huge files
            max_lines = min(len(file_lines), 4000)
            file_lines = file_lines[:max_lines]

            best = (0.0, 0)  # (ratio, start_idx)
            search_join = "\n".join(search_lines)
            for i in range(0, max_lines - n + 1):
                window = "\n".join(file_lines[i:i+n])
                r = difflib.SequenceMatcher(None, search_join, window).ratio()
                if r > best[0]:
                    best = (r, i)
            ratio, idx = best
            if ratio < 0.35:
                return ""
            start = max(idx - 2, 0)
            end = min(idx + n + 2, len(file_lines))
            snippet = "\n".join(file_lines[start:end])
            return f"[FUZZY HINT] Best approx match near line {idx+1} (similarity {ratio:.2f}):\n{snippet}\n"
        except Exception:
            return ""

    def _git_apply_unified_diff(self, patch_text: str, patch_file: Path) -> Tuple[bool, str]:
        """
        Apply patch in work_dir. Returns (ok, logs). Logs are suitable to feed to repair.
        """
        patch_text = self._sanitize_patch_text(patch_text)

        patch_file.write_text(patch_text, encoding="utf-8")

        p_level = self._guess_p_level(patch_text)
        has_git_header = self._patch_has_git_header(patch_text)

        check_cmd = ["git", "apply", "--check", f"-p{p_level}", "--whitespace=nowarn", str(patch_file)]
        check = self.sandbox.run(check_cmd, cwd=self.work_dir)

        # If it's corrupt patch, stop early
        if (not check.ok) and ("corrupt patch" in (check.stderr or "")):
            return False, f"[PATCH APPLY ERROR]\n{check.stdout}\n{check.stderr}"

        # Try apply (3way only if git header exists)
        apply_cmd = ["git", "apply", f"-p{p_level}", "--whitespace=nowarn"]
        if has_git_header:
            apply_cmd.insert(2, "--3way")

        res = self.sandbox.run(apply_cmd + [str(patch_file)], cwd=self.work_dir)
        if res.ok:
            return True, ""

        # Fallback: try toggling p-level once (useful if LLM omitted a/b prefixes)
        alt_p = 0 if p_level == 1 else 1
        apply_cmd2 = ["git", "apply", f"-p{alt_p}", "--whitespace=nowarn"]
        if has_git_header:
            apply_cmd2.insert(2, "--3way")
        res2 = self.sandbox.run(apply_cmd2 + [str(patch_file)], cwd=self.work_dir)
        if res2.ok:
            return True, ""

        extra = self._extract_apply_failure_context(res.stderr + "\n" + res2.stderr)
        logs = (
            "[PATCH APPLY ERROR]\n"
            f"[CHECK CMD] {' '.join(check_cmd)}\n{check.stdout}\n{check.stderr}\n"
            f"[APPLY CMD] {' '.join(apply_cmd)} {patch_file.name}\n{res.stdout}\n{res.stderr}\n"
            f"[APPLY CMD ALT] {' '.join(apply_cmd2)} {patch_file.name}\n{res2.stdout}\n{res2.stderr}\n"
            f"{extra}"
        )
        return False, logs

    # ---------------------------
    # Verify
    # ---------------------------

    def _verify(self, plan: Dict[str, Any]) -> Tuple[bool, str]:
        cmds: List[str] = []

        # Prefer deterministic verification commands from config / auto-detect.
        # LLM-generated verification commands are often incorrect (classpath, globs, etc.),
        # so we only use them when explicitly enabled.
        if self.cfg.use_plan_verification:
            for v in plan.get("verification", []) or []:
                cmd_str = (v.get("cmd") or "").strip()
                if cmd_str:
                    cmds.append(cmd_str)

        if not cmds:
            cmds = list(self.cfg.default_verify_cmds or [])

        # As a last resort, fall back to plan verification (if any)
        if not cmds:
            for v in plan.get("verification", []) or []:
                cmd_str = (v.get("cmd") or "").strip()
                if cmd_str:
                    cmds.append(cmd_str)

        # Pre-create output dirs used by javac -d ...
        self._ensure_output_dirs_for_cmds(cmds)

        logs: List[str] = []
        ok = True
        for cmd_str in cmds:
            cmd = self.sandbox.split_cmd(cmd_str)
            try:
                res = self.sandbox.run(cmd, cwd=self.work_dir)
                logs.append(_format_cmd_result(res))
                if not res.ok:
                    ok = False
            except Exception as e:
                ok = False
                logs.append(f"[VERIFY ERROR] cmd={cmd_str}\n{e}")
        return ok, "\n\n".join(logs)

    # ---------------------------
    # Main loop
    # ---------------------------

    def run(self, *, request: str, context_pack: Dict[str, Any]) -> Dict[str, Any]:
        run_dir = self.work_dir
        artifacts = run_dir / ".agent_artifacts"
        artifacts.mkdir(parents=True, exist_ok=True)

        raw_plan = self._plan(request=request, context_pack=context_pack)
        plan = self._normalize_plan_paths(raw_plan, context_pack)
        objective = request
        # plan["objective_summary"] = plan.get("objective")

        tool_info = self._run_tool_requests(plan.get("tool_requests", []) or [])
        (artifacts / "plan.json").write_text(json.dumps(plan, ensure_ascii=False, indent=2), encoding="utf-8")
        if tool_info:
            (artifacts / "tool_outputs.txt").write_text(tool_info, encoding="utf-8")

        # Git baseline
        self._ensure_git_baseline(artifacts)

        prev_patch = ""
        last_logs = ""
        modified_files: List[str] = []

        for it in range(1, self.cfg.max_iters + 1):
            # Always reset to baseline between attempts
            self._git_reset_clean()

            if it == 1:
                patch = self._edit(objective=objective, plan=plan, context_pack=context_pack, extra_tool_info=tool_info)
            else:
                patch = self._repair(objective=objective, plan=plan, context_pack=context_pack, prev_patch=prev_patch, verify_logs=last_logs, extra_tool_info=tool_info)

            llm_out_file = artifacts / f"llm_output_{it}.txt"
            llm_out_file.write_text(patch, encoding="utf-8")
            diff_file = artifacts / f"patch_attempt_{it}.diff"
            ok_apply, apply_logs = self._apply_llm_output(patch, diff_file)
            if not ok_apply:
                last_logs = apply_logs
                (artifacts / f"verify_attempt_{it}.txt").write_text(last_logs, encoding="utf-8")
                prev_patch = patch
                continue

            verify_ok, verify_logs = self._verify(plan)
            (artifacts / f"verify_attempt_{it}.txt").write_text(verify_logs, encoding="utf-8")

            if verify_ok:
                # Collect modified files for reporting
                diff_names = self.sandbox.run(["git", "diff", "--name-only"], cwd=self.work_dir)
                modified_files = [ln.strip() for ln in diff_names.stdout.splitlines() if ln.strip()]

                summary = {
                    "status": "success",
                    "attempts": it,
                    "work_dir": str(run_dir),
                    "artifacts_dir": str(artifacts),
                    "modified_files": modified_files,
                    "objective": objective,
                }
                (artifacts / "summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
                return summary

            last_logs = verify_logs
            prev_patch = patch

        summary = {
            "status": "failed",
            "attempts": self.cfg.max_iters,
            "work_dir": str(run_dir),
            "artifacts_dir": str(artifacts),
            "modified_files": modified_files,
            "objective": objective,
        }
        (artifacts / "summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
        return summary


def _format_cmd_result(res: CommandResult) -> str:
    cmd_str = " ".join(res.cmd)
    return (
        f"[CMD] {cmd_str}\n"
        f"[RET] {res.returncode}\n"
        f"[STDOUT]\n{res.stdout}\n"
        f"[STDERR]\n{res.stderr}\n"
    )

==================== END FILE ====================


==================== FILE: src/context_engine.py ====================
"""
Graph-RAG Context Engine

Goal:
- Given a natural language query, first do vector search over graph nodes to find seed(s).
- Then expand the graph neighborhood (k-hop + rule-based expansion).
- Finally output a structured "Context Pack" (like IDE refactoring preview).

This is the *bridge* between your graph builder and the future refactoring agent.
"""
from __future__ import annotations

from collections import defaultdict, deque
from dataclasses import dataclass
from typing import Dict, List, Optional, Set, Tuple

import networkx as nx

from .utils import load_snippet
from .vector_index import NodeVectorIndex, ScoredNode


@dataclass
class ContextNode:
    node_id: str
    name: str
    type: str
    file_path: str
    start_line: int
    end_line: int
    signature: str
    docstring: str
    snippet: str
    role: str
    roles: List[str]
    highlight_span: Optional[Dict[str, int]]
    why: List[str]


class GraphRAGContextEngine:
    def __init__(
        self,
        graph: nx.DiGraph,
        vector_index: NodeVectorIndex,
        *,
        max_snippet_lines: int = 120,
    ) -> None:
        self.graph = graph
        self.vindex = vector_index
        self.max_snippet_lines = max_snippet_lines

        # Precompute helper indexes for rule-based expansion
        self.class_to_members: Dict[str, Set[str]] = defaultdict(set)
        self.file_to_nodes: Dict[str, Set[str]] = defaultdict(set)
        self.field_to_methods: Dict[str, Set[str]] = defaultdict(set)

        self._build_aux_indexes()

    def _build_aux_indexes(self) -> None:
        # class_to_members + file_to_nodes
        for nid, attrs in self.graph.nodes(data=True):
            cls = attrs.get("class") or (nid if attrs.get("type") == "Class" else None)
            if cls:
                self.class_to_members[str(cls)].add(nid)
            fp = attrs.get("file_path")
            if fp:
                self.file_to_nodes[str(fp)].add(nid)

        # field_to_methods via READS/WRITES edges
        for u, v, attrs in self.graph.edges(data=True):
            rel = attrs.get("relation") or attrs.get("type")
            if rel in ("READS", "WRITES"):
                # v should be a field node (or unresolved)
                self.field_to_methods[str(v)].add(str(u))

    # -------------------------
    # Public API
    # -------------------------
    def query(
        self,
        query: str,
        *,
        seed_top_k: int = 5,
        hops: int = 2,
        max_nodes: int = 30,
        same_class_limit: int = 8,
        same_file_limit: int = 8,
        shared_field_limit: int = 10,
    ) -> Dict:
        """
        Return a structured context pack.

        Parameters:
        - query: natural language or a node_id (if exact match)
        """
        seeds = self._select_seeds(query, seed_top_k=seed_top_k)

        selected: Set[str] = set()
        reasons: Dict[str, List[str]] = defaultdict(list)
        roles: Dict[str, Set[str]] = defaultdict(set)

        def add(nid: str, why: str, role: Optional[str] = None) -> None:
            if not nid:
                return
            if nid not in selected:
                selected.add(nid)
            if why and why not in reasons[nid]:
                reasons[nid].append(why)
            if role:
                roles[nid].add(role)

        # If query is an exact node id, mark it as focus; otherwise take top seed.
        focus_node_id = query if query in self.graph else (seeds[0].node_id if seeds else "")

        # Always include focus (even when it is not selected by seeds for some reason).
        if focus_node_id:
            add(focus_node_id, "focus node", role="focus")

        # 1) add seed nodes
        for s in seeds:
            add(s.node_id, f"seed via vector search (score={s.score:.3f})", role="seed")

        # 2) call graph expansion: separate callees vs callers (IDE-like preview)
        callees = self._expand_relation_dir([focus_node_id], relation="CALLS", hops=hops, direction="out")
        callers = self._expand_relation_dir([focus_node_id], relation="CALLS", hops=hops, direction="in")
        for nid, depth in callees.items():
            add(nid, f"call-graph neighbor (CALLEE, depth={depth})", role="callee")
        for nid, depth in callers.items():
            add(nid, f"call-graph neighbor (CALLER, depth={depth})", role="caller")

        # 3) same-class members (siblings of focus)
        focus_cls = self.graph.nodes[focus_node_id].get("class") if focus_node_id in self.graph else None
        if focus_cls:
            members = list(self.class_to_members.get(str(focus_cls), set()))
            members = [m for m in members if self.graph.nodes[m].get("type") != "Class"]
            # Keep bounded
            for m in members[:same_class_limit]:
                add(m, f"same class member of {focus_cls}", role="same_class_member")

        # 4) shared field access: focus method -> field -> other methods (READS/WRITES separated)
        read_fields: Set[str] = set()
        written_fields: Set[str] = set()
        if focus_node_id:
            for _, v, attrs in self.graph.out_edges(focus_node_id, data=True):
                rel = attrs.get("relation") or attrs.get("type")
                if rel == "READS":
                    read_fields.add(str(v))
                elif rel == "WRITES":
                    written_fields.add(str(v))

        touched_fields = list(read_fields | written_fields)
        for f in touched_fields[:shared_field_limit]:
            add(f, "shared state (field accessed by focus)", role="shared_field")
            # Identify readers/writers of that field
            for u, _, attrs in self.graph.in_edges(f, data=True):
                rel = attrs.get("relation") or attrs.get("type")
                if rel == "READS":
                    add(u, f"shares field {f} (READS)", role="shared_field_reader")
                elif rel == "WRITES":
                    add(u, f"shares field {f} (WRITES)", role="shared_field_writer")

        # 5) same-file helpers: nodes in same file as focus (bounded)
        fp = self.graph.nodes[focus_node_id].get("file_path") if focus_node_id in self.graph else None
        if fp:
            nodes = list(self.file_to_nodes.get(str(fp), set()))
            nodes.sort(key=lambda nid: 0 if self.graph.nodes[nid].get("type") in ("Method", "Field") else 1)
            for nid in nodes[:same_file_limit]:
                add(nid, f"same file helper ({fp})", role="same_file_helper")

        # Enforce max_nodes budget
        if len(selected) > max_nodes:
            # Keep focus + seeds first, then by number of roles/reasons.
            seed_ids = [s.node_id for s in seeds]
            keep: List[str] = []
            if focus_node_id and focus_node_id in selected:
                keep.append(focus_node_id)
            for nid in seed_ids:
                if nid in selected and nid not in keep:
                    keep.append(nid)
            remaining = [nid for nid in selected if nid not in keep]
            remaining.sort(
                key=lambda nid: (len(roles.get(nid, set())), len(reasons.get(nid, []))),
                reverse=True,
            )
            keep.extend(remaining[: max_nodes - len(keep)])
            selected = set(keep)

        # Build node payloads (stable ordering like an IDE preview)
        nodes_payload = [
            self._build_context_node(
                nid,
                reasons[nid],
                roles=sorted(list(roles.get(nid, set()))),
                focus_id=focus_node_id,
            )
            for nid in selected
        ]

        # Sort nodes by role priority
        role_priority = {
            "focus": 0,
            "seed": 1,
            "callee": 2,
            "caller": 2,
            "shared_field_writer": 3,
            "shared_field_reader": 4,
            "shared_field": 5,
            "same_class_member": 6,
            "same_file_helper": 7,
        }

        def _node_sort_key(n: Dict) -> Tuple[int, str]:
            rls = n.get("roles") or []
            pri = min([role_priority.get(r, 99) for r in rls] or [99])
            return pri, str(n.get("node_id"))

        nodes_payload = sorted([node.__dict__ for node in nodes_payload], key=_node_sort_key)

        # Collect edges among selected nodes for explainability
        edges_payload = []
        for u, v, attrs in self.graph.edges(data=True):
            if u in selected and v in selected:
                edges_payload.append({
                    "source": u,
                    "target": v,
                    "relation": attrs.get("relation") or attrs.get("type"),
                    "file_path": attrs.get("file_path"),
                    "line": attrs.get("line"),
                })

        # IDE-style grouped views
        call_graph_view = {
            "callees": [{"node_id": nid, "depth": d} for nid, d in sorted(callees.items(), key=lambda kv: kv[1]) if nid in selected],
            "callers": [{"node_id": nid, "depth": d} for nid, d in sorted(callers.items(), key=lambda kv: kv[1]) if nid in selected],
        }

        # For IDE preview, keep fields separated by access type
        data_flow_view = {
            "read_fields": [fid for fid in sorted(read_fields) if fid in selected],
            "written_fields": [fid for fid in sorted(written_fields) if fid in selected],
        }

        same_class_view: List[str] = []
        if focus_cls:
            same_class_view = sorted([nid for nid in list(self.class_to_members.get(str(focus_cls), set())) if nid in selected])

        same_file_view: List[str] = []
        if fp:
            same_file_view = sorted([nid for nid in list(self.file_to_nodes.get(str(fp), set())) if nid in selected])

        return {
            "query": query,
            "focus_node": focus_node_id,
            "seed_nodes": [{"node_id": s.node_id, "score": s.score} for s in seeds],
            "nodes": nodes_payload,
            "edges": edges_payload,
            # New: IDE preview sub-views
            "focus": {"node_id": focus_node_id},
            "call_graph": call_graph_view,
            "data_flow": data_flow_view,
            "same_class": same_class_view,
            "same_file": same_file_view,
            "stats": {
                "seed_top_k": seed_top_k,
                "hops": hops,
                "selected_nodes": len(nodes_payload),
                "selected_edges": len(edges_payload),
            },
        }

    # -------------------------
    # Seed selection
    # -------------------------
    def _select_seeds(self, query: str, seed_top_k: int) -> List[ScoredNode]:
        if query in self.graph:
            return [ScoredNode(node_id=query, score=1.0)]
        return self.vindex.search(query, top_k=seed_top_k, min_score=0.0)

    # -------------------------
    # Graph expansion helpers
    # -------------------------
    def _expand_relation_dir(self, start_nodes: List[str], relation: str, hops: int, direction: str) -> Dict[str, int]:
        """Direction-aware BFS expansion.

        direction:
          - "out": follow out_edges (caller -> callee)
          - "in":  follow in_edges  (callee <- caller)
        Returns: node_id -> min depth (>=1)
        """
        if not start_nodes or not any(bool(s) for s in start_nodes):
            return {}
        depth_map: Dict[str, int] = {}
        q: deque[Tuple[str, int]] = deque()
        visited: Set[str] = set()

        for s in start_nodes:
            if not s:
                continue
            q.append((s, 0))
            visited.add(s)

        while q:
            nid, d = q.popleft()
            if d >= hops:
                continue

            if direction == "out":
                edges = self.graph.out_edges(nid, data=True)
                for _, v, attrs in edges:
                    rel = attrs.get("relation") or attrs.get("type")
                    if rel != relation:
                        continue
                    if v not in visited:
                        visited.add(v)
                        depth_map[str(v)] = min(depth_map.get(str(v), 10**9), d + 1)
                        q.append((v, d + 1))
            else:
                edges = self.graph.in_edges(nid, data=True)
                for u, _, attrs in edges:
                    rel = attrs.get("relation") or attrs.get("type")
                    if rel != relation:
                        continue
                    if u not in visited:
                        visited.add(u)
                        depth_map[str(u)] = min(depth_map.get(str(u), 10**9), d + 1)
                        q.append((u, d + 1))

        for s in start_nodes:
            depth_map.pop(s, None)
        return depth_map

    def _expand_relation(self, seeds: List[str], relation: str, hops: int) -> Dict[str, int]:
        """
        Expand by following edges (both directions) that match `relation` up to `hops`.
        Returns: node_id -> min depth
        """
        depth_map: Dict[str, int] = {}
        q: deque[Tuple[str, int]] = deque()
        visited: Set[str] = set()

        for s in seeds:
            q.append((s, 0))
            visited.add(s)

        while q:
            nid, d = q.popleft()
            if d >= hops:
                continue

            # out edges
            for _, v, attrs in self.graph.out_edges(nid, data=True):
                rel = attrs.get("relation") or attrs.get("type")
                if rel != relation:
                    continue
                if v not in visited:
                    visited.add(v)
                    depth_map[str(v)] = min(depth_map.get(str(v), 10**9), d + 1)
                    q.append((v, d + 1))

            # in edges
            for u, _, attrs in self.graph.in_edges(nid, data=True):
                rel = attrs.get("relation") or attrs.get("type")
                if rel != relation:
                    continue
                if u not in visited:
                    visited.add(u)
                    depth_map[str(u)] = min(depth_map.get(str(u), 10**9), d + 1)
                    q.append((u, d + 1))

        # Remove seeds
        for s in seeds:
            depth_map.pop(s, None)
        return depth_map

    # -------------------------
    # Node payload
    # -------------------------
    def _build_context_node(
        self,
        node_id: str,
        why: List[str],
        *,
        roles: List[str],
        focus_id: str,
    ) -> ContextNode:
        """Build a traceable, IDE-like node payload.

        roles: all roles assigned during selection.
        focus_id: focus node id (used for ...)
        """
        attrs = self.graph.nodes[node_id]
        ntype = str(attrs.get("type", "Unknown"))
        name = str(attrs.get("name") or node_id)
        fp = str(attrs.get("file_path", "") or "")
        start_line = int(attrs.get("start_line", 0) or 0)
        end_line = int(attrs.get("end_line", 0) or 0)
        signature = str(attrs.get("signature", "") or "")
        docstring = str(attrs.get("docstring", "") or "")

        snippet = ""
        if fp and start_line and end_line:
            snippet = load_snippet(fp, start_line, end_line, max_lines=self.max_snippet_lines)

        # Primary role (for UI / sorting) based on a simple priority.
        role_priority = {
            "focus": 0,
            "seed": 1,
            "callee": 2,
            "caller": 2,
            "shared_field_writer": 3,
            "shared_field_reader": 4,
            "shared_field": 5,
            "same_class_member": 6,
            "same_file_helper": 7,
        }
        primary_role = "other"
        if node_id == focus_id and "focus" not in roles:
            roles = ["focus"] + roles
        if roles:
            primary_role = sorted(roles, key=lambda r: role_priority.get(r, 99))[0]

        # Highlight span (approx): find the first occurrence of the symbol name in the snippet.
        highlight_span: Optional[Dict[str, int]] = None
        token = str(attrs.get("name") or "")
        if snippet and token and start_line:
            for idx, line in enumerate(snippet.splitlines()):
                if token in line:
                    highlight_span = {"start_line": start_line + idx, "end_line": start_line + idx}
                    break
        if highlight_span is None and fp and start_line:
            highlight_span = {"start_line": start_line, "end_line": start_line}

        return ContextNode(
            node_id=node_id,
            name=name,
            type=ntype,
            file_path=fp,
            start_line=start_line,
            end_line=end_line,
            signature=signature,
            docstring=docstring,
            snippet=snippet,
            role=primary_role,
            roles=roles,
            highlight_span=highlight_span,
            why=why,
        )

==================== END FILE ====================


==================== FILE: src/graph_builder.py ====================
"""
Build a NetworkX code knowledge graph with traceable nodes.

The graph is designed for two purposes:
1) Visualization (optional)
2) Retrieval-time neighborhood expansion (Graph-RAG)
"""
from __future__ import annotations

from typing import Dict, Iterable, List, Optional, Tuple

import networkx as nx


class CodeGraphBuilder:
    def __init__(self) -> None:
        self.graph = nx.DiGraph()

    def build_from_parsed_data(self, data: Dict) -> None:
        """
        Data format is produced by src.parser.JavaCodeParser.parse_project().
        """
        classes = data.get("classes", [])
        methods = data.get("methods", [])
        fields = data.get("fields", [])
        relationships = data.get("relationships", [])

        print(
            f"ðŸ“Š [GraphBuilder] classes={len(classes)} methods={len(methods)} fields={len(fields)} rels={len(relationships)}"
        )

        # 1) Add class nodes
        for cls in classes:
            node_id = cls["id"]
            self.graph.add_node(
                node_id,
                **cls,
            )

        # 2) Add field nodes (+ membership edges)
        for fld in fields:
            node_id = fld["id"]
            self.graph.add_node(node_id, **fld)
            class_id = fld.get("class")
            if class_id:
                self.graph.add_edge(class_id, node_id, relation="CONTAINS", type="CONTAINS")

        # 3) Add method nodes (+ membership edges)
        for m in methods:
            node_id = m["id"]
            self.graph.add_node(node_id, **m)
            class_id = m.get("class")
            if class_id:
                self.graph.add_edge(class_id, node_id, relation="CONTAINS", type="CONTAINS")

        # Helper: normalize relationship targets.
        # We preserve explicit namespaces produced by the parser:
        #   - EXTERNAL::...
        #   - UNRESOLVED::...
        #   - UNRESOLVED_FIELD::...
        # so we don't double-prefix them.
        def _normalize_target_id(source_id: str, target_raw: str) -> str:
            if target_raw in self.graph:
                return target_raw
            if target_raw.startswith(("EXTERNAL::", "UNRESOLVED::", "UNRESOLVED_FIELD::")):
                return target_raw
            # If target looks like a fully qualified id and doesn't exist, keep it anyway.
            if "." in target_raw and "::" not in target_raw:
                return target_raw
            return f"UNRESOLVED::{target_raw}"

        # 4) Add relationship edges
        for rel in relationships:
            src = rel["source"]
            tgt_raw = rel["target"]
            rel_type = rel["type"]

            if src not in self.graph:
                # Create minimal node for source if missing
                self.graph.add_node(src, id=src, type="Unknown", name=src)

            tgt = _normalize_target_id(src, tgt_raw)
            if tgt not in self.graph:
                # Create minimal node for unresolved/external targets
                node_type = "Unresolved"
                display_name = tgt_raw
                if tgt.startswith("EXTERNAL::"):
                    node_type = "External"
                    display_name = tgt.split("::", 1)[1]
                elif tgt.startswith("UNRESOLVED_FIELD::"):
                    node_type = "Unresolved"
                    display_name = tgt.split("::", 1)[1]
                elif tgt.startswith("UNRESOLVED::"):
                    node_type = "Unresolved"
                    display_name = tgt.split("::", 1)[1]

                self.graph.add_node(tgt, id=tgt, type=node_type, name=display_name)

            self.graph.add_edge(
                src,
                tgt,
                relation=rel_type,
                type=rel_type,
                file_path=rel.get("file_path"),
                line=rel.get("line"),
            )

    def get_graph(self) -> nx.DiGraph:
        return self.graph

    # Optional: visualize graph (requires pyvis)
    def visualize(self, output_file: str = "code_graph.html") -> None:
        try:
            from pyvis.network import Network  # type: ignore
        except Exception as e:
            raise ImportError(
                "pyvis is required for visualization. Install with: pip install pyvis"
            ) from e

        net = Network(height="900px", width="100%", directed=True)

        # Add nodes with lightweight styling based on type
        for node_id, attrs in self.graph.nodes(data=True):
            ntype = attrs.get("type", "Unknown")
            title_parts = [f"{ntype}: {node_id}"]
            for k in ("file_path", "start_line", "end_line", "signature"):
                if attrs.get(k):
                    title_parts.append(f"{k}: {attrs.get(k)}")
            title = "\n".join(title_parts)

            color = "#CCCCCC"
            shape = "dot"
            if ntype == "Class":
                color = "#FF9999"
                shape = "box"
            elif ntype == "Method":
                color = "#99CCFF"
                shape = "ellipse"
            elif ntype == "Field":
                color = "#90EE90"
                shape = "dot"

            net.add_node(node_id, label=attrs.get("name", node_id), title=title, color=color, shape=shape)

        for u, v, attrs in self.graph.edges(data=True):
            rel = attrs.get("relation", "")
            net.add_edge(u, v, label=rel, title=rel, arrows="to")

        net.show(output_file)
        print(f"ðŸ–¼ï¸ [Visualizer] saved: {output_file}")

==================== END FILE ====================


==================== FILE: src/agent/__init__.py ====================

==================== END FILE ====================


==================== FILE: src/agent/llm.py ====================
from __future__ import annotations

import json
import os
import time
import urllib.request
import urllib.error
from dataclasses import dataclass
from ..dotenv import auto_load_dotenv
from typing import Any, Dict, List, Optional, Protocol, Tuple


class LLMClient(Protocol):
    def chat(self, messages: List[Dict[str, str]], *, temperature: float = 0.2, max_tokens: int = 1800) -> str:
        ...


@dataclass
class OpenAICompatibleConfig:
    """
    A minimal OpenAI-compatible Chat Completions config.

    Works with:
      - OpenAI (if /v1/chat/completions is enabled)
      - Many self-hosted servers (vLLM / LM Studio / OpenRouter-like gateways) that expose OpenAI-style endpoints.
    """
    base_url: str = "https://api.openai.com"
    api_key: Optional[str] = None
    model: str = "gpt-4.1-mini"
    timeout_s: int = 120
    max_retries: int = 2
    retry_backoff_s: float = 1.5
    # If True, do not verify TLS certs (NOT recommended). Kept for corporate proxies edge cases.
    insecure_skip_verify: bool = False


class OpenAICompatibleChatClient:
    def __init__(self, cfg: OpenAICompatibleConfig):
        self.cfg = cfg
        if not self.cfg.api_key:
            # Try loading from a local .env file (common in research demos).
            auto_load_dotenv(os.environ.get("REFAC_DOTENV") or os.environ.get("DOTENV_PATH"))
            self.cfg.api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("OPENAI_APIKEY")

    def chat(self, messages: List[Dict[str, str]], *, temperature: float = 0.2, max_tokens: int = 1800) -> str:
        if not self.cfg.api_key:
            raise RuntimeError(
                "Missing API key. Set OpenAICompatibleConfig.api_key or environment variable OPENAI_API_KEY."
            )
        url = self.cfg.base_url.rstrip("/") + "/v1/chat/completions"

        payload = {
            "model": self.cfg.model,
            "messages": messages,
            "temperature": float(temperature),
            "max_tokens": int(max_tokens),
        }
        data = json.dumps(payload).encode("utf-8")

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.cfg.api_key}",
        }

        last_err: Optional[Exception] = None
        for attempt in range(self.cfg.max_retries + 1):
            try:
                req = urllib.request.Request(url, data=data, headers=headers, method="POST")
                ctx = None
                if self.cfg.insecure_skip_verify:
                    import ssl
                    ctx = ssl._create_unverified_context()
                with urllib.request.urlopen(req, timeout=self.cfg.timeout_s, context=ctx) as resp:
                    raw = resp.read().decode("utf-8", errors="replace")
                obj = json.loads(raw)
                # OpenAI-style response: choices[0].message.content
                return obj["choices"][0]["message"]["content"]
            except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError, json.JSONDecodeError, KeyError) as e:
                last_err = e
                if attempt >= self.cfg.max_retries:
                    break
                time.sleep(self.cfg.retry_backoff_s * (attempt + 1))
        raise RuntimeError(f"LLM request failed after retries: {last_err}") from last_err


class DummyEchoLLM:
    """
    For dry-runs without an API key.

    This dummy client tries to be *structurally compatible* with the agent:
      - For planning prompts that require STRICT JSON, it returns a minimal valid plan.
      - For edit/repair prompts, it returns a harmless "create a new file" rewrite
        so the patch parser/apply step succeeds and verification can run.

    IMPORTANT: This does NOT attempt to accomplish the user's refactoring request.
    """
    def chat(self, messages: List[Dict[str, str]], *, temperature: float = 0.2, max_tokens: int = 1800) -> str:
        system = ""
        for m in messages:
            if m.get("role") == "system":
                system = str(m.get("content") or "")
                break

        # 1) Plan stage: must be valid JSON
        if "Return STRICT JSON" in system and "refactoring plan" in system.lower():
            plan = {
                "objective": "DRY RUN (no-op)",
                "assumptions": ["This is a dry run using DummyEchoLLM."],
                "steps": ["Do not change code."],
                "files_to_change": [],
                "verification": [],
                "tool_requests": [],
            }
            return json.dumps(plan)

        # 2) Edit/repair stage: return a valid edit instruction that applies cleanly
        if "output ONLY edit instructions" in system:
            return (
                "FILE: DRY_RUN_NOOP.txt\n"
                "<<<<<<< REWRITE\n"
                "DRY RUN: DummyEchoLLM created this file so the patch-apply step is exercised.\n"
                ">>>>>>> REWRITE\n"
            )

        # Fallback
        return "{}"
==================== END FILE ====================


==================== FILE: src/agent/prompts.py ====================
from __future__ import annotations

import json
from typing import Any, Dict, List


def _trim(s: str, max_chars: int) -> str:
    if s is None:
        return ""
    s = str(s)
    return s if len(s) <= max_chars else (s[: max_chars - 3] + "...")


def context_pack_to_prompt(pack: Dict[str, Any], *, max_nodes: int = 18, max_snippet_chars: int = 2200) -> str:
    """
    Convert context_pack.json into a compact, LLM-friendly text block.
    """
    query = pack.get("query", "")
    focus = (pack.get("focus") or {}).get("node_id") or pack.get("focus_node") or ""
    seed_nodes = pack.get("seed_nodes", [])

    nodes = pack.get("nodes", [])
    def node_key(n):
        role = n.get("role", "")
        order = {"focus": 0, "seed": 1, "caller": 2, "callee": 3}.get(role, 9)
        return (order, n.get("type",""), n.get("node_id",""))

    nodes_sorted = sorted(nodes, key=node_key)[:max_nodes]

    out: List[str] = []
    out.append(f"Retrieval query: {query}")
    out.append(f"Focus node: {focus}")
    if seed_nodes:
        out.append("Seed nodes (vector search):")
        for s in seed_nodes[:8]:
            out.append(f"  - {s.get('node_id')} (score={s.get('score')})")
    out.append("")
    out.append("=== Context Nodes (with code excerpts) ===")
    for n in nodes_sorted:
        nid = n.get("node_id")
        typ = n.get("type")
        fp = n.get("file_path")
        sl = n.get("start_line")
        el = n.get("end_line")
        sig = _trim(n.get("signature",""), 240)
        roles = n.get("roles", [])
        why = n.get("why", [])
        snippet = _trim(n.get("snippet",""), max_snippet_chars)
        out.append(f"\n[{typ}] {nid}")
        if fp:
            out.append(f"Location: {fp}:{sl}-{el}")
        if sig:
            out.append(f"Signature: {sig}")
        if roles:
            out.append(f"Roles: {', '.join(map(str, roles))}")
        if why:
            why_short = [str(x) for x in why][:5]
            out.append("Why selected:")
            for w in why_short:
                out.append(f"  - {w}")
        if snippet:
            out.append("Code:")
            out.append(snippet)
    out.append("\n=== End Context ===")
    return "\n".join(out)


PLAN_SYSTEM = """You are a senior software engineer designing a safe automated refactoring plan.
You must be concise, risk-aware, and verification-driven.
Return STRICT JSON only (no markdown, no commentary outside JSON)."""

PLAN_USER_TEMPLATE = """Given the user request and the provided context pack, propose a refactoring plan.

Requirements:
- The goal is behavior-preserving refactoring.
- Only modify files that are necessary.
- Include a verification plan (commands) that can run in a sandbox (no shell operators like &&, |, >).
- Include risk notes.
- Optional: request additional information using tool_requests.
- IMPORTANT: All paths must be repo-root-relative, like "src/main/java/...". Do NOT prefix with "data/marketing-demo/".

Return JSON with this schema:
{{
  "objective": "...",
  "assumptions": ["..."],
  "steps": ["..."],
  "files_to_change": [{{"file_path":"...", "why":"...", "risk":"low|medium|high"}}],
  "verification": [{{"name":"...", "cmd":"..."}}],
  "tool_requests": [{{"tool":"ripgrep", "pattern":"...", "path":"..."}}]
}}

User request:
{request}

Context pack:
{context}
"""


EDIT_SYSTEM = """You are a senior software engineer.
You MUST output ONLY edit instructions using either Search/Replace blocks (preferred) or Full Rewrite blocks.
No markdown. No explanation. No code fences.

FORMAT (Search/Replace blocks - preferred):
FILE: <repo-relative-path>
<<<<<<< SEARCH
<exact text copied from the current file>
=======
<replacement text>
>>>>>>> REPLACE

You may include multiple SEARCH/REPLACE blocks under the same FILE.

FORMAT (Full Rewrite - allowed for small files):
FILE: <repo-relative-path>
<<<<<<< REWRITE
<entire new file content>
>>>>>>> REWRITE

RULES:
- Do NOT use "..." anywhere. Do NOT omit code.
- Do NOT abbreviate file paths.
- For Search/Replace: the SEARCH text MUST match EXACTLY ONE occurrence in the current file.
- Keep changes minimal and behavior-preserving.
- If a file is shown as MISSING in the 'EXACT REPO FILE CONTENTS' section, you MUST create it using a Full Rewrite block.
- You ARE allowed to create new files when required by the task; always use Full Rewrite for new files.
"""


EDIT_USER_TEMPLATE = """Task: {objective}

Refactoring plan (JSON):
{plan_json}

Context pack with code excerpts:
{context}

IMPORTANT:
- Use file paths relative to the repo root (e.g., "src/main/java/..."). Do NOT prefix with "data/marketing-demo/".
- Output MUST be ONLY edit instructions (no commentary).
- Prefer Search/Replace blocks (stable). Use Full Rewrite only when necessary.
- If a file is marked MISSING in the prompt, you MUST create it via Full Rewrite.
- Do NOT use "..." anywhere; do NOT shorten paths or code.

If the prompt includes a section named "EXACT REPO FILE CONTENTS (authoritative)", you MUST use that as the source of truth.

Return an UPDATED FULL set of edit instructions that should pass verification.
Return ONLY the edit instructions.
"""


REPAIR_SYSTEM = """You are a senior software engineer.
You MUST output ONLY edit instructions using either Search/Replace blocks (preferred) or Full Rewrite blocks.
No markdown. No explanation. No code fences.

You are given previous edit instructions and failure logs. Produce an UPDATED FULL set of instructions
(relative to the ORIGINAL codebase) that fixes the failures while keeping changes minimal and behavior-preserving.

FORMAT (Search/Replace blocks - preferred):
FILE: <repo-relative-path>
<<<<<<< SEARCH
<exact text copied from the current file>
=======
<replacement text>
>>>>>>> REPLACE

FORMAT (Full Rewrite - allowed for small files):
FILE: <repo-relative-path>
<<<<<<< REWRITE
<entire new file content>
>>>>>>> REWRITE

RULES:
- Do NOT use "..." anywhere. Do NOT omit code.
- Do NOT abbreviate file paths.
- For Search/Replace: the SEARCH text MUST match EXACTLY ONE occurrence in the current file.
- Keep changes minimal and behavior-preserving.
- If a file is shown as MISSING in the 'EXACT REPO FILE CONTENTS' section, you MUST create it using a Full Rewrite block.
- You ARE allowed to create new files when required by the task; always use Full Rewrite for new files.
"""


REPAIR_USER_TEMPLATE = """Task: {objective}

Refactoring plan (JSON):
{plan_json}

Previous edit instructions (that failed to apply or failed verification):
{prev_patch}

Failure / verification outputs:
{verify_logs}

Context pack with code excerpts:
{context}

IMPORTANT:
- Use file paths relative to the repo root (e.g., "src/main/java/..."). Do NOT prefix with "data/marketing-demo/".
- Output MUST be ONLY edit instructions (no commentary).
- Prefer Search/Replace blocks (stable). Use Full Rewrite only when necessary.
- If a file is marked MISSING in the prompt, you MUST create it via Full Rewrite.
- Do NOT use "..." anywhere; do NOT shorten paths or code.
- If apply failed because SEARCH did not match, adjust the SEARCH blocks to match the exact current file text (include more surrounding context).

If the prompt includes a section named "EXACT REPO FILE CONTENTS (authoritative)", you MUST use that as the source of truth.

Return an UPDATED FULL set of edit instructions that should pass verification.
Return ONLY the edit instructions.
"""

==================== END FILE ====================


==================== FILE: src/agent/sandbox.py ====================
from __future__ import annotations

import os
import glob
import shlex
import subprocess
from dataclasses import dataclass, field
from pathlib import Path
from typing import List, Optional, Tuple


@dataclass
class CommandResult:
    cmd: List[str]
    returncode: int
    stdout: str
    stderr: str

    @property
    def ok(self) -> bool:
        return self.returncode == 0


@dataclass
class SandboxConfig:
    root_dir: Path
    timeout_s: int = 240
    allowed_commands: List[str] = field(default_factory=lambda: [
        # Search / inspection
        "rg", "grep", "find", "ls", "cat", "sed", "python", "python3",
        # Build / test
        "mvn", "./mvnw", "gradle", "./gradlew", "npm", "pnpm", "yarn",
        "pytest",
        # Format / lint (optional)
        "black", "ruff", "prettier", "eslint", "google-java-format",
        # git (optional)
        "git",
        # java tools
        "javac", "java"
    ])
    use_docker: bool = False
    docker_image: str = "python:3.10-slim"  # user should override for Java/Maven projects
    docker_workdir: str = "/repo"


class Sandbox:
    """
    Runs commands in a controlled way:
    - shell=False (no pipes/&&)
    - only whitelisted base commands
    - optionally run inside a docker container with repo mounted read-write
    """
    def __init__(self, cfg: SandboxConfig):
        self.cfg = cfg
        self.cfg.root_dir = Path(self.cfg.root_dir).resolve()

    def _is_allowed(self, cmd: List[str]) -> bool:
        if not cmd:
            return False
        base = cmd[0]
        return base in set(self.cfg.allowed_commands)

    def _expand_globs(self, cmd: List[str], *, cwd: Path) -> List[str]:
        """Expand shell-style globs (* ? [..]) because we run with shell=False.

        This matches typical shell behavior for arguments like 'src/**/*.java'.
        If a pattern has no matches, it is kept as-is.
        """
        expanded: List[str] = []
        for arg in cmd:
            # Skip options (e.g. '-cp') and URLs etc.; only expand likely file patterns
            if any(ch in arg for ch in ("*", "?", "[")) and not arg.startswith("-"):
                matches = glob.glob(str(cwd / arg), recursive=True)
                if matches:
                    # Make matches relative to cwd for nicer logs and compatibility
                    for mpath in sorted(matches):
                        expanded.append(os.path.relpath(mpath, str(cwd)))
                    continue
            expanded.append(arg)
        return expanded


    def run(self, cmd: List[str], *, cwd: Optional[Path] = None) -> CommandResult:
        if not self._is_allowed(cmd):
            raise PermissionError(f"Command not allowed: {cmd}. Allowed={self.cfg.allowed_commands}")

        cwd = (cwd or self.cfg.root_dir).resolve()

        # Expand globs like *.java because we run with shell=False
        cmd = self._expand_globs(cmd, cwd=cwd)

        # Ensure cwd stays inside root_dir
        if not str(cwd).startswith(str(self.cfg.root_dir)):
            raise PermissionError(f"cwd must be inside sandbox root: {cwd}")

        if self.cfg.use_docker:
            return self._run_in_docker(cmd, cwd=cwd)

        # Local run
        p = subprocess.run(
            cmd,
            cwd=str(cwd),
            shell=False,
            capture_output=True,
            text=True,
            timeout=self.cfg.timeout_s,
        )
        return CommandResult(cmd=cmd, returncode=p.returncode, stdout=p.stdout, stderr=p.stderr)

    def _run_in_docker(self, cmd: List[str], *, cwd: Path) -> CommandResult:
        # Map cwd relative to repo root into container workdir
        rel = cwd.relative_to(self.cfg.root_dir)
        workdir = str(Path(self.cfg.docker_workdir) / rel)

        docker_cmd = [
            "docker", "run", "--rm",
            "-v", f"{self.cfg.root_dir}:{self.cfg.docker_workdir}",
            "-w", workdir,
            self.cfg.docker_image
        ] + cmd

        # NOTE: we intentionally do NOT allow arbitrary docker args from the LLM; only from config.
        p = subprocess.run(
            docker_cmd,
            shell=False,
            capture_output=True,
            text=True,
            timeout=self.cfg.timeout_s,
        )
        return CommandResult(cmd=docker_cmd, returncode=p.returncode, stdout=p.stdout, stderr=p.stderr)

    @staticmethod
    def split_cmd(cmd_str: str) -> List[str]:
        # shlex split (still safe because we run shell=False)
        return shlex.split(cmd_str)

==================== END FILE ====================


==================== FILE: src/agent/patcher.py ====================
from __future__ import annotations

import re
from dataclasses import dataclass
from pathlib import Path
from typing import List, Optional


@dataclass
class HunkLine:
    tag: str  # ' ', '+', '-'
    text: str


@dataclass
class Hunk:
    src_start: int
    src_len: int
    dst_start: int
    dst_len: int
    lines: List[HunkLine]


@dataclass
class FilePatch:
    old_path: str
    new_path: str
    hunks: List[Hunk]


_DIFF_GIT_RE = re.compile(r"^diff --git a/(.+?) b/(.+)$")
_HUNK_RE = re.compile(r"^@@ -(\d+)(?:,(\d+))? \+(\d+)(?:,(\d+))? @@")
_OLD_RE = re.compile(r"^---\s+(?:a/)?(.+)$")
_NEW_RE = re.compile(r"^\+\+\+\s+(?:b/)?(.+)$")


class PatchApplyError(Exception):
    pass


def parse_unified_diff(diff_text: str) -> List[FilePatch]:
    """
    Parses a subset of unified diff enough for LLM-generated patches.
    Supports:
      diff --git a/... b/...
      --- a/...
      +++ b/...
      @@ -l,s +l,s @@ hunks
    """
    lines = diff_text.splitlines()
    i = 0
    patches: List[FilePatch] = []

    current_old = None
    current_new = None
    current_hunks: List[Hunk] = []

    def flush():
        nonlocal current_old, current_new, current_hunks
        if current_old and current_new:
            patches.append(FilePatch(old_path=current_old, new_path=current_new, hunks=current_hunks))
        current_old = None
        current_new = None
        current_hunks = []

    while i < len(lines):
        line = lines[i]

        m = _DIFF_GIT_RE.match(line)
        if m:
            flush()
            current_old, current_new = m.group(1), m.group(2)
            i += 1
            continue

        m = _OLD_RE.match(line)
        if m:
            if current_old is None and current_new is None:
                current_old = m.group(1)
            i += 1
            continue

        m = _NEW_RE.match(line)
        if m:
            if current_new is None:
                current_new = m.group(1)
            i += 1
            continue

        m = _HUNK_RE.match(line)
        if m:
            src_start = int(m.group(1))
            src_len = int(m.group(2) or "1")
            dst_start = int(m.group(3))
            dst_len = int(m.group(4) or "1")
            i += 1

            hunk_lines: List[HunkLine] = []
            while i < len(lines):
                hl = lines[i]
                if hl.startswith("diff --git ") or hl.startswith("@@ "):
                    break
                if hl.startswith("--- ") or hl.startswith("+++ "):
                    break
                if hl.startswith("\\ No newline"):
                    i += 1
                    continue

                if hl == "":
                    # treat empty as context blank line
                    hunk_lines.append(HunkLine(tag=" ", text=""))
                    i += 1
                    continue

                tag = hl[0]
                if tag not in (" ", "+", "-"):
                    break

                # normalize CRLF artifacts
                txt = hl[1:].rstrip("\r")
                hunk_lines.append(HunkLine(tag=tag, text=txt))
                i += 1

            current_hunks.append(Hunk(src_start, src_len, dst_start, dst_len, hunk_lines))
            continue

        i += 1

    flush()
    return patches


def _safe_join(root: Path, rel: str) -> Path:
    rel = rel.replace("\\", "/").lstrip("/")
    p = (root / rel).resolve()
    if not str(p).startswith(str(root.resolve())):
        raise PatchApplyError(f"Unsafe path in patch: {rel}")
    return p


def normalize_patch_path(root_dir: Path, rel: str) -> str:
    """
    Normalize patch file paths to be relative to root_dir.

    Handles cases like:
      data/marketing-demo/src/main/java/...  (but root_dir is already marketing-demo)
    """
    root_dir = Path(root_dir).resolve()
    rel = (rel or "").replace("\\", "/").lstrip("/")
    if not rel:
        return rel

    # 1) As-is
    try:
        p = _safe_join(root_dir, rel)
        if p.exists():
            return rel
    except PatchApplyError:
        pass

    parts = [x for x in rel.split("/") if x]
    if len(parts) <= 1:
        return rel

    # 2) Try suffixes that exist as files
    for i in range(1, len(parts)):
        cand = "/".join(parts[i:])
        try:
            p2 = _safe_join(root_dir, cand)
        except PatchApplyError:
            continue
        if p2.exists():
            return cand

    # 3) For new files: try suffixes whose parent exists
    for i in range(1, len(parts)):
        cand = "/".join(parts[i:])
        try:
            p2 = _safe_join(root_dir, cand)
        except PatchApplyError:
            continue
        if p2.parent.exists():
            return cand

    return rel


def _seek_line(lines: List[str], cursor: int, text: str, window: int = 60) -> Optional[int]:
    """
    Find `text` near `cursor` within +/- window.
    Returns best matched index (closest), or None.
    """
    n = len(lines)
    if n == 0:
        return None
    cursor = max(0, min(cursor, n - 1))

    best = None
    best_dist = 10**9

    start = max(0, cursor - window)
    end = min(n - 1, cursor + window)
    for i in range(start, end + 1):
        if lines[i] == text:
            dist = abs(i - cursor)
            if dist < best_dist:
                best_dist = dist
                best = i
                if dist == 0:
                    break
    return best


def apply_unified_diff(diff_text: str, *, root_dir: Path, dry_run: bool = False) -> List[Path]:
    """
    Applies unified diff to files under root_dir.
    Returns list of modified file paths (absolute).
    """
    root_dir = Path(root_dir).resolve()
    patches = parse_unified_diff(diff_text)
    if not patches:
        raise PatchApplyError("No file patches found in diff.")

    modified: List[Path] = []

    for fp in patches:
        old_path = fp.old_path
        new_path = fp.new_path

        if old_path == "/dev/null":
            old_path = ""
        if new_path == "/dev/null":
            new_path = ""

        target_rel = new_path or old_path
        if not target_rel:
            raise PatchApplyError("Patch missing target path.")

        target_rel = normalize_patch_path(root_dir, target_rel)
        target = _safe_join(root_dir, target_rel)

        if target.exists():
            old_text = target.read_text(encoding="utf-8", errors="replace")
            old_lines = [ln.rstrip("\r") for ln in old_text.splitlines()]
        else:
            old_lines = []

        new_lines = old_lines[:]

        line_offset = 0
        for h in fp.hunks:
            idx = max(0, h.src_start - 1 + line_offset)
            cursor = min(idx, max(0, len(new_lines) - 1)) if new_lines else 0

            for hl in h.lines:
                if hl.tag == " ":
                    if cursor >= len(new_lines) or new_lines[cursor] != hl.text:
                        found = _seek_line(new_lines, cursor, hl.text, window=60)
                        if found is None:
                            raise PatchApplyError(
                                f"Context mismatch while applying hunk to {target_rel}: "
                                f"expected '{hl.text}' near line {cursor+1}"
                            )
                        cursor = found
                    cursor += 1

                elif hl.tag == "-":
                    if cursor >= len(new_lines) or new_lines[cursor] != hl.text:
                        found = _seek_line(new_lines, cursor, hl.text, window=30)
                        if found is None:
                            raise PatchApplyError(
                                f"Removal mismatch while applying hunk to {target_rel}: "
                                f"expected to remove '{hl.text}' near line {cursor+1}"
                            )
                        cursor = found
                    del new_lines[cursor]
                    line_offset -= 1

                elif hl.tag == "+":
                    new_lines.insert(cursor, hl.text)
                    cursor += 1
                    line_offset += 1

        if not dry_run:
            target.parent.mkdir(parents=True, exist_ok=True)
            target.write_text("\n".join(new_lines) + ("\n" if new_lines else ""), encoding="utf-8")
        modified.append(target)

    return modified


def list_target_files(diff_text: str) -> List[str]:
    patches = parse_unified_diff(diff_text)
    out: List[str] = []
    for fp in patches:
        target_rel = fp.new_path or fp.old_path
        if target_rel and target_rel not in out:
            out.append(target_rel)
    return out

==================== END FILE ====================


==================== FILE: src/agent/agent.py ====================
from __future__ import annotations

import json
import os
import re
import shutil
import time
import difflib
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from .llm import LLMClient
from .patcher import PatchApplyError  # reuse exception type
from .prompts import (
    PLAN_SYSTEM, PLAN_USER_TEMPLATE,
    EDIT_SYSTEM, EDIT_USER_TEMPLATE,
    REPAIR_SYSTEM, REPAIR_USER_TEMPLATE,
    context_pack_to_prompt,
)
from .sandbox import Sandbox, SandboxConfig, CommandResult


@dataclass
class AgentConfig:
    project_dir: Path
    work_dir: Optional[Path] = None  # if None, create .refactor_agent_runs/<ts> under project_dir
    max_iters: int = 3

    # Prompt control
    max_nodes_in_prompt: int = 18
    max_snippet_chars: int = 2200

    # Verification
    # If None/empty, RefactoringAgent will auto-detect sensible verification commands
    # based on repo contents (e.g. Maven/Gradle/Java demo runner).
    default_verify_cmds: Optional[List[str]] = None

    # Whether to trust/execute verification commands proposed by the LLM in plan.json.
    # Default False to avoid brittle verification steps.
    use_plan_verification: bool = False


    # Execution
    # - monolithic: one large patch per attempt (original behavior)
    # - stepwise: split into small steps (recommended; improves patch applicability and reduces truncation)
    execution_mode: str = "stepwise"  # "monolithic" or "stepwise"
    step_max_files: int = 1           # when auto-splitting, max files per step
    verify_each_step: bool = True     # run verification after each step
    enforce_file_whitelist: bool = True  # prevent edits outside plan files_to_change
    allow_new_files: bool = True      # allow creating new files via Full Rewrite

    # LLM output budgets (increase to reduce truncation)
    edit_max_tokens: int = 4000
    repair_max_tokens: int = 6000
    # Sandbox
    sandbox_timeout_s: int = 240
    use_docker: bool = False
    docker_image: str = "python:3.10-slim"
    allowed_commands: Optional[List[str]] = None


@dataclass
class SearchReplaceBlock:
    search: str
    replace: str


@dataclass
class FileEditInstruction:
    path: str
    blocks: List[SearchReplaceBlock] = None
    rewrite: Optional[str] = None



class RefactoringAgent:
    """
    Minimal refactoring agent (Plan â†’ Edit â†’ Verify/Repair) using git apply as the patch application engine.

    Key robustness features vs earlier versions:
    - Normalize plan paths (strip prefixes like data/marketing-demo/ if work_dir is already marketing-demo root)
    - Feed EXACT file contents into prompts so LLM doesn't guess context lines
    - Use git reset --hard + git clean -fd between iterations to keep index/worktree consistent
    - Support both git-style patches (diff --git a/ b/) and traditional patches (---/+++ without a/ b/) via -p level
    """
    def __init__(self, *, llm: LLMClient, cfg: AgentConfig):
        self.llm = llm
        self.cfg = cfg
        self.project_dir = Path(cfg.project_dir).resolve()
        if not self.project_dir.exists():
            raise FileNotFoundError(f"project_dir not found: {self.project_dir}")

        ts = time.strftime("%Y%m%d_%H%M%S")
        self.work_dir = Path(cfg.work_dir or (self.project_dir / ".refactor_agent_runs" / ts)).resolve()

        if self.work_dir.exists():
            raise FileExistsError(f"work_dir already exists: {self.work_dir}")
        self.work_dir.parent.mkdir(parents=True, exist_ok=True)

        # Copy project into sandbox workspace (ignore heavy folders)
        shutil.copytree(
            self.project_dir,
            self.work_dir,
            dirs_exist_ok=False,
            ignore=shutil.ignore_patterns(".refactor_agent_runs", ".git", "target", "build", ".gradle", "node_modules", "__pycache__")
        )

        sandbox_cfg = SandboxConfig(
            root_dir=self.work_dir,
            timeout_s=cfg.sandbox_timeout_s,
            allowed_commands=(cfg.allowed_commands or SandboxConfig(root_dir=self.work_dir).allowed_commands),
            use_docker=cfg.use_docker,
            docker_image=cfg.docker_image,
        )
        self.sandbox = Sandbox(sandbox_cfg)

        # Auto-detect verification commands if not provided.
        if not (self.cfg.default_verify_cmds or []):
            self.cfg.default_verify_cmds = self._auto_detect_verify_cmds()

        self._git_initialized = False

    # ---------------------------
    # Utilities
    # ---------------------------


    def _auto_detect_verify_cmds(self) -> List[str]:
        """Choose deterministic verification commands based on repo contents.

        We intentionally avoid trusting LLM-generated verification commands by default
        because they are often brittle (wrong classpath, missing files, shell globs, etc.).
        """
        repo = self.work_dir

        # Java: if there is a DemoRunner, compile all sources and run it.
        src_root = repo / "src" / "main" / "java"
        if src_root.exists():
            demo = next(src_root.rglob("DemoRunner.java"), None)
            if demo:
                main_class = self._java_main_class_from_source(demo)
                # Compile into target/classes to avoid polluting source tree
                compile_cmd = "javac -encoding UTF-8 -d target/classes -cp src/main/java src/main/java/**/*.java"

                # Include resources if present
                cp = f"target/classes{os.pathsep}src/main/resources" if (repo / "src" / "main" / "resources").exists() else "target/classes"
                run_cmd = f"java -cp {cp} {main_class}"
                return [compile_cmd, run_cmd]

            # Fallback: just compile everything
            return ["javac -encoding UTF-8 -d target/classes -cp src/main/java src/main/java/**/*.java"]

        # Maven / Gradle (fallbacks)
        if (repo / "pom.xml").exists():
            if (repo / "mvnw").exists():
                return ["./mvnw -q test"]
            return ["mvn -q test"]

        if (repo / "build.gradle").exists() or (repo / "build.gradle.kts").exists():
            if (repo / "gradlew").exists():
                return ["./gradlew test"]
            return ["gradle test"]

        # Python (very generic fallback)
        if (repo / "pyproject.toml").exists() or (repo / "requirements.txt").exists():
            return ["pytest -q"]

        return []

    @staticmethod
    def _java_main_class_from_source(source_path: Path) -> str:
        """Derive a Java main class (FQN) from a .java file by reading its package statement."""
        try:
            lines = source_path.read_text(encoding="utf-8", errors="replace").splitlines()
        except Exception:
            return source_path.stem

        pkg = ""
        for ln in lines[:80]:
            s = ln.strip()
            if s.startswith("package ") and s.endswith(";"):
                pkg = s[len("package "):].rstrip(";").strip()
                break
        return f"{pkg}.{source_path.stem}" if pkg else source_path.stem

    def _ensure_output_dirs_for_cmds(self, cmds: List[str]) -> None:
        """Create output dirs used by javac -d to avoid spurious failures."""
        for cmd_str in cmds or []:
            m = re.search(r"\s-d\s+([^\s]+)", cmd_str)
            if not m:
                continue
            out_dir = m.group(1)
            # Only handle relative paths inside the workdir
            if out_dir.startswith(('/', '~')) or ':' in out_dir:
                continue
            try:
                (self.work_dir / out_dir).mkdir(parents=True, exist_ok=True)
            except Exception:
                pass

    def _extract_json(self, text: str) -> Dict[str, Any]:
        text = (text or "").strip()
        try:
            return json.loads(text)
        except json.JSONDecodeError:
            start = text.find("{")
            end = text.rfind("}")
            if start >= 0 and end > start:
                return json.loads(text[start:end + 1])
            raise

    @staticmethod
    def _sanitize_patch_text(patch: str) -> str:
        """
        Make LLM output more 'git apply' friendly:
        - remove ``` fences
        - trim everything before first diff header
        - normalize newlines and ensure trailing newline
        - fix corrupt diffs caused by blank lines inside hunks
        - fix common LLM mistakes where hunk lines miss the leading ' ' / '+' / '-' marker
        - reconstruct truncated 'diff --git' lines from subsequent ---/+++ headers
        """
        if patch is None:
            return ""

        patch = patch.replace("\r\n", "\n").replace("\r", "\n")
        raw_lines = patch.splitlines()

        # Drop code fences if any
        raw_lines = [ln for ln in raw_lines if not ln.strip().startswith("```")]

        # Trim everything before the first diff header
        start_idx = 0
        for i, ln in enumerate(raw_lines):
            if ln.startswith("diff --git ") or ln.startswith("--- "):
                start_idx = i
                break
        raw_lines = raw_lines[start_idx:]

        out: list[str] = []
        in_hunk = False

        for ln in raw_lines:
            if ln.startswith("@@ "):
                in_hunk = True
                out.append(ln)
                continue

            # leaving a hunk when a new file header starts
            if in_hunk and (ln.startswith("diff --git ") or ln.startswith("--- ") or ln.startswith("+++ ")):
                in_hunk = False

            if in_hunk:
                # In unified diff, every hunk line must start with ' ', '+', '-', or '\'
                if ln == "":
                    out.append(" ")
                    continue
                if ln.startswith("\\ No newline at end of file"):
                    out.append(ln)
                    continue
                if ln[:1] not in (" ", "+", "-", "\\"):
                    # Model forgot the prefix; assume it's a context line.
                    out.append(" " + ln)
                    continue

            out.append(ln)

        # Fix 'diff --git' lines that may be truncated by the LLM by reconstructing
        # them from the subsequent ---/+++ headers.
        fixed: list[str] = []
        i = 0
        while i < len(out):
            ln = out[i]
            if ln.startswith("diff --git "):
                a_path = None
                b_path = None
                j = i + 1
                while j < len(out) and (not out[j].startswith("diff --git ")):
                    if out[j].startswith("--- "):
                        a_path = out[j].split(maxsplit=1)[1].strip()
                    elif out[j].startswith("+++ "):
                        b_path = out[j].split(maxsplit=1)[1].strip()
                        break
                    j += 1
                if a_path and b_path:
                    fixed.append(f"diff --git {a_path} {b_path}")
                    i += 1
                    continue
            fixed.append(ln)
            i += 1

        return "\n".join(fixed).strip() + "\n"



    def _patch_has_git_header(self, patch: str) -> bool:
        return "diff --git " in (patch or "")

    def _guess_p_level(self, patch: str) -> int:
        """
        git apply by default behaves like -p1 (strip one path component).
        For patches without a/ b/ prefixes, we usually want -p0.
        """
        if re.search(r"^---\s+a\/", patch, re.M) or re.search(r"^\+\+\+\s+b\/", patch, re.M) or "diff --git a/" in patch:
            return 1
        return 0

    def _resolve_in_workdir(self, path: str, *, want_dir: bool = False) -> Optional[str]:
        """
        Resolve a possibly-prefixed path (e.g. data/marketing-demo/src/...) to a repo-root-relative path
        that exists under work_dir. Returns normalized relative path, or None if not resolvable.
        """
        if not path:
            return None
        p = str(path).replace("\\", "/").lstrip("/")

        # strip common diff prefixes
        if p.startswith("a/") or p.startswith("b/"):
            p = p[2:]

        # try as-is
        cand = (self.work_dir / p)
        if want_dir and cand.is_dir():
            return p
        if (not want_dir) and cand.is_file():
            return p

        parts = [x for x in p.split("/") if x]
        if not parts:
            return None

        # try suffixes
        for i in range(1, len(parts)):
            suf = "/".join(parts[i:])
            cand2 = (self.work_dir / suf)
            if want_dir and cand2.is_dir():
                return suf
            if (not want_dir) and cand2.is_file():
                return suf

        # directory fallback: if want_dir, also allow existing parent
        if want_dir:
            for i in range(1, len(parts)):
                suf = "/".join(parts[i:])
                cand2 = (self.work_dir / suf)
                if cand2.exists() and cand2.is_dir():
                    return suf
        return None

    def _normalize_plan_paths(self, plan: Dict[str, Any], context_pack: Dict[str, Any]) -> Dict[str, Any]:
        """
        Normalize plan["files_to_change"][].file_path and plan["tool_requests"][].path so they work under work_dir.
        """
        plan = dict(plan)

        # files_to_change
        ftc = plan.get("files_to_change") or []
        new_ftc = []
        for item in ftc:
            item = dict(item)
            fp = (item.get("file_path") or "").strip()
            resolved = self._resolve_in_workdir(fp, want_dir=False)
            if resolved:
                item["file_path"] = resolved
            new_ftc.append(item)
        plan["files_to_change"] = new_ftc

        # tool_requests paths (dirs)
        tr = plan.get("tool_requests") or []
        new_tr = []
        for req in tr:
            req = dict(req)
            p = (req.get("path") or ".").strip() or "."
            resolved_dir = self._resolve_in_workdir(p, want_dir=True)
            req["path"] = resolved_dir or "."
            new_tr.append(req)
        plan["tool_requests"] = new_tr

        # verification commands: keep as-is
        return plan

    def _focus_file_from_context_pack(self, context_pack: Dict[str, Any]) -> Optional[str]:
        focus = (context_pack.get("focus") or {}).get("node_id") or context_pack.get("focus_node")
        if not focus:
            return None
        for n in (context_pack.get("nodes") or []):
            if n.get("node_id") == focus and n.get("file_path"):
                fp = n.get("file_path")
                resolved = self._resolve_in_workdir(fp, want_dir=False)
                return resolved or None
        return None

    def _dump_files_for_prompt(self, plan: Dict[str, Any], context_pack: Dict[str, Any], *, max_chars_per_file: int = 22000, only_files: Optional[List[str]] = None) -> str:
        """
        Append exact file contents from the sandbox workdir so the LLM can produce an apply-able patch.
        Uses normalized plan file paths; if missing, falls back to focus file.
        """
        rel_files: List[str] = []
        if only_files:
            rel_files.extend([str(x).strip() for x in only_files if str(x).strip()])
        else:
            for f in (plan.get("files_to_change") or []):
                fp = (f.get("file_path") or "").strip()
                if fp:
                    rel_files.append(fp)

        if not rel_files:
            focus_fp = self._focus_file_from_context_pack(context_pack)
            if focus_fp:
                rel_files.append(focus_fp)

        # de-dup
        seen = set()
        rel_files = [x for x in rel_files if not (x in seen or seen.add(x))]

        blocks = []
        for rel in rel_files[:6]:
            p = (self.work_dir / rel).resolve()
            if not str(p).startswith(str(self.work_dir)):
                continue
            if not p.exists() or not p.is_file():
                # Expose missing files to the LLM so it can create them via Full Rewrite.
                blocks.append(
                    f"\n--- FILE: {rel} (MISSING) ---\n"
                    "/* This file does not exist yet. Create it using a Full Rewrite (REWRITE) block. */\n"
                    f"--- END FILE: {rel} ---\n"
                )
                continue
            txt = p.read_text(encoding="utf-8", errors="replace")
            if len(txt) > max_chars_per_file:
                txt = txt[:max_chars_per_file] + "\n/* ... TRUNCATED ... */\n"
            blocks.append(f"\n--- FILE: {rel} ---\n{txt}\n--- END FILE: {rel} ---\n")
        return "\n".join(blocks)

    # ---------------------------
    # Plan / Edit / Repair
    # ---------------------------

    def _plan(self, *, request: str, context_pack: Dict[str, Any]) -> Dict[str, Any]:
        context_txt = context_pack_to_prompt(
            context_pack,
            max_nodes=self.cfg.max_nodes_in_prompt,
            max_snippet_chars=self.cfg.max_snippet_chars,
        )
        messages = [
            {"role": "system", "content": PLAN_SYSTEM},
            {"role": "user", "content": PLAN_USER_TEMPLATE.format(request=request, context=context_txt)},
        ]
        out = self.llm.chat(messages, temperature=0.1, max_tokens=1400)
        plan = self._extract_json(out)
        return plan

    def _run_tool_requests(self, tool_requests: List[Dict[str, Any]]) -> str:
        if not tool_requests:
            return ""
        chunks: List[str] = []
        for req in tool_requests[:6]:
            tool = (req.get("tool") or "").lower()
            if tool in ("ripgrep", "rg"):
                pattern = str(req.get("pattern") or "").strip()
                path = str(req.get("path") or ".").strip() or "."
                if not pattern:
                    continue
                cmd = ["rg", "-n", pattern, path]
                try:
                    res = self.sandbox.run(cmd, cwd=self.work_dir)
                    chunks.append(f"[TOOL rg] cmd={' '.join(cmd)}\n{res.stdout}\n{res.stderr}".strip())
                except Exception as e:
                    # Fallback to grep if rg is not available in the environment.
                    try:
                        gcmd = ["grep", "-R", "-n", "--", pattern, path]
                        gres = self.sandbox.run(gcmd, cwd=self.work_dir)
                        chunks.append(f"[TOOL grep] cmd={' '.join(gcmd)}\n{gres.stdout}\n{gres.stderr}".strip())
                    except Exception as e2:
                        chunks.append(f"[TOOL rg ERROR] {e}\n[TOOL grep ERROR] {e2}")
        return "\n\n".join(chunks)

    def _edit(self, *, objective: str, plan: Dict[str, Any], context_pack: Dict[str, Any], extra_tool_info: str = "") -> str:
        context_txt = context_pack_to_prompt(
            context_pack,
            max_nodes=self.cfg.max_nodes_in_prompt,
            max_snippet_chars=self.cfg.max_snippet_chars,
        )
        file_dump = self._dump_files_for_prompt(plan, context_pack)
        if file_dump:
            context_txt += "\n\n=== EXACT REPO FILE CONTENTS (authoritative) ===\n" + file_dump + "\n=== END EXACT FILE CONTENTS ===\n"
        if extra_tool_info:
            context_txt += "\n\n=== Tool outputs ===\n" + extra_tool_info + "\n=== End tool outputs ===\n"

        plan_json = json.dumps(plan, ensure_ascii=False, indent=2)
        messages = [
            {"role": "system", "content": EDIT_SYSTEM},
            {"role": "user", "content": EDIT_USER_TEMPLATE.format(objective=objective, plan_json=plan_json, context=context_txt)},
        ]
        patch = self.llm.chat(messages, temperature=0.2, max_tokens=self.cfg.edit_max_tokens)
        return (patch or "").strip()

    def _repair(self, *, objective: str, plan: Dict[str, Any], context_pack: Dict[str, Any], prev_patch: str, verify_logs: str, extra_tool_info: str = "") -> str:
        context_txt = context_pack_to_prompt(
            context_pack,
            max_nodes=self.cfg.max_nodes_in_prompt,
            max_snippet_chars=self.cfg.max_snippet_chars,
        )
        file_dump = self._dump_files_for_prompt(plan, context_pack)
        if file_dump:
            context_txt += "\n\n=== EXACT REPO FILE CONTENTS (authoritative) ===\n" + file_dump + "\n=== END EXACT FILE CONTENTS ===\n"
        if extra_tool_info:
            context_txt += "\n\n=== Tool outputs ===\n" + extra_tool_info + "\n=== End tool outputs ===\n"

        plan_json = json.dumps(plan, ensure_ascii=False, indent=2)
        messages = [
            {"role": "system", "content": REPAIR_SYSTEM},
            {"role": "user", "content": REPAIR_USER_TEMPLATE.format(
                objective=objective,
                plan_json=plan_json,
                prev_patch=prev_patch,
                verify_logs=verify_logs,
                context=context_txt
            )},
        ]
        patch = self.llm.chat(messages, temperature=0.2, max_tokens=self.cfg.repair_max_tokens)
        return (patch or "").strip()

    # ---------------------------
    # Git patch application
    # ---------------------------

    def _ensure_git_baseline(self, artifacts_dir: Path) -> None:
        if self._git_initialized:
            return
        if not (self.work_dir / ".git").exists():
            self.sandbox.run(["git", "init"], cwd=self.work_dir)
        # set identity to avoid "Please tell me who you are"
        self.sandbox.run(["git", "config", "user.email", "refactor-agent@example.com"], cwd=self.work_dir)
        self.sandbox.run(["git", "config", "user.name", "RefactorAgent"], cwd=self.work_dir)

        self.sandbox.run(["git", "add", "-A"], cwd=self.work_dir)
        # baseline commit (ignore non-zero if nothing to commit)
        _ = self.sandbox.run(["git", "commit", "-m", "baseline"], cwd=self.work_dir)
        self._git_initialized = True

    def _git_reset_clean(self) -> None:
        # restore to baseline commit
        self.sandbox.run(["git", "reset", "--hard", "HEAD"], cwd=self.work_dir)
        self.sandbox.run(["git", "clean", "-fd"], cwd=self.work_dir)

    def _git_head_hash(self) -> str:
        res = self.sandbox.run(["git", "rev-parse", "HEAD"], cwd=self.work_dir)
        return (res.stdout or "").strip()

    def _git_reset_clean_to(self, rev: str) -> None:
        self.sandbox.run(["git", "reset", "--hard", rev], cwd=self.work_dir)
        self.sandbox.run(["git", "clean", "-fd"], cwd=self.work_dir)

    def _git_commit_checkpoint(self, msg: str) -> None:
        # Commit current working tree changes. Ignore "nothing to commit".
        self.sandbox.run(["git", "add", "-A"], cwd=self.work_dir)
        res = self.sandbox.run(["git", "commit", "-m", msg], cwd=self.work_dir)
        _ = res  # keep for debugging if needed

    @staticmethod
    def _is_meta_path(p: str) -> bool:
        return (
            p.startswith(".agent_artifacts/")
            or p == ".agent_artifacts"
            or p.startswith(".git/")
            or p == ".git"
        )

    def _list_changed_files(self) -> List[str]:
        diff_names = self.sandbox.run(["git", "diff", "--name-only"], cwd=self.work_dir)
        files = [ln.strip() for ln in (diff_names.stdout or "").splitlines() if ln.strip()]
        return [f for f in files if not self._is_meta_path(f)]

    def _allowed_files_from_plan(self, plan: Dict[str, Any]) -> List[str]:
        rel_files: List[str] = []
        for f in (plan.get("files_to_change") or []):
            fp = (f.get("file_path") or "").strip()
            if fp:
                rel_files.append(fp)
        # de-dup keep order
        seen = set()
        rel_files = [x for x in rel_files if not (x in seen or seen.add(x))]
        return rel_files

    def _enforce_changed_files_whitelist(self, allowed: List[str]) -> Tuple[bool, str]:
        if not self.cfg.enforce_file_whitelist:
            return True, ""
        allowed_set = set(allowed or [])
        changed = self._list_changed_files()
        extra = [f for f in changed if f not in allowed_set]
        if extra:
            return False, (
                "[SCOPE ERROR] The patch modified files outside the planned scope.\n"
                f"Allowed: {sorted(allowed_set)}\n"
                f"Changed: {changed}\n"
                f"Out-of-scope: {extra}\n"
                "Fix by ONLY editing allowed files.\n"
            )
        return True, ""


    def _extract_apply_failure_context(self, stderr: str) -> str:
        """
        If stderr contains 'patch failed: <file>:<line>', append an excerpt of that file around the line.
        """
        if not stderr:
            return ""
        m = re.search(r"patch failed:\s+([^\s:]+):(\d+)", stderr)
        if not m:
            return ""
        rel = m.group(1).strip()
        line_no = int(m.group(2))
        resolved = self._resolve_in_workdir(rel, want_dir=False) or rel
        p = (self.work_dir / resolved)
        if not p.exists():
            return ""
        lines = p.read_text(encoding="utf-8", errors="replace").splitlines()
        lo = max(0, line_no - 1 - 20)
        hi = min(len(lines), line_no - 1 + 20)
        excerpt = "\n".join(f"{i+1:04d}: {lines[i]}" for i in range(lo, hi))
        return f"\n[FILE EXCERPT] {resolved} around line {line_no}\n{excerpt}\n"


    # ---------------------------
    # Apply LLM edits (Search/Replace Blocks or Full Rewrite)
    # ---------------------------

    def _apply_llm_output(self, llm_text: str, diff_file: Path) -> Tuple[bool, str]:
        """
        Apply LLM output to the repo working tree.
        Preferred format:
          - FILE: <path>
            <<<<<<< SEARCH
            ...
            =======
            ...
            >>>>>>> REPLACE
          - or:
            FILE: <path>
            <<<<<<< REWRITE
            <full new file content>
            >>>>>>> REWRITE

        Fallback: if the output looks like a unified diff (diff --git), apply via git apply.
        On success, writes `git diff` (against baseline) to diff_file.
        Returns (ok, logs). Logs are suitable to feed to repair.
        """
        (diff_file.parent / (diff_file.stem + "_raw.txt")).write_text(llm_text, encoding="utf-8")

        looks_like_diff = bool(re.search(r"^diff --git ", llm_text.strip(), re.M)) or bool(re.search(r"^---\s+", llm_text.strip(), re.M))
        looks_like_blocks = ("FILE:" in llm_text) or ("<<<<<<< SEARCH" in llm_text) or ("<<<<<<< REWRITE" in llm_text)

        if looks_like_diff and not looks_like_blocks:
            # unified diff path
            tmp_patch = diff_file.parent / (diff_file.stem + "_unified.diff")
            ok, logs = self._git_apply_unified_diff(llm_text, tmp_patch)
            if not ok:
                return False, logs
        else:
            edits, perr = self._parse_edit_instructions(llm_text)
            if perr:
                return False, "[EDIT PARSE ERROR]\n" + perr
            ok, logs = self._apply_edit_instructions(edits)
            if not ok:
                return False, logs

        # On success, persist the actual diff vs baseline
        diff = self.sandbox.run(["git", "diff"], cwd=self.work_dir)
        diff_file.write_text(diff.stdout or "", encoding="utf-8")
        return True, ""

    def _parse_edit_instructions(self, llm_text: str) -> Tuple[List[FileEditInstruction], str]:
        """
        Parse Search/Replace blocks and Full Rewrite blocks from LLM output.
        Expected:
          FILE: path
          <<<<<<< SEARCH
          ...
          =======
          ...
          >>>>>>> REPLACE

        Or:
          FILE: path
          <<<<<<< REWRITE
          ...
          >>>>>>> REWRITE

        Returns (edits, error_message). error_message == "" when ok.
        """
        if llm_text is None:
            return [], "Empty output."

        t = llm_text.replace("\r\n", "\n").replace("\r", "\n")
        lines = t.split("\n")

        edits: List[FileEditInstruction] = []
        cur: Optional[FileEditInstruction] = None

        def finish_current():
            nonlocal cur
            if cur is not None:
                if cur.blocks is None:
                    cur.blocks = []
                edits.append(cur)
                cur = None

        i = 0
        while i < len(lines):
            ln = lines[i]
            m = re.match(r"^\s*FILE:\s*(.+?)\s*$", ln)
            if m:
                finish_current()
                cur = FileEditInstruction(path=m.group(1).strip(), blocks=[], rewrite=None)
                i += 1
                continue

            if cur is None:
                i += 1
                continue

            if ln.strip() == "<<<<<<< SEARCH":
                i += 1
                search_lines = []
                while i < len(lines) and lines[i].strip() != "=======":
                    search_lines.append(lines[i])
                    i += 1
                if i >= len(lines) or lines[i].strip() != "=======":
                    return [], f"Missing '=======' after SEARCH block in file {cur.path}."
                i += 1
                replace_lines = []
                while i < len(lines) and lines[i].strip() != ">>>>>>> REPLACE":
                    replace_lines.append(lines[i])
                    i += 1
                if i >= len(lines) or lines[i].strip() != ">>>>>>> REPLACE":
                    return [], f"Missing '>>>>>>> REPLACE' after REPLACE block in file {cur.path}."
                i += 1
                cur.blocks.append(SearchReplaceBlock(search="\n".join(search_lines), replace="\n".join(replace_lines)))
                continue

            if ln.strip() == "<<<<<<< REWRITE":
                i += 1
                rewrite_lines = []
                while i < len(lines) and lines[i].strip() != ">>>>>>> REWRITE":
                    rewrite_lines.append(lines[i])
                    i += 1
                if i >= len(lines) or lines[i].strip() != ">>>>>>> REWRITE":
                    return [], f"Missing '>>>>>>> REWRITE' for file {cur.path}."
                i += 1
                cur.rewrite = "\n".join(rewrite_lines)
                continue

            i += 1

        finish_current()

        if not edits:
            return [], "No FILE: sections found. Output must start with one or more 'FILE: <path>' headers."
        # Validate
        bad = [e.path for e in edits if not e.path]
        if bad:
            return [], f"Empty FILE path in sections: {bad}"
        return edits, ""

    def _apply_edit_instructions(self, edits: List[FileEditInstruction]) -> Tuple[bool, str]:
        """
        Apply parsed edits to the working tree. Strict by default:
          - SEARCH text must match EXACTLY once
          - REWRITE replaces entire file contents
        """
        logs: List[str] = []
        for e in edits:
            rel = e.path.strip()
            resolved = self._resolve_in_workdir(rel, want_dir=False) or rel.lstrip("/")
            p = self.work_dir / resolved
            if not p.exists() and e.rewrite is None:
                logs.append(f"[EDIT APPLY ERROR] File not found: {resolved}")
                continue

            if e.rewrite is not None:
                p.parent.mkdir(parents=True, exist_ok=True)
                new_text = e.rewrite.replace("\r\n", "\n").replace("\r", "\n")
                if not new_text.endswith("\n"):
                    new_text += "\n"
                p.write_text(new_text, encoding="utf-8")
                continue

            # Search/Replace blocks
            file_text = p.read_text(encoding="utf-8").replace("\r\n", "\n").replace("\r", "\n")
            for bi, blk in enumerate(e.blocks or [], start=1):
                search = blk.search.replace("\r\n", "\n").replace("\r", "\n")
                replace = blk.replace.replace("\r\n", "\n").replace("\r", "\n")
                if search == "":
                    logs.append(f"[EDIT APPLY ERROR] Empty SEARCH block in {resolved} (block #{bi}).")
                    continue

                occ = file_text.count(search)
                if occ == 0:
                    # Provide fuzzy hint
                    hint = self._best_fuzzy_match_hint(file_text, search)
                    logs.append(
                        f"[EDIT APPLY ERROR] SEARCH block not found in {resolved} (block #{bi}).\n"
                        f"[SEARCH]\n{search[:800]}\n"
                        f"{hint}"
                    )
                    continue
                if occ > 1:
                    logs.append(
                        f"[EDIT APPLY ERROR] SEARCH block matched {occ} times in {resolved} (block #{bi}). "
                        "Make SEARCH more specific.\n"
                        f"[SEARCH]\n{search[:800]}\n"
                    )
                    continue

                file_text = file_text.replace(search, replace, 1)

            # Only write back if no errors for this file
            if not any(msg.startswith("[EDIT APPLY ERROR]") and f" {resolved}" in msg for msg in logs):
                if not file_text.endswith("\n"):
                    file_text += "\n"
                p.write_text(file_text, encoding="utf-8")

        if logs:
            return False, "\n".join(logs)
        return True, ""

    def _best_fuzzy_match_hint(self, file_text: str, search: str) -> str:
        """
        Best-effort hint for repair: find the most similar window in the file for the given search block.
        """
        try:
            file_lines = file_text.split("\n")
            search_lines = search.split("\n")
            n = len(search_lines)
            if n == 0:
                return ""

            # Limit scanning for performance on huge files
            max_lines = min(len(file_lines), 4000)
            file_lines = file_lines[:max_lines]

            best = (0.0, 0)  # (ratio, start_idx)
            search_join = "\n".join(search_lines)
            for i in range(0, max_lines - n + 1):
                window = "\n".join(file_lines[i:i+n])
                r = difflib.SequenceMatcher(None, search_join, window).ratio()
                if r > best[0]:
                    best = (r, i)
            ratio, idx = best
            if ratio < 0.35:
                return ""
            start = max(idx - 2, 0)
            end = min(idx + n + 2, len(file_lines))
            snippet = "\n".join(file_lines[start:end])
            return f"[FUZZY HINT] Best approx match near line {idx+1} (similarity {ratio:.2f}):\n{snippet}\n"
        except Exception:
            return ""

    def _git_apply_unified_diff(self, patch_text: str, patch_file: Path) -> Tuple[bool, str]:
        """
        Apply patch in work_dir. Returns (ok, logs). Logs are suitable to feed to repair.
        """
        patch_text = self._sanitize_patch_text(patch_text)

        patch_file.write_text(patch_text, encoding="utf-8")

        p_level = self._guess_p_level(patch_text)
        has_git_header = self._patch_has_git_header(patch_text)

        check_cmd = ["git", "apply", "--check", f"-p{p_level}", "--whitespace=nowarn", str(patch_file)]
        check = self.sandbox.run(check_cmd, cwd=self.work_dir)

        # If it's corrupt patch, stop early
        if (not check.ok) and ("corrupt patch" in (check.stderr or "")):
            return False, f"[PATCH APPLY ERROR]\n{check.stdout}\n{check.stderr}"

        # Try apply (3way only if git header exists)
        apply_cmd = ["git", "apply", f"-p{p_level}", "--whitespace=nowarn"]
        if has_git_header:
            apply_cmd.insert(2, "--3way")

        res = self.sandbox.run(apply_cmd + [str(patch_file)], cwd=self.work_dir)
        if res.ok:
            return True, ""

        # Fallback: try toggling p-level once (useful if LLM omitted a/b prefixes)
        alt_p = 0 if p_level == 1 else 1
        apply_cmd2 = ["git", "apply", f"-p{alt_p}", "--whitespace=nowarn"]
        if has_git_header:
            apply_cmd2.insert(2, "--3way")
        res2 = self.sandbox.run(apply_cmd2 + [str(patch_file)], cwd=self.work_dir)
        if res2.ok:
            return True, ""

        extra = self._extract_apply_failure_context(res.stderr + "\n" + res2.stderr)
        logs = (
            "[PATCH APPLY ERROR]\n"
            f"[CHECK CMD] {' '.join(check_cmd)}\n{check.stdout}\n{check.stderr}\n"
            f"[APPLY CMD] {' '.join(apply_cmd)} {patch_file.name}\n{res.stdout}\n{res.stderr}\n"
            f"[APPLY CMD ALT] {' '.join(apply_cmd2)} {patch_file.name}\n{res2.stdout}\n{res2.stderr}\n"
            f"{extra}"
        )
        return False, logs

    # ---------------------------
    # Verify
    # ---------------------------

    def _verify(self, plan: Dict[str, Any]) -> Tuple[bool, str]:
        cmds: List[str] = []

        # Prefer deterministic verification commands from config / auto-detect.
        # LLM-generated verification commands are often incorrect (classpath, globs, etc.),
        # so we only use them when explicitly enabled.
        if self.cfg.use_plan_verification:
            for v in plan.get("verification", []) or []:
                cmd_str = (v.get("cmd") or "").strip()
                if cmd_str:
                    cmds.append(cmd_str)

        if not cmds:
            cmds = list(self.cfg.default_verify_cmds or [])

        # As a last resort, fall back to plan verification (if any)
        if not cmds:
            for v in plan.get("verification", []) or []:
                cmd_str = (v.get("cmd") or "").strip()
                if cmd_str:
                    cmds.append(cmd_str)

        # Pre-create output dirs used by javac -d ...
        self._ensure_output_dirs_for_cmds(cmds)

        logs: List[str] = []
        ok = True
        for cmd_str in cmds:
            cmd = self.sandbox.split_cmd(cmd_str)
            try:
                res = self.sandbox.run(cmd, cwd=self.work_dir)
                logs.append(_format_cmd_result(res))
                if not res.ok:
                    ok = False
            except Exception as e:
                ok = False
                logs.append(f"[VERIFY ERROR] cmd={cmd_str}\n{e}")
        return ok, "\n\n".join(logs)

    # ---------------------------
    # Main loop
    # ---------------------------

    def run(self, *, request: str, context_pack: Dict[str, Any]) -> Dict[str, Any]:
        run_dir = self.work_dir
        artifacts = run_dir / ".agent_artifacts"
        artifacts.mkdir(parents=True, exist_ok=True)

        raw_plan = self._plan(request=request, context_pack=context_pack)
        plan = self._normalize_plan_paths(raw_plan, context_pack)
        objective = request

        tool_info = self._run_tool_requests(plan.get("tool_requests", []) or [])
        (artifacts / "plan.json").write_text(json.dumps(plan, ensure_ascii=False, indent=2), encoding="utf-8")
        if tool_info:
            (artifacts / "tool_outputs.txt").write_text(tool_info, encoding="utf-8")

        # Git baseline
        self._ensure_git_baseline(artifacts)
        baseline_rev = self._git_head_hash()

        # Planned/allowed files (also include expected_files from context_pack if present)
        allowed_files = self._allowed_files_from_plan(plan)
        for ef in (context_pack.get("expected_files") or []):
            if isinstance(ef, str) and ef.strip():
                allowed_files.append(ef.strip())
        # de-dup
        seen = set()
        allowed_files = [x for x in allowed_files if not (x in seen or seen.add(x))]

        modified_files: List[str] = []

        def collect_modified_files() -> List[str]:
            # report diff vs baseline commit; exclude agent artifacts
            res = self.sandbox.run(["git", "diff", "--name-only", baseline_rev, "HEAD"], cwd=self.work_dir)
            files = [ln.strip() for ln in (res.stdout or "").splitlines() if ln.strip()]
            return [f for f in files if not self._is_meta_path(f)]

        # ---------------------------
        # Mode: monolithic (original)
        # ---------------------------
        if (self.cfg.execution_mode or "monolithic").lower() in ("monolithic", "one_shot", "oneshot"):
            prev_patch = ""
            last_logs = ""

            for it in range(1, self.cfg.max_iters + 1):
                # Always reset to baseline between attempts
                self._git_reset_clean()

                if it == 1:
                    patch = self._edit(objective=objective, plan=plan, context_pack=context_pack, extra_tool_info=tool_info)
                else:
                    patch = self._repair(
                        objective=objective,
                        plan=plan,
                        context_pack=context_pack,
                        prev_patch=prev_patch,
                        verify_logs=last_logs,
                        extra_tool_info=tool_info,
                    )

                llm_out_file = artifacts / f"llm_output_{it}.txt"
                llm_out_file.write_text(patch, encoding="utf-8")
                diff_file = artifacts / f"patch_attempt_{it}.diff"
                ok_apply, apply_logs = self._apply_llm_output(patch, diff_file)
                (artifacts / f"apply_attempt_{it}.txt").write_text(apply_logs, encoding="utf-8")
                if not ok_apply:
                    last_logs = apply_logs
                    prev_patch = patch
                    continue

                ok_scope, scope_logs = self._enforce_changed_files_whitelist(allowed_files)
                if not ok_scope:
                    (artifacts / f"scope_attempt_{it}.txt").write_text(scope_logs, encoding="utf-8")
                    last_logs = scope_logs
                    prev_patch = patch
                    continue

                verify_ok, verify_logs = self._verify(plan)
                (artifacts / f"verify_attempt_{it}.txt").write_text(verify_logs, encoding="utf-8")

                if verify_ok:
                    modified_files = collect_modified_files()
                    summary = {
                        "status": "success",
                        "attempts": it,
                        "work_dir": str(run_dir),
                        "artifacts_dir": str(artifacts),
                        "modified_files": modified_files,
                        "objective": objective,
                    }
                    (artifacts / "summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
                    return summary

                last_logs = verify_logs
                prev_patch = patch

            summary = {
                "status": "failed",
                "attempts": self.cfg.max_iters,
                "work_dir": str(run_dir),
                "artifacts_dir": str(artifacts),
                "modified_files": modified_files,
                "objective": objective,
            }
            (artifacts / "summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
            return summary

        # ---------------------------
        # Mode: stepwise (recommended)
        # ---------------------------
        # Build steps: use plan steps if provided, else split files_to_change into small chunks.
        step_files: List[str] = []
        for f in (plan.get("files_to_change") or []):
            fp = (f.get("file_path") or "").strip()
            if fp:
                step_files.append(fp)
        if not step_files:
            focus_fp = self._focus_file_from_context_pack(context_pack)
            if focus_fp:
                step_files.append(focus_fp)

        # chunk by step_max_files
        chunk = max(1, int(self.cfg.step_max_files or 1))
        steps: List[List[str]] = [step_files[i:i+chunk] for i in range(0, len(step_files), chunk)]
        if not steps:
            steps = [[]]

        for si, files_in_step in enumerate(steps, start=1):
            step_start_rev = self._git_head_hash()
            step_prev_patch = ""
            step_last_logs = ""

            step_objective = objective
            if files_in_step:
                step_objective += f"\n\n[STEP {si}/{len(steps)}] Only edit these files: {', '.join(files_in_step)}"
            else:
                step_objective += f"\n\n[STEP {si}/{len(steps)}]"

            step_plan = dict(plan)
            if files_in_step:
                step_plan["files_to_change"] = [{"file_path": p} for p in files_in_step]

            for it in range(1, self.cfg.max_iters + 1):
                # Reset to start of this step (NOT to baseline) so we can accumulate progress.
                self._git_reset_clean_to(step_start_rev)

                if it == 1:
                    patch = self._edit(
                        objective=step_objective,
                        plan=step_plan,
                        context_pack=context_pack,
                        extra_tool_info=tool_info,
                    )
                else:
                    patch = self._repair(
                        objective=step_objective,
                        plan=step_plan,
                        context_pack=context_pack,
                        prev_patch=step_prev_patch,
                        verify_logs=step_last_logs,
                        extra_tool_info=tool_info,
                    )

                llm_out_file = artifacts / f"llm_output_step{si}_attempt{it}.txt"
                llm_out_file.write_text(patch, encoding="utf-8")
                diff_file = artifacts / f"patch_step{si}_attempt{it}.diff"

                ok_apply, apply_logs = self._apply_llm_output(patch, diff_file)
                (artifacts / f"apply_step{si}_attempt{it}.txt").write_text(apply_logs, encoding="utf-8")
                if not ok_apply:
                    step_last_logs = apply_logs
                    step_prev_patch = patch
                    continue

                ok_scope, scope_logs = self._enforce_changed_files_whitelist(allowed_files)
                if not ok_scope:
                    (artifacts / f"scope_step{si}_attempt{it}.txt").write_text(scope_logs, encoding="utf-8")
                    step_last_logs = scope_logs
                    step_prev_patch = patch
                    continue

                if self.cfg.verify_each_step:
                    verify_ok, verify_logs = self._verify(step_plan)
                    (artifacts / f"verify_step{si}_attempt{it}.txt").write_text(verify_logs, encoding="utf-8")
                    if not verify_ok:
                        step_last_logs = verify_logs
                        step_prev_patch = patch
                        continue

                # Step success: checkpoint commit
                try:
                    self._git_commit_checkpoint(f"step {si}")
                except Exception:
                    # ignore if nothing to commit
                    pass
                modified_files = collect_modified_files()
                break
            else:
                # step failed
                summary = {
                    "status": "failed",
                    "attempts": self.cfg.max_iters,
                    "failed_step": si,
                    "work_dir": str(run_dir),
                    "artifacts_dir": str(artifacts),
                    "modified_files": modified_files,
                    "objective": objective,
                }
                (artifacts / "summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
                return summary

        # Final verification (even if verify_each_step=False, do it once at the end)
        final_ok, final_logs = self._verify(plan)
        (artifacts / "verify_final.txt").write_text(final_logs, encoding="utf-8")
        if final_ok:
            modified_files = collect_modified_files()
            summary = {
                "status": "success",
                "attempts": len(steps),
                "work_dir": str(run_dir),
                "artifacts_dir": str(artifacts),
                "modified_files": modified_files,
                "objective": objective,
            }
            (artifacts / "summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
            return summary

        summary = {
            "status": "failed",
            "attempts": len(steps),
            "work_dir": str(run_dir),
            "artifacts_dir": str(artifacts),
            "modified_files": modified_files,
            "objective": objective,
        }
        (artifacts / "summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")
        return summary


def _format_cmd_result(res: CommandResult) -> str:
    cmd_str = " ".join(res.cmd)
    return (
        f"[CMD] {cmd_str}\n"
        f"[RET] {res.returncode}\n"
        f"[STDOUT]\n{res.stdout}\n"
        f"[STDERR]\n{res.stderr}\n"
    )

==================== END FILE ====================


==================== FILE: src/eval/metrics.py ====================
from __future__ import annotations

import os
import re
from collections import Counter, defaultdict, deque
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, Iterable, List, Optional, Sequence, Set, Tuple

import networkx as nx

from ..parser import JavaCodeParser
from ..graph_builder import CodeGraphBuilder


def iter_java_files(project_root: str) -> Iterable[str]:
    ignore = {
        ".git",
        ".refactor_agent_runs",
        "target",
        "build",
        ".gradle",
        "node_modules",
        "__MACOSX",
        "__pycache__",
    }
    for root, dirs, files in os.walk(project_root):
        dirs[:] = [d for d in dirs if d not in ignore]
        for fn in files:
            if fn.endswith(".java"):
                yield os.path.join(root, fn)


_BLOCK_COMMENT_RE = re.compile(r"/\*.*?\*/", re.DOTALL)
_LINE_COMMENT_RE = re.compile(r"//.*?$", re.MULTILINE)


def strip_java_comments(text: str) -> str:
    # Best-effort: not a full lexer, but good enough for metrics.
    text = _BLOCK_COMMENT_RE.sub("", text)
    text = _LINE_COMMENT_RE.sub("", text)
    return text


def normalize_line(line: str) -> str:
    # Normalize for duplication detection
    s = strip_java_comments(line)
    s = s.strip()
    s = re.sub(r"\s+", " ", s)
    return s


def cyclomatic_complexity_approx(code: str) -> int:
    """Very lightweight cyclomatic complexity approximation.

    CC = 1 + (#decision points)

    Decision points counted:
      - if / for / while / case / catch
      - && / ||
      - ?: ternary

    This is intentionally simple and reproducible (no external tooling).
    """
    if not code:
        return 1

    code = strip_java_comments(code)
    # Remove string literals to avoid false positives.
    code = re.sub(r'"(?:\\.|[^"\\])*"', '""', code)
    code = re.sub(r"'(?:\\.|[^'\\])*'", "''", code)

    kw = re.findall(r"\b(if|for|while|case|catch)\b", code)
    and_or = code.count("&&") + code.count("||")
    ternary = code.count("?")
    return 1 + len(kw) + and_or + ternary


@dataclass
class MethodMetrics:
    method_id: str
    file_path: str
    start_line: int
    end_line: int
    loc: int
    loc_non_empty: int
    cyclomatic: int


def compute_method_metrics(project_root: str, *, prefer_tree_sitter: bool = True) -> Dict[str, MethodMetrics]:
    parser = JavaCodeParser(prefer_tree_sitter=prefer_tree_sitter)
    data = parser.parse_project(project_root)
    out: Dict[str, MethodMetrics] = {}

    # Cache file lines
    file_lines: Dict[str, List[str]] = {}

    for m in data.get("methods", []) or []:
        mid = str(m.get("id") or "")
        fp = str(m.get("file_path") or "")
        sl = int(m.get("start_line") or 0)
        el = int(m.get("end_line") or 0)
        if not mid or not fp or sl <= 0 or el <= 0 or el < sl:
            continue

        if fp not in file_lines:
            try:
                file_lines[fp] = Path(fp).read_text(encoding="utf-8", errors="ignore").splitlines()
            except Exception:
                file_lines[fp] = []
        lines = file_lines.get(fp, [])
        snippet_lines = lines[sl - 1 : el]
        snippet = "\n".join(snippet_lines)

        loc = el - sl + 1
        loc_non_empty = sum(1 for ln in snippet_lines if normalize_line(ln))
        cc = cyclomatic_complexity_approx(snippet)

        out[mid] = MethodMetrics(
            method_id=mid,
            file_path=fp,
            start_line=sl,
            end_line=el,
            loc=loc,
            loc_non_empty=loc_non_empty,
            cyclomatic=cc,
        )

    return out


@dataclass
class DuplicationMetrics:
    total_lines: int
    duplicate_lines: int
    duplicate_line_ratio: float
    distinct_lines: int


def compute_duplication_metrics(project_root: str) -> DuplicationMetrics:
    """Line-level duplication (simple + reproducible).

    We treat a line as *duplicate* if the same normalized line occurs in
    2+ places across the project (comments/whitespace ignored).
    """
    norm_lines: List[str] = []
    for fp in iter_java_files(project_root):
        try:
            raw = Path(fp).read_text(encoding="utf-8", errors="ignore")
        except Exception:
            continue
        for ln in raw.splitlines():
            n = normalize_line(ln)
            if not n:
                continue
            norm_lines.append(n)

    total = len(norm_lines)
    if total == 0:
        return DuplicationMetrics(total_lines=0, duplicate_lines=0, duplicate_line_ratio=0.0, distinct_lines=0)

    freq = Counter(norm_lines)
    dup = sum(c for c in freq.values() if c > 1)
    distinct = len(freq)
    return DuplicationMetrics(
        total_lines=total,
        duplicate_lines=dup,
        duplicate_line_ratio=float(dup) / float(total) if total else 0.0,
        distinct_lines=distinct,
    )


@dataclass
class ProjectMaintainabilityMetrics:
    methods: int
    avg_loc: float
    avg_cyclomatic: float
    p95_loc: float
    p95_cyclomatic: float
    max_loc: int
    max_cyclomatic: int
    duplication: DuplicationMetrics


def _percentile(values: List[int], p: float) -> float:
    if not values:
        return 0.0
    values = sorted(values)
    k = (len(values) - 1) * p
    f = int(k)
    c = min(f + 1, len(values) - 1)
    if f == c:
        return float(values[f])
    d0 = values[f] * (c - k)
    d1 = values[c] * (k - f)
    return float(d0 + d1)


def compute_project_maintainability(project_root: str, *, prefer_tree_sitter: bool = True) -> ProjectMaintainabilityMetrics:
    mm = compute_method_metrics(project_root, prefer_tree_sitter=prefer_tree_sitter)
    locs = [m.loc for m in mm.values()]
    ccs = [m.cyclomatic for m in mm.values()]

    methods = len(mm)
    avg_loc = float(sum(locs)) / float(methods) if methods else 0.0
    avg_cc = float(sum(ccs)) / float(methods) if methods else 0.0

    dup = compute_duplication_metrics(project_root)
    return ProjectMaintainabilityMetrics(
        methods=methods,
        avg_loc=avg_loc,
        avg_cyclomatic=avg_cc,
        p95_loc=_percentile(locs, 0.95),
        p95_cyclomatic=_percentile(ccs, 0.95),
        max_loc=max(locs) if locs else 0,
        max_cyclomatic=max(ccs) if ccs else 0,
        duplication=dup,
    )


def build_code_graph(project_root: str, *, prefer_tree_sitter: bool = True) -> nx.DiGraph:
    parser = JavaCodeParser(prefer_tree_sitter=prefer_tree_sitter)
    data = parser.parse_project(project_root)
    builder = CodeGraphBuilder()
    builder.build_from_parsed_data(data)
    return builder.get_graph()


@dataclass
class ChangeRiskMetrics:
    focus_node: str
    fan_in: int
    fan_out: int
    upstream_depth_max: int
    downstream_depth_max: int
    impacted_nodes_upstream: int
    impacted_nodes_downstream: int
    impacted_files: List[str]


def _bfs_depth(
    graph: nx.DiGraph,
    start: str,
    *,
    direction: str,
    relation: str = "CALLS",
    max_hops: Optional[int] = None,
) -> Dict[str, int]:
    if start not in graph:
        return {}
    q: deque[Tuple[str, int]] = deque([(start, 0)])
    visited: Set[str] = {start}
    depth_map: Dict[str, int] = {}
    while q:
        nid, d = q.popleft()
        if max_hops is not None and d >= max_hops:
            continue

        if direction == "in":
            edges = graph.in_edges(nid, data=True)
            for u, _, attrs in edges:
                rel = attrs.get("relation") or attrs.get("type")
                if rel != relation:
                    continue
                if u not in visited:
                    visited.add(u)
                    depth_map[str(u)] = d + 1
                    q.append((str(u), d + 1))
        else:
            edges = graph.out_edges(nid, data=True)
            for _, v, attrs in edges:
                rel = attrs.get("relation") or attrs.get("type")
                if rel != relation:
                    continue
                if v not in visited:
                    visited.add(v)
                    depth_map[str(v)] = d + 1
                    q.append((str(v), d + 1))
    depth_map.pop(start, None)
    return depth_map


def compute_change_risk(graph: nx.DiGraph, focus_node: str, *, max_hops: Optional[int] = None) -> ChangeRiskMetrics:
    """Compute a few graph-native "change risk" metrics.

    Interpretation for a refactoring focus node:
      - fan_in: how many direct callers depend on it
      - fan_out: how many direct callees it depends on
      - upstream_depth_max: max call-chain depth of its callers (impact propagates upward)
      - downstream_depth_max: max call-chain depth of its callees (impact propagates downward)
      - impacted_files: unique files of reachable caller/callee nodes (plus focus file when present)
    """
    if focus_node not in graph:
        return ChangeRiskMetrics(
            focus_node=focus_node,
            fan_in=0,
            fan_out=0,
            upstream_depth_max=0,
            downstream_depth_max=0,
            impacted_nodes_upstream=0,
            impacted_nodes_downstream=0,
            impacted_files=[],
        )

    # Direct fan-in/out for CALLS edges
    fan_in = sum(1 for u, _, a in graph.in_edges(focus_node, data=True) if (a.get("relation") or a.get("type")) == "CALLS")
    fan_out = sum(1 for _, v, a in graph.out_edges(focus_node, data=True) if (a.get("relation") or a.get("type")) == "CALLS")

    upstream = _bfs_depth(graph, focus_node, direction="in", relation="CALLS", max_hops=max_hops)
    downstream = _bfs_depth(graph, focus_node, direction="out", relation="CALLS", max_hops=max_hops)

    upstream_depth_max = max(upstream.values()) if upstream else 0
    downstream_depth_max = max(downstream.values()) if downstream else 0

    impacted_nodes = set([focus_node]) | set(upstream.keys()) | set(downstream.keys())
    files: Set[str] = set()
    for nid in impacted_nodes:
        fp = graph.nodes.get(nid, {}).get("file_path")
        if fp:
            files.add(str(fp))

    return ChangeRiskMetrics(
        focus_node=focus_node,
        fan_in=fan_in,
        fan_out=fan_out,
        upstream_depth_max=upstream_depth_max,
        downstream_depth_max=downstream_depth_max,
        impacted_nodes_upstream=len(upstream),
        impacted_nodes_downstream=len(downstream),
        impacted_files=sorted(files),
    )


def relpath_under(project_root: str, path: str) -> str:
    try:
        return os.path.relpath(path, project_root).replace("\\", "/")
    except Exception:
        return path.replace("\\", "/")


def context_pack_file_coverage(
    context_pack: Dict[str, Any],
    *,
    project_root: str,
    expected_files_rel: Sequence[str],
) -> Dict[str, Any]:
    """How many expected files are present in the context pack (by node.file_path)."""
    expected = {p.replace("\\", "/") for p in expected_files_rel if p}
    found: Set[str] = set()
    for n in context_pack.get("nodes", []) or []:
        fp = n.get("file_path")
        if not fp:
            continue
        found.add(relpath_under(project_root, str(fp)))

    hit = sorted(list(expected & found))
    miss = sorted(list(expected - found))
    coverage = (len(hit) / len(expected)) if expected else 1.0
    return {
        "expected_files": sorted(expected),
        "found_files": sorted(found),
        "hit_files": hit,
        "missing_files": miss,
        "coverage": coverage,
    }

==================== END FILE ====================


==================== FILE: src/eval/benchmark copy.py ====================
from __future__ import annotations

import json
import os
import time
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Tuple

import networkx as nx

from ..agent.agent import AgentConfig, RefactoringAgent
from ..agent.llm import DummyEchoLLM, OpenAICompatibleChatClient, OpenAICompatibleConfig
from ..context_engine import GraphRAGContextEngine
from ..vector_index import NodeVectorIndex
from ..graph_builder import CodeGraphBuilder
from ..parser import JavaCodeParser
from .metrics import (
    ChangeRiskMetrics,
    MethodMetrics,
    ProjectMaintainabilityMetrics,
    build_code_graph,
    compute_change_risk,
    compute_method_metrics,
    compute_project_maintainability,
    context_pack_file_coverage,
    relpath_under,
)


@dataclass
class BenchmarkTask:
    name: str
    query: str
    request: str
    expected_files: List[str]
    focus_node: Optional[str] = None
    focus_node_after: Optional[str] = None
    description: str = ""


def load_tasks(path: Path) -> List[BenchmarkTask]:
    obj = json.loads(path.read_text(encoding="utf-8"))
    tasks: List[BenchmarkTask] = []
    for t in obj.get("tasks", []):
        tasks.append(
            BenchmarkTask(
                name=str(t["name"]),
                query=str(t.get("query") or t.get("focus_node") or ""),
                request=str(t["request"]),
                expected_files=[str(x) for x in (t.get("expected_files") or [])],
                focus_node=str(t.get("focus_node") or "") or None,
                focus_node_after=str(t.get("focus_node_after") or "") or None,
                description=str(t.get("description") or ""),
            )
        )
    if not tasks:
        raise ValueError(f"No tasks found in: {path}")
    return tasks


def _build_graph_and_index(project_root: str, *, prefer_tree_sitter: bool = True) -> Tuple[nx.DiGraph, NodeVectorIndex]:
    parser = JavaCodeParser(prefer_tree_sitter=prefer_tree_sitter)
    data = parser.parse_project(project_root)
    builder = CodeGraphBuilder()
    builder.build_from_parsed_data(data)
    graph = builder.get_graph()

    vindex = NodeVectorIndex()
    vindex.build_from_graph(graph)
    return graph, vindex


def build_context_pack(
    project_root: str,
    *,
    query: str,
    mode: str = "graph_rag",
    seed_top_k: int = 5,
    hops: int = 2,
    max_nodes: int = 30,
    prefer_tree_sitter: bool = True,
) -> Dict[str, Any]:
    """Build a context pack in different ablation modes.

    mode:
      - graph_rag: full Graph-RAG expansion (vector seeds + neighborhood expansion)
      - vector_only: vector seeds only (graph expansion disabled)
    """
    graph, vindex = _build_graph_and_index(project_root, prefer_tree_sitter=prefer_tree_sitter)
    engine = GraphRAGContextEngine(graph, vindex)

    if mode == "vector_only":
        return engine.query(
            query,
            seed_top_k=seed_top_k,
            hops=0,
            max_nodes=max_nodes,
            same_class_limit=0,
            same_file_limit=0,
            shared_field_limit=0,
        )

    if mode != "graph_rag":
        raise ValueError(f"Unknown mode: {mode}")

    return engine.query(
        query,
        seed_top_k=seed_top_k,
        hops=hops,
        max_nodes=max_nodes,
    )


def _default_llm_from_env(*, dry_llm: bool) -> Any:
    if dry_llm:
        return DummyEchoLLM()
    base_url = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com")
    api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("OPENAI_APIKEY")
    model = os.environ.get("OPENAI_MODEL", "gpt-4.1-mini")
    return OpenAICompatibleChatClient(OpenAICompatibleConfig(base_url=base_url, api_key=api_key, model=model))


def run_benchmark(
    *,
    project_root: Path,
    tasks: Sequence[BenchmarkTask],
    out_dir: Path,
    modes: Sequence[str] = ("graph_rag", "vector_only"),
    prefer_tree_sitter: bool = True,
    # Context engine params
    seed_top_k: int = 5,
    hops: int = 2,
    max_nodes: int = 30,
    # Agent params
    max_iters: int = 3,
    use_docker: bool = False,
    docker_image: str = "python:3.10-slim",
    verify_cmds: Optional[List[str]] = None,
    allow_cmds: Optional[List[str]] = None,
    dry_llm: bool = False,
) -> Dict[str, Any]:
    """Run tasks under different retrieval modes and compute before/after metrics.

    This function does NOT modify `project_root` in-place: RefactoringAgent always
    works on a copied sandbox directory.
    """
    project_root = project_root.resolve()
    out_dir.mkdir(parents=True, exist_ok=True)

    # Pre-compute baseline maintainability for the *original* project.
    pre_project_maint = compute_project_maintainability(str(project_root), prefer_tree_sitter=prefer_tree_sitter)

    llm = _default_llm_from_env(dry_llm=dry_llm)

    results: Dict[str, Any] = {
        "project_root": str(project_root),
        "generated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "modes": list(modes),
        "tasks": [asdict(t) for t in tasks],
        "pre_project_maintainability": asdict(pre_project_maint),
        "runs": {},
    }

    for mode in modes:
        results["runs"][mode] = {}
        for task in tasks:
            task_dir = out_dir / mode / task.name
            task_dir.mkdir(parents=True, exist_ok=True)

            # 1) Build context pack
            pack = build_context_pack(
                str(project_root),
                query=task.query or (task.focus_node or ""),
                mode=mode,
                seed_top_k=seed_top_k,
                hops=hops,
                max_nodes=max_nodes,
                prefer_tree_sitter=prefer_tree_sitter,
            )
            (task_dir / "context_pack.json").write_text(json.dumps(pack, ensure_ascii=False, indent=2), encoding="utf-8")

            # 2) Coverage metric (benchmark style)
            cov = context_pack_file_coverage(pack, project_root=str(project_root), expected_files_rel=task.expected_files)
            (task_dir / "context_coverage.json").write_text(json.dumps(cov, ensure_ascii=False, indent=2), encoding="utf-8")

            # 3) Pre metrics (focus-level) on original project
            pre_method_mm = compute_method_metrics(str(project_root), prefer_tree_sitter=prefer_tree_sitter)
            focus_before = task.focus_node or pack.get("focus_node") or ""
            pre_focus_method: Optional[MethodMetrics] = pre_method_mm.get(focus_before)

            pre_graph = build_code_graph(str(project_root), prefer_tree_sitter=prefer_tree_sitter)
            pre_risk = compute_change_risk(pre_graph, focus_before)

            # 4) Run the refactoring agent
            cfg = AgentConfig(
                project_dir=project_root,
                max_iters=max_iters,
                use_docker=use_docker,
                docker_image=docker_image,
                default_verify_cmds=verify_cmds,
                allowed_commands=allow_cmds,
            )
            agent = RefactoringAgent(llm=llm, cfg=cfg)
            summary = agent.run(request=task.request, context_pack=pack)
            (task_dir / "agent_summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")

            # 5) Post metrics on agent's sandbox workdir (even on failure, work_dir exists)
            work_dir = Path(summary.get("work_dir") or "").resolve()
            post_project_maint = compute_project_maintainability(str(work_dir), prefer_tree_sitter=prefer_tree_sitter)
            post_method_mm = compute_method_metrics(str(work_dir), prefer_tree_sitter=prefer_tree_sitter)

            focus_after = task.focus_node_after or focus_before
            post_focus_method: Optional[MethodMetrics] = post_method_mm.get(focus_after)

            post_graph = build_code_graph(str(work_dir), prefer_tree_sitter=prefer_tree_sitter)
            post_risk = compute_change_risk(post_graph, focus_after)

            # 6) Normalize impacted files relative to project roots for easier reading
            def _rel_files(files: List[str], root: Path) -> List[str]:
                out: List[str] = []
                for f in files:
                    out.append(relpath_under(str(root), f))
                return sorted(list(dict.fromkeys(out)))

            run_record: Dict[str, Any] = {
                "status": summary.get("status"),
                "attempts": summary.get("attempts"),
                "objective": summary.get("objective"),
                "modified_files": summary.get("modified_files", []),
                "work_dir": str(work_dir),
                "context_coverage": cov,
                "focus_before": focus_before,
                "focus_after": focus_after,
                "pre_focus_method": asdict(pre_focus_method) if pre_focus_method else None,
                "post_focus_method": asdict(post_focus_method) if post_focus_method else None,
                "pre_project_maintainability": asdict(pre_project_maint),
                "post_project_maintainability": asdict(post_project_maint),
                "pre_change_risk": asdict(pre_risk),
                "post_change_risk": asdict(post_risk),
                "pre_impacted_files": _rel_files(pre_risk.impacted_files, project_root),
                "post_impacted_files": _rel_files(post_risk.impacted_files, work_dir),
            }

            (task_dir / "run_record.json").write_text(json.dumps(run_record, ensure_ascii=False, indent=2), encoding="utf-8")
            results["runs"][mode][task.name] = run_record

    (out_dir / "benchmark_results.json").write_text(json.dumps(results, ensure_ascii=False, indent=2), encoding="utf-8")
    return results

==================== END FILE ====================


==================== FILE: src/eval/benchmark.py ====================
from __future__ import annotations

import json
import os
import time
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence, Tuple

import networkx as nx

from ..agent.agent import AgentConfig, RefactoringAgent
from ..agent.llm import DummyEchoLLM, OpenAICompatibleChatClient, OpenAICompatibleConfig
from ..agent.sandbox import SandboxConfig
from ..context_engine import GraphRAGContextEngine
from ..vector_index import NodeVectorIndex
from ..graph_builder import CodeGraphBuilder
from ..parser import JavaCodeParser
from .metrics import (
    ChangeRiskMetrics,
    MethodMetrics,
    ProjectMaintainabilityMetrics,
    build_code_graph,
    compute_change_risk,
    compute_method_metrics,
    compute_project_maintainability,
    context_pack_file_coverage,
    relpath_under,
)


@dataclass
class BenchmarkTask:
    name: str
    query: str
    request: str
    expected_files: List[str]
    focus_node: Optional[str] = None
    focus_node_after: Optional[str] = None
    description: str = ""


def load_tasks(path: Path) -> List[BenchmarkTask]:
    obj = json.loads(path.read_text(encoding="utf-8"))
    tasks: List[BenchmarkTask] = []
    for t in obj.get("tasks", []):
        tasks.append(
            BenchmarkTask(
                name=str(t["name"]),
                query=str(t.get("query") or t.get("focus_node") or ""),
                request=str(t["request"]),
                expected_files=[str(x) for x in (t.get("expected_files") or [])],
                focus_node=str(t.get("focus_node") or "") or None,
                focus_node_after=str(t.get("focus_node_after") or "") or None,
                description=str(t.get("description") or ""),
            )
        )
    if not tasks:
        raise ValueError(f"No tasks found in: {path}")
    return tasks


def _build_graph_and_index(project_root: str, *, prefer_tree_sitter: bool = True) -> Tuple[nx.DiGraph, NodeVectorIndex]:
    parser = JavaCodeParser(prefer_tree_sitter=prefer_tree_sitter)
    data = parser.parse_project(project_root)
    builder = CodeGraphBuilder()
    builder.build_from_parsed_data(data)
    graph = builder.get_graph()

    vindex = NodeVectorIndex()
    vindex.build_from_graph(graph)
    return graph, vindex


def build_context_pack(
    project_root: str,
    *,
    query: str,
    mode: str = "graph_rag",
    seed_top_k: int = 5,
    hops: int = 2,
    max_nodes: int = 30,
    prefer_tree_sitter: bool = True,
) -> Dict[str, Any]:
    """Build a context pack in different ablation modes.

    mode:
      - graph_rag: full Graph-RAG expansion (vector seeds + neighborhood expansion)
      - vector_only: vector seeds only (graph expansion disabled)
    """
    graph, vindex = _build_graph_and_index(project_root, prefer_tree_sitter=prefer_tree_sitter)
    engine = GraphRAGContextEngine(graph, vindex)

    if mode == "vector_only":
        return engine.query(
            query,
            seed_top_k=seed_top_k,
            hops=0,
            max_nodes=max_nodes,
            same_class_limit=0,
            same_file_limit=0,
            shared_field_limit=0,
        )

    if mode != "graph_rag":
        raise ValueError(f"Unknown mode: {mode}")

    return engine.query(
        query,
        seed_top_k=seed_top_k,
        hops=hops,
        max_nodes=max_nodes,
    )


def _default_llm_from_env(*, dry_llm: bool) -> Any:
    if dry_llm:
        return DummyEchoLLM()
    base_url = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com")
    api_key = os.environ.get("OPENAI_API_KEY") or os.environ.get("OPENAI_APIKEY")
    model = os.environ.get("OPENAI_MODEL", "gpt-4.1-mini")
    return OpenAICompatibleChatClient(OpenAICompatibleConfig(base_url=base_url, api_key=api_key, model=model))


def run_benchmark(
    *,
    project_root: Path,
    tasks: Sequence[BenchmarkTask],
    out_dir: Path,
    modes: Sequence[str] = ("graph_rag", "vector_only"),
    prefer_tree_sitter: bool = True,
    # Context engine params
    seed_top_k: int = 5,
    hops: int = 2,
    max_nodes: int = 30,
    # Agent params
    max_iters: int = 3,
    use_docker: bool = False,
    docker_image: str = "python:3.10-slim",
    verify_cmds: Optional[List[str]] = None,
    allow_cmds: Optional[List[str]] = None,
    restrict_vector_only_tools: bool = False,
    dry_llm: bool = False,
) -> Dict[str, Any]:
    """Run tasks under different retrieval modes and compute before/after metrics.

    This function does NOT modify `project_root` in-place: RefactoringAgent always
    works on a copied sandbox directory.
    """
    project_root = project_root.resolve()
    out_dir.mkdir(parents=True, exist_ok=True)

    # Pre-compute baseline maintainability for the *original* project.
    pre_project_maint = compute_project_maintainability(str(project_root), prefer_tree_sitter=prefer_tree_sitter)

    llm = _default_llm_from_env(dry_llm=dry_llm)

    results: Dict[str, Any] = {
        "project_root": str(project_root),
        "generated_at": time.strftime("%Y-%m-%d %H:%M:%S"),
        "modes": list(modes),
        "tasks": [asdict(t) for t in tasks],
        "pre_project_maintainability": asdict(pre_project_maint),
        "runs": {},
    }

    for mode in modes:
        results["runs"][mode] = {}
        for task in tasks:
            task_dir = out_dir / mode / task.name
            task_dir.mkdir(parents=True, exist_ok=True)

            # 1) Build context pack
            pack = build_context_pack(
                str(project_root),
                query=task.query or (task.focus_node or ""),
                mode=mode,
                seed_top_k=seed_top_k,
                hops=hops,
                max_nodes=max_nodes,
                prefer_tree_sitter=prefer_tree_sitter,
            )
            (task_dir / "context_pack.json").write_text(json.dumps(pack, ensure_ascii=False, indent=2), encoding="utf-8")

            # 2) Coverage metric (benchmark style)
            cov = context_pack_file_coverage(pack, project_root=str(project_root), expected_files_rel=task.expected_files)
            (task_dir / "context_coverage.json").write_text(json.dumps(cov, ensure_ascii=False, indent=2), encoding="utf-8")

            # 3) Pre metrics (focus-level) on original project
            pre_method_mm = compute_method_metrics(str(project_root), prefer_tree_sitter=prefer_tree_sitter)
            focus_before = task.focus_node or pack.get("focus_node") or ""
            pre_focus_method: Optional[MethodMetrics] = pre_method_mm.get(focus_before)

            pre_graph = build_code_graph(str(project_root), prefer_tree_sitter=prefer_tree_sitter)
            pre_risk = compute_change_risk(pre_graph, focus_before)

            # 4) Run the refactoring agent
            mode_allow_cmds = allow_cmds
            if restrict_vector_only_tools and mode == "vector_only":
                # Make the ablation between retrieval modes more meaningful by
                # restricting shell-based code search in vector_only runs.
                base_cmds = mode_allow_cmds or SandboxConfig(root_dir=project_root).allowed_commands
                mode_allow_cmds = [c for c in base_cmds if c not in ("rg", "grep", "find")]

            cfg = AgentConfig(
                project_dir=project_root,
                max_iters=max_iters,
                use_docker=use_docker,
                docker_image=docker_image,
                default_verify_cmds=verify_cmds,
                allowed_commands=mode_allow_cmds,
            )
            agent = RefactoringAgent(llm=llm, cfg=cfg)
            summary = agent.run(request=task.request, context_pack=pack)
            (task_dir / "agent_summary.json").write_text(json.dumps(summary, ensure_ascii=False, indent=2), encoding="utf-8")

            # 5) Post metrics on agent's sandbox workdir (even on failure, work_dir exists)
            work_dir = Path(summary.get("work_dir") or "").resolve()
            post_project_maint = compute_project_maintainability(str(work_dir), prefer_tree_sitter=prefer_tree_sitter)
            post_method_mm = compute_method_metrics(str(work_dir), prefer_tree_sitter=prefer_tree_sitter)

            focus_after = task.focus_node_after or focus_before
            post_focus_method: Optional[MethodMetrics] = post_method_mm.get(focus_after)

            post_graph = build_code_graph(str(work_dir), prefer_tree_sitter=prefer_tree_sitter)
            post_risk = compute_change_risk(post_graph, focus_after)

            # 6) Normalize impacted files relative to project roots for easier reading
            def _rel_files(files: List[str], root: Path) -> List[str]:
                out: List[str] = []
                for f in files:
                    out.append(relpath_under(str(root), f))
                return sorted(list(dict.fromkeys(out)))

            run_record: Dict[str, Any] = {
                "status": summary.get("status"),
                "attempts": summary.get("attempts"),
                "objective": summary.get("objective"),
                "modified_files": summary.get("modified_files", []),
                "work_dir": str(work_dir),
                "allowed_commands": mode_allow_cmds,
                "context_coverage": cov,
                "focus_before": focus_before,
                "focus_after": focus_after,
                "pre_focus_method": asdict(pre_focus_method) if pre_focus_method else None,
                "post_focus_method": asdict(post_focus_method) if post_focus_method else None,
                "pre_project_maintainability": asdict(pre_project_maint),
                "post_project_maintainability": asdict(post_project_maint),
                "pre_change_risk": asdict(pre_risk),
                "post_change_risk": asdict(post_risk),
                "pre_impacted_files": _rel_files(pre_risk.impacted_files, project_root),
                "post_impacted_files": _rel_files(post_risk.impacted_files, work_dir),
            }

            # 7) Lightweight acceptance checks (more "honest" benchmark)
            accept_ok = True
            accept_reasons: List[str] = []

            def _looks_like_method_id(s: Optional[str]) -> bool:
                if not s:
                    return False
                s = str(s).strip()
                if not s:
                    return False
                if "," in s or " " in s or "(" in s or ")" in s:
                    return False
                # method ids are typically "Class.method" (exactly one dot)
                if s.count(".") != 1:
                    return False
                left, right = s.split(".", 1)
                return bool(left) and bool(right)

            if _looks_like_method_id(task.focus_node_after):
                if post_focus_method is None:
                    accept_ok = False
                    accept_reasons.append("post_focus_method_missing")

            missing_expected: List[str] = []
            for f in task.expected_files:
                f = str(f or "").strip()
                if not f:
                    continue
                if not (work_dir / f).exists():
                    missing_expected.append(f)

            if missing_expected:
                accept_ok = False
                accept_reasons.append("missing_expected_files: " + ", ".join(missing_expected))

            run_record["accept_ok"] = accept_ok
            run_record["accept_reasons"] = accept_reasons
            if run_record.get("status") == "success" and not accept_ok:
                run_record["status"] = "failed_acceptance"

            (task_dir / "run_record.json").write_text(json.dumps(run_record, ensure_ascii=False, indent=2), encoding="utf-8")
            results["runs"][mode][task.name] = run_record

    (out_dir / "benchmark_results.json").write_text(json.dumps(results, ensure_ascii=False, indent=2), encoding="utf-8")
    return results

==================== END FILE ====================


==================== FILE: src/eval/__init__.py ====================
"""Lightweight evaluation utilities for the demo.

This package is intentionally dependency-light so you can ship a reproducible
benchmark/evaluation story alongside the refactoring demo.
"""

==================== END FILE ====================


==================== FILE: src/eval/report.py ====================
from __future__ import annotations

import html
import json
from dataclasses import asdict, is_dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional


def _escape(s: Any) -> str:
    return html.escape(str(s), quote=False)


def _jsonable(x: Any) -> Any:
    if is_dataclass(x):
        return asdict(x)
    return x


def _bar(before: Optional[float], after: Optional[float], *, max_value: float) -> str:
    """A tiny HTML bar pair for before/after."""
    if max_value <= 0:
        max_value = 1.0
    b = (float(before) / max_value * 100.0) if before is not None else 0.0
    a = (float(after) / max_value * 100.0) if after is not None else 0.0
    return (
        f"<div class='barwrap'>"
        f"<div class='bar before' style='width:{b:.1f}%'></div>"
        f"<div class='bar after' style='width:{a:.1f}%'></div>"
        f"</div>"
    )


def render_benchmark_report(results: Dict[str, Any]) -> str:
    """Render a single self-contained HTML report."""
    modes: List[str] = list(results.get('modes') or [])
    tasks: List[Dict[str, Any]] = list(results.get('tasks') or [])
    runs: Dict[str, Any] = dict(results.get('runs') or {})

    # Choose a stable list of metrics to visualize.
    # We'll scale bars per-metric across the entire report.
    metric_values: Dict[str, float] = {}

    def upd(name: str, v: Optional[float]) -> None:
        if v is None:
            return
        metric_values[name] = max(metric_values.get(name, 0.0), float(v))

    for mode in modes:
        for t in tasks:
            r = (runs.get(mode) or {}).get(t['name']) or {}
            pre_m = (r.get('pre_focus_method') or {})
            post_m = (r.get('post_focus_method') or {})
            for k in ('loc', 'loc_non_empty', 'cyclomatic'):
                upd(f"focus_{k}", pre_m.get(k))
                upd(f"focus_{k}", post_m.get(k))
            pre_pr = (r.get('pre_change_risk') or {})
            post_pr = (r.get('post_change_risk') or {})
            for k in ('fan_in', 'fan_out', 'upstream_depth_max', 'downstream_depth_max'):
                upd(f"risk_{k}", pre_pr.get(k))
                upd(f"risk_{k}", post_pr.get(k))

    css = """
    body{font-family:system-ui,-apple-system,Segoe UI,Roboto,Helvetica,Arial; margin:0; background:#fafafa; color:#111;}
    header{padding:16px 20px; background:#111; color:#fff;}
    h1{margin:0; font-size:18px;}
    .sub{opacity:.85; font-size:12px; margin-top:4px;}
    .wrap{padding:16px 20px;}
    .card{background:#fff; border:1px solid #e6e6e6; border-radius:10px; padding:14px 14px; margin-bottom:14px;}
    table{width:100%; border-collapse:collapse; font-size:13px;}
    th, td{border-bottom:1px solid #eee; padding:8px 6px; vertical-align:top;}
    th{text-align:left; background:#fcfcfc;}
    code{background:#f2f2f2; padding:1px 4px; border-radius:4px;}
    .pill{display:inline-block; padding:2px 8px; border-radius:999px; font-size:12px; background:#f2f2f2;}
    .pill.ok{background:#e7f7ee;}
    .pill.fail{background:#fde8e8;}
    .barwrap{position:relative; height:10px; background:#f3f3f3; border-radius:999px; overflow:hidden; width:140px;}
    .bar{position:absolute; top:0; bottom:0;}
    .bar.before{left:0; opacity:0.5;}
    .bar.after{left:0; opacity:0.9;}
    .muted{color:#666;}
    details summary{cursor:pointer;}
    """

    def task_title(t: Dict[str, Any]) -> str:
        desc = t.get('description') or ''
        return f"<b>{_escape(t.get('name'))}</b> <span class='muted'>{_escape(desc)}</span>"

    out: List[str] = []
    out.append("<html><head><meta charset='utf-8'/>")
    out.append("<meta name='viewport' content='width=device-width, initial-scale=1'/>")
    out.append(f"<style>{css}</style></head><body>")
    out.append("<header>")
    out.append("<h1>Refactoring Benchmark Report</h1>")
    out.append(
        f"<div class='sub'>Project: <code>{_escape(results.get('project_root'))}</code> &nbsp; Generated: {_escape(results.get('generated_at'))}</div>"
    )
    out.append("</header>")
    out.append("<div class='wrap'>")

    # One card per task (rows = modes)
    for t in tasks:
        out.append("<div class='card'>")
        out.append(f"<div style='margin-bottom:8px'>{task_title(t)}</div>")
        out.append("<table>")
        out.append(
            "<tr><th style='width:120px'>Mode</th><th>Status</th><th>Context coverage</th><th>Focus maintainability</th><th>Change risk</th><th>Changed files</th></tr>"
        )

        for mode in modes:
            r = (runs.get(mode) or {}).get(t['name']) or {}
            status = str(r.get('status') or '')
            pill = "pill ok" if status == 'success' else "pill fail"
            attempts = r.get('attempts')
            cov = (r.get('context_coverage') or {}).get('coverage')
            cov_s = f"{float(cov)*100:.0f}%" if cov is not None else "n/a"

            pre_m = r.get('pre_focus_method') or {}
            post_m = r.get('post_focus_method') or {}
            pre_cc = pre_m.get('cyclomatic')
            post_cc = post_m.get('cyclomatic')
            pre_loc = pre_m.get('loc')
            post_loc = post_m.get('loc')

            pre_r = r.get('pre_change_risk') or {}
            post_r = r.get('post_change_risk') or {}

            cc_bar = _bar(pre_cc, post_cc, max_value=metric_values.get('focus_cyclomatic', 1.0))
            loc_bar = _bar(pre_loc, post_loc, max_value=metric_values.get('focus_loc', 1.0))

            risk_bar = _bar(
                pre_r.get('fan_in'),
                post_r.get('fan_in'),
                max_value=metric_values.get('risk_fan_in', 1.0),
            )

            changed = r.get('modified_files') or []
            changed_s = "<br/>".join(f"<code>{_escape(x)}</code>" for x in changed[:8])
            if len(changed) > 8:
                changed_s += f"<div class='muted'>... +{len(changed)-8} more</div>"

            out.append("<tr>")
            out.append(f"<td><code>{_escape(mode)}</code></td>")
            out.append(
                f"<td><span class='{pill}'>{_escape(status)}</span> <span class='muted'>(attempts={_escape(attempts)})</span></td>"
            )
            out.append(f"<td>{_escape(cov_s)}</td>")
            out.append(
                "<td>"
                f"<div class='muted'>CC: { _escape(pre_cc) } â†’ { _escape(post_cc) }</div>{cc_bar}"
                f"<div class='muted' style='margin-top:6px'>LOC: { _escape(pre_loc) } â†’ { _escape(post_loc) }</div>{loc_bar}"
                "</td>"
            )
            out.append(
                "<td>"
                f"<div class='muted'>fan-in: { _escape(pre_r.get('fan_in')) } â†’ { _escape(post_r.get('fan_in')) }</div>{risk_bar}"
                f"<div class='muted' style='margin-top:6px'>depth(up): { _escape(pre_r.get('upstream_depth_max')) } â†’ { _escape(post_r.get('upstream_depth_max')) }</div>"
                f"<div class='muted'>depth(down): { _escape(pre_r.get('downstream_depth_max')) } â†’ { _escape(post_r.get('downstream_depth_max')) }</div>"
                "</td>"
            )
            out.append(f"<td>{changed_s if changed_s else '<span class=muted>n/a</span>'}</td>")
            out.append("</tr>")

        out.append("</table>")

        # Raw JSON details for reproducibility
        out.append("<details style='margin-top:10px'><summary>Raw JSON (for reproducibility)</summary>")
        raw = {
            'task': t,
            'runs': {m: (runs.get(m) or {}).get(t['name']) for m in modes},
        }
        out.append(f"<pre style='white-space:pre-wrap'>{_escape(json.dumps(raw, ensure_ascii=False, indent=2, default=_jsonable))}</pre>")
        out.append("</details>")

        out.append("</div>")

    out.append("</div></body></html>")
    return "".join(out)


def write_benchmark_report(results_path: Path, *, out_html: Path) -> Path:
    results = json.loads(results_path.read_text(encoding='utf-8'))
    html_text = render_benchmark_report(results)
    out_html.write_text(html_text, encoding='utf-8')
    return out_html

==================== END FILE ====================

